/* Generated by Cython 0.22 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "language": "c++", 
        "runtime_library_dirs": [
            "."
        ], 
        "libraries": [
            "TH", 
            "THC", 
            "TorchLanguageIndependence"
        ], 
        "depends": [
            "/home/user/torch/install/include/TH/THStorage.h", 
            "/home/user/torch/install/include/THC/THCTensor.h", 
            "/home/user/torch/install/include/TH/THRandom.h", 
            "/home/user/torch/install/include/TH/THTensor.h", 
            "../pytorch/src/nnWrapper.h", 
            "/home/user/torch/install/include/THC/THCGeneral.h", 
            "/home/user/torch/install/include/THC/THCTensorCopy.h", 
            "/home/user/torch/install/include/THC/THCTensorMath.h", 
            "cudannWrapper.h", 
            "../pytorch/src/LuaHelper.h"
        ], 
        "extra_compile_args": [
            "-std=c++0x", 
            "-g"
        ], 
        "library_dirs": [
            "cbuild", 
            "/home/user/torch/install/lib"
        ], 
        "include_dirs": [
            "/opt/cuda-7.0/include", 
            "/home/user/torch/install/include", 
            "/home/user/torch/install/include/TH", 
            "/home/user/torch/install/include/THC", 
            "/usr/include/lua5.1", 
            "../pytorch/src"
        ]
    }
}
END: Cython Metadata */

#define PY_SSIZE_T_CLEAN
#ifndef CYTHON_USE_PYLONG_INTERNALS
#ifdef PYLONG_BITS_IN_DIGIT
#define CYTHON_USE_PYLONG_INTERNALS 0
#else
#include "pyconfig.h"
#ifdef PYLONG_BITS_IN_DIGIT
#define CYTHON_USE_PYLONG_INTERNALS 1
#else
#define CYTHON_USE_PYLONG_INTERNALS 0
#endif
#endif
#endif
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03020000)
    #error Cython requires Python 2.6+ or Python 3.2+.
#else
#define CYTHON_ABI "0_22"
#include <stddef.h>
#ifndef offsetof
#define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
#define CYTHON_COMPILING_IN_PYPY 1
#define CYTHON_COMPILING_IN_CPYTHON 0
#else
#define CYTHON_COMPILING_IN_PYPY 0
#define CYTHON_COMPILING_IN_CPYTHON 1
#endif
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
#define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos) \
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos) \
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyType_Type
#endif
#if PY_MAJOR_VERSION >= 3
  #define Py_TPFLAGS_CHECKTYPES 0
  #define Py_TPFLAGS_HAVE_INDEX 0
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#if PY_VERSION_HEX < 0x030400a1 && !defined(Py_TPFLAGS_HAVE_FINALIZE)
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ? \
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
#else
  #define CYTHON_PEP393_ENABLED 0
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
  #define __Pyx_PyFrozenSet_Size(s)         PyObject_Size(s)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ? \
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
  #define __Pyx_PyFrozenSet_Size(s)         PySet_Size(s)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#ifndef CYTHON_INLINE
  #if defined(__GNUC__)
    #define CYTHON_INLINE __inline__
  #elif defined(_MSC_VER)
    #define CYTHON_INLINE __inline
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_INLINE inline
  #else
    #define CYTHON_INLINE
  #endif
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  /* Initialize NaN. The sign is irrelevant, an exponent with all bits 1 and
   a nonzero mantissa means NaN. If the first bit in the mantissa is 1, it is
   a quiet NaN. */
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#define __Pyx_void_to_None(void_result) (void_result, Py_INCREF(Py_None), Py_None)
#ifdef __cplusplus
template<typename T>
void __Pyx_call_destructor(T* x) {
    x->~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(T& ref) : ptr(&ref) { }
    T *operator->() { return ptr; }
    operator T&() { return *ptr; }
  private:
    T *ptr;
};
#endif


#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#if defined(WIN32) || defined(MS_WINDOWS)
#define _USE_MATH_DEFINES
#endif
#include <math.h>
#define __PYX_HAVE__PyCudaTorch
#define __PYX_HAVE_API__PyCudaTorch
#include "string.h"
#include "stdio.h"
#include "THRandom.h"
#include "nnWrapper.h"
#include "THTensor.h"
#include "THStorage.h"
#include "LuaHelper.h"
#include "THCGeneral.h"
#include "THCTensor.h"
#include "THCTensorCopy.h"
#include "THCTensorMath.h"
#include "cudannWrapper.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#ifdef PYREX_WITHOUT_ASSERTIONS
#define CYTHON_WITHOUT_ASSERTIONS
#endif

#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
typedef struct {PyObject **p; char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (    \
    (sizeof(type) < sizeof(Py_ssize_t))  ||             \
    (sizeof(type) > sizeof(Py_ssize_t) &&               \
          likely(v < (type)PY_SSIZE_T_MAX ||            \
                 v == (type)PY_SSIZE_T_MAX)  &&         \
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||       \
                                v == (type)PY_SSIZE_T_MIN)))  ||  \
    (sizeof(type) == sizeof(Py_ssize_t) &&              \
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||        \
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyObject_AsSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
#if PY_MAJOR_VERSION < 3
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u)
{
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#else
#define __Pyx_Py_UNICODE_strlen Py_UNICODE_strlen
#endif
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_Owned_Py_None(b) (Py_INCREF(Py_None), Py_None)
#define __Pyx_PyBool_FromLong(b) ((b) ? (Py_INCREF(Py_True), Py_True) : (Py_INCREF(Py_False), Py_False))
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_Int(PyObject* x);
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_COMPILING_IN_CPYTHON
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c));
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */

static PyObject *__pyx_m;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "PyCudaTorch.pyx",
  "array.pxd",
  "PyTorch.pxd",
  "Storage.pxd",
};

/*--- Type declarations ---*/
#ifndef _ARRAYARRAY_H
struct arrayobject;
typedef struct arrayobject arrayobject;
#endif
struct __pyx_obj_7PyTorch__DoubleTensor;
struct __pyx_obj_7PyTorch__ByteTensor;
struct __pyx_obj_7PyTorch__FloatTensor;
struct __pyx_obj_7PyTorch__LongTensor;
struct __pyx_obj_7PyTorch_GlobalState;
struct __pyx_obj_7Storage__DoubleStorage;
struct __pyx_obj_7Storage__ByteStorage;
struct __pyx_obj_7Storage__FloatStorage;
struct __pyx_obj_7Storage__LongStorage;
struct __pyx_obj_11PyCudaTorch_CudaTensor;
struct __pyx_obj_11PyCudaTorch_CudaGlobalState;
struct __pyx_opt_args_7Storage__DoubleStorage_fromNative;
struct __pyx_opt_args_7Storage__ByteStorage_fromNative;
struct __pyx_opt_args_7Storage__FloatStorage_fromNative;
struct __pyx_opt_args_7Storage__LongStorage_fromNative;

/* "Storage.pxd":84
 *     cpdef long size(self)
 * 
 * cdef _DoubleStorage_fromNative(THDoubleStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_opt_args_7Storage__DoubleStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "Storage.pxd":91
 *     cpdef long size(self)
 * 
 * cdef _ByteStorage_fromNative(THByteStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_opt_args_7Storage__ByteStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "Storage.pxd":98
 *     cpdef long size(self)
 * 
 * cdef _FloatStorage_fromNative(THFloatStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 * 
 */
struct __pyx_opt_args_7Storage__FloatStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "Storage.pxd":105
 *     cpdef long size(self)
 * 
 * cdef _LongStorage_fromNative(THLongStorage *storageC, retain=*)             # <<<<<<<<<<<<<<
 * 
 */
struct __pyx_opt_args_7Storage__LongStorage_fromNative {
  int __pyx_n;
  PyObject *retain;
};
struct __pyx_opt_args_11PyCudaTorch_CudaTensor_fromNative;

/* "PyCudaTorch.pyx":238
 *     return prediction + 1
 * 
 * cdef CudaTensor_fromNative(THCudaTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     cdef CudaTensor tensor = CudaTensor(_allocate=False )
 *     tensor.native = tensorC
 */
struct __pyx_opt_args_11PyCudaTorch_CudaTensor_fromNative {
  int __pyx_n;
  PyObject *retain;
};

/* "PyTorch.pxd":21
 *     cdef struct THDoubleTensor
 * 
 * cdef class _DoubleTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THDoubleTensor *native
 *     cpdef int dims(self)
 */
struct __pyx_obj_7PyTorch__DoubleTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__DoubleTensor *__pyx_vtab;
  struct THDoubleTensor *native;
};


/* "PyTorch.pxd":36
 *     cdef struct THByteTensor
 * 
 * cdef class _ByteTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THByteTensor *native
 *     cpdef int dims(self)
 */
struct __pyx_obj_7PyTorch__ByteTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__ByteTensor *__pyx_vtab;
  struct THByteTensor *native;
};


/* "PyTorch.pxd":51
 *     cdef struct THFloatTensor
 * 
 * cdef class _FloatTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THFloatTensor *native
 *     cpdef int dims(self)
 */
struct __pyx_obj_7PyTorch__FloatTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__FloatTensor *__pyx_vtab;
  struct THFloatTensor *native;
};


/* "PyTorch.pxd":66
 *     cdef struct THLongTensor
 * 
 * cdef class _LongTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THLongTensor *native
 *     cpdef int dims(self)
 */
struct __pyx_obj_7PyTorch__LongTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_7PyTorch__LongTensor *__pyx_vtab;
  struct THLongTensor *native;
};


/* "PyTorch.pxd":77
 * 
 * 
 * cdef class GlobalState:             # <<<<<<<<<<<<<<
 * #    cdef PyTorchState *state
 *     cdef lua_State *L
 */
struct __pyx_obj_7PyTorch_GlobalState {
  PyObject_HEAD
  struct lua_State *L;
  struct THGenerator *generator;
};


/* "Storage.pxd":80
 * 
 * 
 * cdef class _DoubleStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THDoubleStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__DoubleStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__DoubleStorage *__pyx_vtab;
  struct THDoubleStorage *native;
};


/* "Storage.pxd":87
 * 
 * 
 * cdef class _ByteStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THByteStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__ByteStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__ByteStorage *__pyx_vtab;
  struct THByteStorage *native;
};


/* "Storage.pxd":94
 * 
 * 
 * cdef class _FloatStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THFloatStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__FloatStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__FloatStorage *__pyx_vtab;
  struct THFloatStorage *native;
};


/* "Storage.pxd":101
 * 
 * 
 * cdef class _LongStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THLongStorage *native
 *     cpdef long size(self)
 */
struct __pyx_obj_7Storage__LongStorage {
  PyObject_HEAD
  struct __pyx_vtabstruct_7Storage__LongStorage *__pyx_vtab;
  struct THLongStorage *native;
};


/* "PyCudaTorch.pyx":71
 *     pushCudaTensor(cudaGlobalState.state, globalState.L, tensor.native)
 * 
 * cdef class CudaTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THCudaTensor *native
 * 
 */
struct __pyx_obj_11PyCudaTorch_CudaTensor {
  PyObject_HEAD
  struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *__pyx_vtab;
  struct THCudaTensor *native;
};


/* "PyCudaTorch.pyx":289
 * cdef PyTorch.GlobalState globalState = PyTorch.getGlobalState()
 * 
 * cdef class CudaGlobalState(object):             # <<<<<<<<<<<<<<
 *     cdef THCState *state
 * 
 */
struct __pyx_obj_11PyCudaTorch_CudaGlobalState {
  PyObject_HEAD
  struct THCState *state;
};



/* "PyTorch.pxd":21
 *     cdef struct THDoubleTensor
 * 
 * cdef class _DoubleTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THDoubleTensor *native
 *     cpdef int dims(self)
 */

struct __pyx_vtabstruct_7PyTorch__DoubleTensor {
  int (*dims)(struct __pyx_obj_7PyTorch__DoubleTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, double, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int, double, int __pyx_skip_dispatch);
  double (*get1d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int __pyx_skip_dispatch);
  double (*get2d)(struct __pyx_obj_7PyTorch__DoubleTensor *, int, int, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__DoubleTensor *__pyx_vtabptr_7PyTorch__DoubleTensor;


/* "PyTorch.pxd":36
 *     cdef struct THByteTensor
 * 
 * cdef class _ByteTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THByteTensor *native
 *     cpdef int dims(self)
 */

struct __pyx_vtabstruct_7PyTorch__ByteTensor {
  int (*dims)(struct __pyx_obj_7PyTorch__ByteTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, unsigned char, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int, unsigned char, int __pyx_skip_dispatch);
  unsigned char (*get1d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int __pyx_skip_dispatch);
  unsigned char (*get2d)(struct __pyx_obj_7PyTorch__ByteTensor *, int, int, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__ByteTensor *__pyx_vtabptr_7PyTorch__ByteTensor;


/* "PyTorch.pxd":51
 *     cdef struct THFloatTensor
 * 
 * cdef class _FloatTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THFloatTensor *native
 *     cpdef int dims(self)
 */

struct __pyx_vtabstruct_7PyTorch__FloatTensor {
  int (*dims)(struct __pyx_obj_7PyTorch__FloatTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, float, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int, float, int __pyx_skip_dispatch);
  float (*get1d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int __pyx_skip_dispatch);
  float (*get2d)(struct __pyx_obj_7PyTorch__FloatTensor *, int, int, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__FloatTensor *__pyx_vtabptr_7PyTorch__FloatTensor;


/* "PyTorch.pxd":66
 *     cdef struct THLongTensor
 * 
 * cdef class _LongTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THLongTensor *native
 *     cpdef int dims(self)
 */

struct __pyx_vtabstruct_7PyTorch__LongTensor {
  int (*dims)(struct __pyx_obj_7PyTorch__LongTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_7PyTorch__LongTensor *, int, long, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_7PyTorch__LongTensor *, int, int, long, int __pyx_skip_dispatch);
  long (*get1d)(struct __pyx_obj_7PyTorch__LongTensor *, int, int __pyx_skip_dispatch);
  long (*get2d)(struct __pyx_obj_7PyTorch__LongTensor *, int, int, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7PyTorch__LongTensor *__pyx_vtabptr_7PyTorch__LongTensor;


/* "Storage.pxd":80
 * 
 * 
 * cdef class _DoubleStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THDoubleStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__DoubleStorage {
  long (*size)(struct __pyx_obj_7Storage__DoubleStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__DoubleStorage *__pyx_vtabptr_7Storage__DoubleStorage;


/* "Storage.pxd":87
 * 
 * 
 * cdef class _ByteStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THByteStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__ByteStorage {
  long (*size)(struct __pyx_obj_7Storage__ByteStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__ByteStorage *__pyx_vtabptr_7Storage__ByteStorage;


/* "Storage.pxd":94
 * 
 * 
 * cdef class _FloatStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THFloatStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__FloatStorage {
  long (*size)(struct __pyx_obj_7Storage__FloatStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__FloatStorage *__pyx_vtabptr_7Storage__FloatStorage;


/* "Storage.pxd":101
 * 
 * 
 * cdef class _LongStorage(object):             # <<<<<<<<<<<<<<
 *     cdef THLongStorage *native
 *     cpdef long size(self)
 */

struct __pyx_vtabstruct_7Storage__LongStorage {
  long (*size)(struct __pyx_obj_7Storage__LongStorage *, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_7Storage__LongStorage *__pyx_vtabptr_7Storage__LongStorage;


/* "PyCudaTorch.pyx":71
 *     pushCudaTensor(cudaGlobalState.state, globalState.L, tensor.native)
 * 
 * cdef class CudaTensor(object):             # <<<<<<<<<<<<<<
 *     cdef THCudaTensor *native
 * 
 */

struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor {
  int (*dims)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int __pyx_skip_dispatch);
  PyObject *(*set1d)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, float, int __pyx_skip_dispatch);
  PyObject *(*set2d)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, int, float, int __pyx_skip_dispatch);
  float (*get1d)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, int __pyx_skip_dispatch);
  float (*get2d)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, int, int __pyx_skip_dispatch);
};
static struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *__pyx_vtabptr_11PyCudaTorch_CudaTensor;

/* --- Runtime support code (head) --- */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil) \
          if (acquire_gil) { \
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure(); \
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__); \
              PyGILState_Release(__pyx_gilstate_save); \
          } else { \
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__); \
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil) \
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext() \
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {                            \
        PyObject *tmp = (PyObject *) r;                         \
        r = v; __Pyx_XDECREF(tmp);                              \
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {                             \
        PyObject *tmp = (PyObject *) r;                         \
        r = v; __Pyx_DECREF(tmp);                               \
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

static PyObject *__Pyx_GetBuiltinName(PyObject *name);

static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type);

static CYTHON_INLINE int __Pyx_ArgTypeTest(PyObject *obj, PyTypeObject *type, int none_allowed,
    const char *name, int exact);

static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[], \
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args, \
    const char* function_name);

static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

static CYTHON_INLINE void __Pyx_ErrRestore(PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetch(PyObject **type, PyObject **value, PyObject **tb);

static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck) \
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ? \
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) : \
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) : \
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck) \
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ? \
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) : \
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck) \
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ? \
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) : \
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

static CYTHON_INLINE int __Pyx_CheckKeywordStrings(PyObject *kwdict, const char* function_name, int kw_allowed);

#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);
#else
#define __Pyx_PyObject_CallNoArg(func) __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL)
#endif

static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                  int lineno, const char *filename,
                                  int full_traceback);

#define __Pyx_SetItemInt(o, i, v, type, is_signed, to_py_func, is_list, wraparound, boundscheck) \
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ? \
    __Pyx_SetItemInt_Fast(o, (Py_ssize_t)i, v, is_list, wraparound, boundscheck) : \
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list assignment index out of range"), -1) : \
               __Pyx_SetItemInt_Generic(o, to_py_func(i), v)))
static CYTHON_INLINE int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v);
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v,
                                               int is_list, int wraparound, int boundscheck);

static int __Pyx_SetVtable(PyObject *dict, void *vtable);

static void* __Pyx_GetVtable(PyObject *dict);

static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name);

static PyObject *__Pyx_GetNameInClass(PyObject *nmspace, PyObject *name);

typedef struct {
    int code_line;
    PyCodeObject* code_object;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

#ifndef _ARRAYARRAY_H
#define _ARRAYARRAY_H
typedef struct arraydescr {
    int typecode;
    int itemsize;
    PyObject * (*getitem)(struct arrayobject *, Py_ssize_t);
    int (*setitem)(struct arrayobject *, Py_ssize_t, PyObject *);
#if PY_MAJOR_VERSION >= 3
    char *formats;
#endif
} arraydescr;
struct arrayobject {
    PyObject_HEAD
    Py_ssize_t ob_size;
    union {
        char *ob_item;
        float *as_floats;
        double *as_doubles;
        int *as_ints;
        unsigned int *as_uints;
        unsigned char *as_uchars;
        signed char *as_schars;
        char *as_chars;
        unsigned long *as_ulongs;
        long *as_longs;
        short *as_shorts;
        unsigned short *as_ushorts;
        Py_UNICODE *as_pyunicodes;
        void *as_voidptr;
    } data;
    Py_ssize_t allocated;
    struct arraydescr *ob_descr;
    PyObject *weakreflist;
#if PY_MAJOR_VERSION >= 3
        int ob_exports;
#endif
};
#ifndef NO_NEWARRAY_INLINE
static CYTHON_INLINE PyObject * newarrayobject(PyTypeObject *type, Py_ssize_t size,
    struct arraydescr *descr) {
    arrayobject *op;
    size_t nbytes;
    if (size < 0) {
        PyErr_BadInternalCall();
        return NULL;
    }
    nbytes = size * descr->itemsize;
    if (nbytes / descr->itemsize != (size_t)size) {
        return PyErr_NoMemory();
    }
    op = (arrayobject *) type->tp_alloc(type, 0);
    if (op == NULL) {
        return NULL;
    }
    op->ob_descr = descr;
    op->allocated = size;
    op->weakreflist = NULL;
    op->ob_size = size;
    if (size <= 0) {
        op->data.ob_item = NULL;
    }
    else {
        op->data.ob_item = PyMem_NEW(char, nbytes);
        if (op->data.ob_item == NULL) {
            Py_DECREF(op);
            return PyErr_NoMemory();
        }
    }
    return (PyObject *) op;
}
#else
PyObject* newarrayobject(PyTypeObject *type, Py_ssize_t size,
    struct arraydescr *descr);
#endif
static CYTHON_INLINE int resize(arrayobject *self, Py_ssize_t n) {
    void *items = (void*) self->data.ob_item;
    PyMem_Resize(items, char, (size_t)(n * self->ob_descr->itemsize));
    if (items == NULL) {
        PyErr_NoMemory();
        return -1;
    }
    self->data.ob_item = (char*) items;
    self->ob_size = n;
    self->allocated = n;
    return 0;
}
static CYTHON_INLINE int resize_smart(arrayobject *self, Py_ssize_t n) {
    void *items = (void*) self->data.ob_item;
    Py_ssize_t newsize;
    if (n < self->ob_size) {
        self->ob_size = n;
        return 0;
    }
    newsize = n + (n / 2) + 1;
    if (newsize <= self->allocated) {
        PyErr_NoMemory();
        return -1;
    }
    PyMem_Resize(items, char, (size_t)(newsize * self->ob_descr->itemsize));
    if (items == NULL) {
        PyErr_NoMemory();
        return -1;
    }
    self->data.ob_item = (char*) items;
    self->ob_size = n;
    self->allocated = newsize;
    return 0;
}
#endif

static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value);

static int __Pyx_check_binary_version(void);

#if !defined(__Pyx_PyIdentifier_FromString)
#if PY_MAJOR_VERSION < 3
  #define __Pyx_PyIdentifier_FromString(s) PyString_FromString(s)
#else
  #define __Pyx_PyIdentifier_FromString(s) PyUnicode_FromString(s)
#endif
#endif

static PyObject *__Pyx_ImportModule(const char *name);

static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name, size_t size, int strict);

static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);

static int __pyx_f_11PyCudaTorch_10CudaTensor_dims(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_11PyCudaTorch_10CudaTensor_set1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static PyObject *__pyx_f_11PyCudaTorch_10CudaTensor_set2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value, int __pyx_skip_dispatch); /* proto*/
static float __pyx_f_11PyCudaTorch_10CudaTensor_get1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch); /* proto*/
static float __pyx_f_11PyCudaTorch_10CudaTensor_get2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch); /* proto*/

/* Module declarations from 'cython' */

/* Module declarations from 'libc.string' */

/* Module declarations from 'cpython.ref' */

/* Module declarations from 'libc.stdio' */

/* Module declarations from 'cpython.object' */

/* Module declarations from 'cpython.exc' */

/* Module declarations from 'cpython.mem' */

/* Module declarations from 'array' */

/* Module declarations from 'cpython.array' */
static PyTypeObject *__pyx_ptype_7cpython_5array_array = 0;
static CYTHON_INLINE int __pyx_f_7cpython_5array_extend_buffer(arrayobject *, char *, Py_ssize_t); /*proto*/

/* Module declarations from 'cpython' */

/* Module declarations from 'PyTorch' */
static PyTypeObject *__pyx_ptype_7PyTorch__DoubleTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch__ByteTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch__FloatTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch__LongTensor = 0;
static PyTypeObject *__pyx_ptype_7PyTorch_GlobalState = 0;

/* Module declarations from 'Storage' */
static PyTypeObject *__pyx_ptype_7Storage__DoubleStorage = 0;
static PyTypeObject *__pyx_ptype_7Storage__ByteStorage = 0;
static PyTypeObject *__pyx_ptype_7Storage__FloatStorage = 0;
static PyTypeObject *__pyx_ptype_7Storage__LongStorage = 0;

/* Module declarations from 'PyCudaTorch' */
static PyTypeObject *__pyx_ptype_11PyCudaTorch_CudaTensor = 0;
static PyTypeObject *__pyx_ptype_11PyCudaTorch_CudaGlobalState = 0;
static struct __pyx_obj_7PyTorch_GlobalState *__pyx_v_11PyCudaTorch_globalState = 0;
static struct __pyx_obj_11PyCudaTorch_CudaGlobalState *__pyx_v_11PyCudaTorch_cudaGlobalState = 0;
static int __pyx_f_11PyCudaTorch_getPrediction(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_11PyCudaTorch_CudaTensor_fromNative(struct THCudaTensor *, struct __pyx_opt_args_11PyCudaTorch_CudaTensor_fromNative *__pyx_optional_args); /*proto*/
#define __Pyx_MODULE_NAME "PyCudaTorch"
int __pyx_module_is_main_PyCudaTorch = 0;

/* Implementation of 'PyCudaTorch' */
static PyObject *__pyx_builtin_staticmethod;
static PyObject *__pyx_builtin_Exception;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_print;
static PyObject *__pyx_builtin_MemoryError;
static PyObject *__pyx_pf_11PyCudaTorch_cyPopCudaTensor(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_2cyPushCudaTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_tensor); /* proto */
static int __pyx_pf_11PyCudaTorch_10CudaTensor___cinit__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args); /* proto */
static void __pyx_pf_11PyCudaTorch_10CudaTensor_2__dealloc__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_4new(); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_6__getitem__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_index); /* proto */
static int __pyx_pf_11PyCudaTorch_10CudaTensor_8__setitem__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_index, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_10__repr__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_12float(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_14copy(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, PyObject *__pyx_v__src); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_16dims(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_18size(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_20nElement(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_22sum(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_24narrow(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_26set1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_28set2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_30get1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_32get2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_34__add__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, float __pyx_v_scalar); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_36__getitem__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_index); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_38resize(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_40resizeAs(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_model); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_42uniform(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, float __pyx_v_a, float __pyx_v_b); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_4getPrediction(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_output); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_6FloatTensorToCudaTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_floatTensor); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_8DoubleTensorToCudaTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_floatTensor); /* proto */
static PyObject *__pyx_pf_11PyCudaTorch_10init(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static int __pyx_pf_7cpython_5array_5array___getbuffer__(arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info, CYTHON_UNUSED int __pyx_v_flags); /* proto */
static void __pyx_pf_7cpython_5array_5array_2__releasebuffer__(CYTHON_UNUSED arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info); /* proto */
static PyObject *__pyx_tp_new_11PyCudaTorch_CudaTensor(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_11PyCudaTorch_CudaGlobalState(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static char __pyx_k_a[] = "a";
static char __pyx_k_b[] = "b";
static char __pyx_k_x0[] = "x0";
static char __pyx_k_x1[] = "x1";
static char __pyx_k_new[] = "new";
static char __pyx_k_copy[] = "copy";
static char __pyx_k_cunn[] = "cunn";
static char __pyx_k_dims[] = "dims";
static char __pyx_k_init[] = "init";
static char __pyx_k_main[] = "__main__";
static char __pyx_k_repr[] = "__repr__";
static char __pyx_k_size[] = "size";
static char __pyx_k_test[] = "__test__";
static char __pyx_k_array[] = "array";
static char __pyx_k_float[] = "float";
static char __pyx_k_get1d[] = "get1d";
static char __pyx_k_get2d[] = "get2d";
static char __pyx_k_print[] = "print";
static char __pyx_k_range[] = "range";
static char __pyx_k_set1d[] = "set1d";
static char __pyx_k_set2d[] = "set2d";
static char __pyx_k_value[] = "value";
static char __pyx_k_import[] = "__import__";
static char __pyx_k_resize[] = "resize";
static char __pyx_k_state2[] = "state2";
static char __pyx_k_tensor[] = "tensor";
static char __pyx_k_PyTorch[] = "PyTorch";
static char __pyx_k_cutorch[] = "cutorch";
static char __pyx_k_replace[] = "replace";
static char __pyx_k_tensorC[] = "tensorC";
static char __pyx_k_uniform[] = "uniform";
static char __pyx_k_allocate[] = "_allocate";
static char __pyx_k_clTensor[] = "clTensor";
static char __pyx_k_nElement[] = "nElement";
static char __pyx_k_Exception[] = "Exception";
static char __pyx_k_dimension[] = "dimension";
static char __pyx_k_CudaTensor[] = "CudaTensor";
static char __pyx_k_firstIndex[] = "firstIndex";
static char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static char __pyx_k_FloatTensor[] = "FloatTensor";
static char __pyx_k_MemoryError[] = "MemoryError";
static char __pyx_k_PyCudaTorch[] = "PyCudaTorch";
static char __pyx_k_floatTensor[] = "floatTensor";
static char __pyx_k_loaded_cunn[] = "loaded cunn";
static char __pyx_k_staticmethod[] = "staticmethod";
static char __pyx_k_getGlobalState[] = "getGlobalState";
static char __pyx_k_loaded_cutorch[] = "loaded cutorch";
static char __pyx_k_cyPopCudaTensor[] = "cyPopCudaTensor";
static char __pyx_k_not_implemented[] = "not implemented";
static char __pyx_k_cyPushCudaTensor[] = "cyPushCudaTensor";
static char __pyx_k_floattensor_patch[] = "floattensor_patch";
static char __pyx_k_type_not_recognized[] = "type not recognized ";
static char __pyx_k_FloatTensorToCudaTensor[] = "FloatTensorToCudaTensor";
static char __pyx_k_PyCudaTorch_initialized[] = " ... PyCudaTorch initialized";
static char __pyx_k_DoubleTensorToCudaTensor[] = "DoubleTensorToCudaTensor";
static char __pyx_k_Not_implemented_for_dims[] = "Not implemented for dims=";
static char __pyx_k_Not_implemented_len_args[] = "Not implemented, len(args)=";
static char __pyx_k_initializing_PyCudaTorch[] = "initializing PyCudaTorch...";
static char __pyx_k_data_norep_git_pycudatorch_PyCu[] = "/data/norep/git/pycudatorch/PyCudaTorch.pyx";
static char __pyx_k_cannot_provide_arguments_to_init[] = "cannot provide arguments to initializer";
static PyObject *__pyx_n_s_CudaTensor;
static PyObject *__pyx_n_s_DoubleTensorToCudaTensor;
static PyObject *__pyx_n_s_Exception;
static PyObject *__pyx_n_s_FloatTensor;
static PyObject *__pyx_n_s_FloatTensorToCudaTensor;
static PyObject *__pyx_n_s_MemoryError;
static PyObject *__pyx_kp_s_Not_implemented_for_dims;
static PyObject *__pyx_kp_s_Not_implemented_len_args;
static PyObject *__pyx_n_s_PyCudaTorch;
static PyObject *__pyx_kp_s_PyCudaTorch_initialized;
static PyObject *__pyx_n_s_PyTorch;
static PyObject *__pyx_n_s_a;
static PyObject *__pyx_n_s_allocate;
static PyObject *__pyx_n_s_array;
static PyObject *__pyx_n_s_b;
static PyObject *__pyx_kp_s_cannot_provide_arguments_to_init;
static PyObject *__pyx_n_s_clTensor;
static PyObject *__pyx_n_s_copy;
static PyObject *__pyx_n_s_cyPopCudaTensor;
static PyObject *__pyx_n_s_cyPushCudaTensor;
static PyObject *__pyx_kp_s_data_norep_git_pycudatorch_PyCu;
static PyObject *__pyx_n_s_dimension;
static PyObject *__pyx_n_s_dims;
static PyObject *__pyx_n_s_firstIndex;
static PyObject *__pyx_n_s_float;
static PyObject *__pyx_n_s_floatTensor;
static PyObject *__pyx_n_s_floattensor_patch;
static PyObject *__pyx_n_s_get1d;
static PyObject *__pyx_n_s_get2d;
static PyObject *__pyx_n_s_getGlobalState;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_init;
static PyObject *__pyx_kp_s_initializing_PyCudaTorch;
static PyObject *__pyx_kp_s_loaded_cunn;
static PyObject *__pyx_kp_s_loaded_cutorch;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_nElement;
static PyObject *__pyx_n_s_new;
static PyObject *__pyx_kp_s_not_implemented;
static PyObject *__pyx_n_s_print;
static PyObject *__pyx_n_s_pyx_vtable;
static PyObject *__pyx_n_s_range;
static PyObject *__pyx_n_s_replace;
static PyObject *__pyx_n_s_repr;
static PyObject *__pyx_n_s_resize;
static PyObject *__pyx_n_s_set1d;
static PyObject *__pyx_n_s_set2d;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_state2;
static PyObject *__pyx_n_s_staticmethod;
static PyObject *__pyx_n_s_tensor;
static PyObject *__pyx_n_s_tensorC;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_kp_s_type_not_recognized;
static PyObject *__pyx_n_s_uniform;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_x0;
static PyObject *__pyx_n_s_x1;
static PyObject *__pyx_tuple_;
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__3;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__5;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_tuple__7;
static PyObject *__pyx_tuple__8;
static PyObject *__pyx_tuple__9;
static PyObject *__pyx_tuple__10;
static PyObject *__pyx_tuple__12;
static PyObject *__pyx_tuple__15;
static PyObject *__pyx_tuple__17;
static PyObject *__pyx_tuple__19;
static PyObject *__pyx_codeobj__11;
static PyObject *__pyx_codeobj__13;
static PyObject *__pyx_codeobj__14;
static PyObject *__pyx_codeobj__16;
static PyObject *__pyx_codeobj__18;
static PyObject *__pyx_codeobj__20;

/* "PyCudaTorch.pyx":63
 *     void pushCudaTensor(THCState *state, lua_State *L, THCudaTensor *tensor)
 * 
 * def cyPopCudaTensor():             # <<<<<<<<<<<<<<
 *     cdef THCudaTensor *tensorC = popCudaTensor(globalState.L)
 *     cdef CudaTensor tensor = CudaTensor_fromNative(tensorC)
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_1cyPopCudaTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_11PyCudaTorch_1cyPopCudaTensor = {"cyPopCudaTensor", (PyCFunction)__pyx_pw_11PyCudaTorch_1cyPopCudaTensor, METH_NOARGS, 0};
static PyObject *__pyx_pw_11PyCudaTorch_1cyPopCudaTensor(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cyPopCudaTensor (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_cyPopCudaTensor(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_cyPopCudaTensor(CYTHON_UNUSED PyObject *__pyx_self) {
  struct THCudaTensor *__pyx_v_tensorC;
  struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_tensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("cyPopCudaTensor", 0);

  /* "PyCudaTorch.pyx":64
 * 
 * def cyPopCudaTensor():
 *     cdef THCudaTensor *tensorC = popCudaTensor(globalState.L)             # <<<<<<<<<<<<<<
 *     cdef CudaTensor tensor = CudaTensor_fromNative(tensorC)
 *     return tensor
 */
  __pyx_v_tensorC = popCudaTensor(__pyx_v_11PyCudaTorch_globalState->L);

  /* "PyCudaTorch.pyx":65
 * def cyPopCudaTensor():
 *     cdef THCudaTensor *tensorC = popCudaTensor(globalState.L)
 *     cdef CudaTensor tensor = CudaTensor_fromNative(tensorC)             # <<<<<<<<<<<<<<
 *     return tensor
 * 
 */
  __pyx_t_1 = __pyx_f_11PyCudaTorch_CudaTensor_fromNative(__pyx_v_tensorC, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 65; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_11PyCudaTorch_CudaTensor))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 65; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_tensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":66
 *     cdef THCudaTensor *tensorC = popCudaTensor(globalState.L)
 *     cdef CudaTensor tensor = CudaTensor_fromNative(tensorC)
 *     return tensor             # <<<<<<<<<<<<<<
 * 
 * def cyPushCudaTensor(CudaTensor tensor):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_tensor));
  __pyx_r = ((PyObject *)__pyx_v_tensor);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":63
 *     void pushCudaTensor(THCState *state, lua_State *L, THCudaTensor *tensor)
 * 
 * def cyPopCudaTensor():             # <<<<<<<<<<<<<<
 *     cdef THCudaTensor *tensorC = popCudaTensor(globalState.L)
 *     cdef CudaTensor tensor = CudaTensor_fromNative(tensorC)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.cyPopCudaTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":68
 *     return tensor
 * 
 * def cyPushCudaTensor(CudaTensor tensor):             # <<<<<<<<<<<<<<
 *     pushCudaTensor(cudaGlobalState.state, globalState.L, tensor.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_3cyPushCudaTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor); /*proto*/
static PyMethodDef __pyx_mdef_11PyCudaTorch_3cyPushCudaTensor = {"cyPushCudaTensor", (PyCFunction)__pyx_pw_11PyCudaTorch_3cyPushCudaTensor, METH_O, 0};
static PyObject *__pyx_pw_11PyCudaTorch_3cyPushCudaTensor(PyObject *__pyx_self, PyObject *__pyx_v_tensor) {
  CYTHON_UNUSED int __pyx_lineno = 0;
  CYTHON_UNUSED const char *__pyx_filename = NULL;
  CYTHON_UNUSED int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cyPushCudaTensor (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_tensor), __pyx_ptype_11PyCudaTorch_CudaTensor, 1, "tensor", 0))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 68; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_pf_11PyCudaTorch_2cyPushCudaTensor(__pyx_self, ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_tensor));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_2cyPushCudaTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_tensor) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cyPushCudaTensor", 0);

  /* "PyCudaTorch.pyx":69
 * 
 * def cyPushCudaTensor(CudaTensor tensor):
 *     pushCudaTensor(cudaGlobalState.state, globalState.L, tensor.native)             # <<<<<<<<<<<<<<
 * 
 * cdef class CudaTensor(object):
 */
  pushCudaTensor(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_11PyCudaTorch_globalState->L, __pyx_v_tensor->native);

  /* "PyCudaTorch.pyx":68
 *     return tensor
 * 
 * def cyPushCudaTensor(CudaTensor tensor):             # <<<<<<<<<<<<<<
 *     pushCudaTensor(cudaGlobalState.state, globalState.L, tensor.native)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":74
 *     cdef THCudaTensor *native
 * 
 *     def __cinit__(CudaTensor self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        print('CudaTensor.__cinit__')
 *         if _allocate:
 */

/* Python wrapper */
static int __pyx_pw_11PyCudaTorch_10CudaTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_11PyCudaTorch_10CudaTensor_1__cinit__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v__allocate = 0;
  PyObject *__pyx_v_args = 0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__cinit__ (wrapper)", 0);
  if (PyTuple_GET_SIZE(__pyx_args) > 0) {
    __pyx_v_args = PyTuple_GetSlice(__pyx_args, 0, PyTuple_GET_SIZE(__pyx_args));
    if (unlikely(!__pyx_v_args)) {
      __Pyx_RefNannyFinishContext();
      return -1;
    }
    __Pyx_GOTREF(__pyx_v_args);
  } else {
    __pyx_v_args = __pyx_empty_tuple; __Pyx_INCREF(__pyx_empty_tuple);
  }
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_allocate,0};
    PyObject* values[1] = {0};
    values[0] = ((PyObject *)Py_True);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        default:
        case  0: break;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      if (kw_args == 1) {
        const Py_ssize_t index = 0;
        PyObject* value = PyDict_GetItem(__pyx_kwds, *__pyx_pyargnames[index]);
        if (value) { values[index] = value; kw_args--; }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, 0, "__cinit__") < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 74; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) < 0) {
      goto __pyx_L5_argtuple_error;
    } else {
    }
    __pyx_v__allocate = values[0];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__cinit__", 0, 0, 0, PyTuple_GET_SIZE(__pyx_args)); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 74; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  __pyx_L3_error:;
  __Pyx_DECREF(__pyx_v_args); __pyx_v_args = 0;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor___cinit__(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), __pyx_v__allocate, __pyx_v_args);

  /* function exit code */
  __Pyx_XDECREF(__pyx_v_args);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_11PyCudaTorch_10CudaTensor___cinit__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, PyObject *__pyx_v__allocate, PyObject *__pyx_v_args) {
  PyObject *__pyx_v_arg = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  long __pyx_t_8;
  long __pyx_t_9;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__cinit__", 0);

  /* "PyCudaTorch.pyx":76
 *     def __cinit__(CudaTensor self, *args, _allocate=True):
 * #        print('CudaTensor.__cinit__')
 *         if _allocate:             # <<<<<<<<<<<<<<
 *             for arg in args:
 *                 if not isinstance(arg, int):
 */
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_v__allocate); if (unlikely(__pyx_t_1 < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 76; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  if (__pyx_t_1) {

    /* "PyCudaTorch.pyx":77
 * #        print('CudaTensor.__cinit__')
 *         if _allocate:
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    __pyx_t_2 = __pyx_v_args; __Pyx_INCREF(__pyx_t_2); __pyx_t_3 = 0;
    for (;;) {
      if (__pyx_t_3 >= PyTuple_GET_SIZE(__pyx_t_2)) break;
      #if CYTHON_COMPILING_IN_CPYTHON
      __pyx_t_4 = PyTuple_GET_ITEM(__pyx_t_2, __pyx_t_3); __Pyx_INCREF(__pyx_t_4); __pyx_t_3++; if (unlikely(0 < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 77; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      #else
      __pyx_t_4 = PySequence_ITEM(__pyx_t_2, __pyx_t_3); __pyx_t_3++; if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 77; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      #endif
      __Pyx_XDECREF_SET(__pyx_v_arg, __pyx_t_4);
      __pyx_t_4 = 0;

      /* "PyCudaTorch.pyx":78
 *         if _allocate:
 *             for arg in args:
 *                 if not isinstance(arg, int):             # <<<<<<<<<<<<<<
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 */
      __pyx_t_1 = PyInt_Check(__pyx_v_arg); 
      __pyx_t_5 = ((!(__pyx_t_1 != 0)) != 0);
      if (__pyx_t_5) {

        /* "PyCudaTorch.pyx":79
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 self.native = THCudaTensor_new(cudaGlobalState.state)
 */
        __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_Exception, __pyx_tuple_, NULL); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 79; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
        __Pyx_GOTREF(__pyx_t_4);
        __Pyx_Raise(__pyx_t_4, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        {__pyx_filename = __pyx_f[0]; __pyx_lineno = 79; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      }

      /* "PyCudaTorch.pyx":77
 * #        print('CudaTensor.__cinit__')
 *         if _allocate:
 *             for arg in args:             # <<<<<<<<<<<<<<
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 */
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "PyCudaTorch.pyx":80
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:             # <<<<<<<<<<<<<<
 *                 self.native = THCudaTensor_new(cudaGlobalState.state)
 *             elif len(args) == 1:
 */
    __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 80; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __pyx_t_5 = ((__pyx_t_3 == 0) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":81
 *                     raise Exception('cannot provide arguments to initializer')
 *             if len(args) == 0:
 *                 self.native = THCudaTensor_new(cudaGlobalState.state)             # <<<<<<<<<<<<<<
 *             elif len(args) == 1:
 *                 self.native = THCudaTensor_newWithSize1d(cudaGlobalState.state, args[0])
 */
      __pyx_v_self->native = THCudaTensor_new(__pyx_v_11PyCudaTorch_cudaGlobalState->state);
      goto __pyx_L7;
    }

    /* "PyCudaTorch.pyx":82
 *             if len(args) == 0:
 *                 self.native = THCudaTensor_new(cudaGlobalState.state)
 *             elif len(args) == 1:             # <<<<<<<<<<<<<<
 *                 self.native = THCudaTensor_newWithSize1d(cudaGlobalState.state, args[0])
 *             elif len(args) == 2:
 */
    __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 82; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __pyx_t_5 = ((__pyx_t_3 == 1) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":83
 *                 self.native = THCudaTensor_new(cudaGlobalState.state)
 *             elif len(args) == 1:
 *                 self.native = THCudaTensor_newWithSize1d(cudaGlobalState.state, args[0])             # <<<<<<<<<<<<<<
 *             elif len(args) == 2:
 *                 self.native = THCudaTensor_newWithSize2d(cudaGlobalState.state, args[0], args[1])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 83; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 83; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THCudaTensor_newWithSize1d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_t_6);
      goto __pyx_L7;
    }

    /* "PyCudaTorch.pyx":84
 *             elif len(args) == 1:
 *                 self.native = THCudaTensor_newWithSize1d(cudaGlobalState.state, args[0])
 *             elif len(args) == 2:             # <<<<<<<<<<<<<<
 *                 self.native = THCudaTensor_newWithSize2d(cudaGlobalState.state, args[0], args[1])
 *             elif len(args) == 3:
 */
    __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 84; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __pyx_t_5 = ((__pyx_t_3 == 2) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":85
 *                 self.native = THCudaTensor_newWithSize1d(cudaGlobalState.state, args[0])
 *             elif len(args) == 2:
 *                 self.native = THCudaTensor_newWithSize2d(cudaGlobalState.state, args[0], args[1])             # <<<<<<<<<<<<<<
 *             elif len(args) == 3:
 *                 self.native = THCudaTensor_newWithSize3d(cudaGlobalState.state, args[0], args[1], args[2])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 85; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 85; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 85; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 85; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THCudaTensor_newWithSize2d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_t_6, __pyx_t_7);
      goto __pyx_L7;
    }

    /* "PyCudaTorch.pyx":86
 *             elif len(args) == 2:
 *                 self.native = THCudaTensor_newWithSize2d(cudaGlobalState.state, args[0], args[1])
 *             elif len(args) == 3:             # <<<<<<<<<<<<<<
 *                 self.native = THCudaTensor_newWithSize3d(cudaGlobalState.state, args[0], args[1], args[2])
 *             elif len(args) == 4:
 */
    __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 86; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __pyx_t_5 = ((__pyx_t_3 == 3) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":87
 *                 self.native = THCudaTensor_newWithSize2d(cudaGlobalState.state, args[0], args[1])
 *             elif len(args) == 3:
 *                 self.native = THCudaTensor_newWithSize3d(cudaGlobalState.state, args[0], args[1], args[2])             # <<<<<<<<<<<<<<
 *             elif len(args) == 4:
 *                 self.native = THCudaTensor_newWithSize4d(cudaGlobalState.state, args[0], args[1], args[2], args[3])
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_8 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_8 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THCudaTensor_newWithSize3d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_t_7, __pyx_t_6, __pyx_t_8);
      goto __pyx_L7;
    }

    /* "PyCudaTorch.pyx":88
 *             elif len(args) == 3:
 *                 self.native = THCudaTensor_newWithSize3d(cudaGlobalState.state, args[0], args[1], args[2])
 *             elif len(args) == 4:             # <<<<<<<<<<<<<<
 *                 self.native = THCudaTensor_newWithSize4d(cudaGlobalState.state, args[0], args[1], args[2], args[3])
 *             else:
 */
    __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 88; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __pyx_t_5 = ((__pyx_t_3 == 4) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":89
 *                 self.native = THCudaTensor_newWithSize3d(cudaGlobalState.state, args[0], args[1], args[2])
 *             elif len(args) == 4:
 *                 self.native = THCudaTensor_newWithSize4d(cudaGlobalState.state, args[0], args[1], args[2], args[3])             # <<<<<<<<<<<<<<
 *             else:
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 */
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_8 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_8 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt_Tuple(__pyx_v_args, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_9 = __Pyx_PyInt_As_long(__pyx_t_2); if (unlikely((__pyx_t_9 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 89; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_self->native = THCudaTensor_newWithSize4d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_t_8, __pyx_t_6, __pyx_t_7, __pyx_t_9);
      goto __pyx_L7;
    }
    /*else*/ {

      /* "PyCudaTorch.pyx":91
 *                 self.native = THCudaTensor_newWithSize4d(cudaGlobalState.state, args[0], args[1], args[2], args[3])
 *             else:
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(CudaTensor self):
 */
      __pyx_t_3 = PyTuple_GET_SIZE(__pyx_v_args); if (unlikely(__pyx_t_3 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __pyx_t_2 = PyInt_FromSsize_t(__pyx_t_3); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)(&PyString_Type))), __pyx_t_4, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_4 = PyNumber_Add(__pyx_kp_s_Not_implemented_len_args, __pyx_t_2); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      __pyx_t_4 = 0;
      __pyx_t_4 = __Pyx_PyObject_Call(__pyx_builtin_Exception, __pyx_t_2, NULL); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_Raise(__pyx_t_4, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      {__pyx_filename = __pyx_f[0]; __pyx_lineno = 91; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    }
    __pyx_L7:;
    goto __pyx_L3;
  }
  __pyx_L3:;

  /* "PyCudaTorch.pyx":74
 *     cdef THCudaTensor *native
 * 
 *     def __cinit__(CudaTensor self, *args, _allocate=True):             # <<<<<<<<<<<<<<
 * #        print('CudaTensor.__cinit__')
 *         if _allocate:
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__cinit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_arg);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":93
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * 
 *     def __dealloc__(CudaTensor self):             # <<<<<<<<<<<<<<
 * #        print('CudaTensor.__dealloc__')
 *         THCudaTensor_free(cudaGlobalState.state, self.native)
 */

/* Python wrapper */
static void __pyx_pw_11PyCudaTorch_10CudaTensor_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_11PyCudaTorch_10CudaTensor_3__dealloc__(PyObject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_pf_11PyCudaTorch_10CudaTensor_2__dealloc__(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_11PyCudaTorch_10CudaTensor_2__dealloc__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "PyCudaTorch.pyx":95
 *     def __dealloc__(CudaTensor self):
 * #        print('CudaTensor.__dealloc__')
 *         THCudaTensor_free(cudaGlobalState.state, self.native)             # <<<<<<<<<<<<<<
 * 
 *     @staticmethod
 */
  THCudaTensor_free(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native);

  /* "PyCudaTorch.pyx":93
 *                 raise Exception('Not implemented, len(args)=' + str(len(args)))
 * 
 *     def __dealloc__(CudaTensor self):             # <<<<<<<<<<<<<<
 * #        print('CudaTensor.__dealloc__')
 *         THCudaTensor_free(cudaGlobalState.state, self.native)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "PyCudaTorch.pyx":98
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 *         return CudaTensor()
 * #        cdef THCudaTensor *newTensorC = THCudaTensor_new(cudaGlobalState.state)
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_5new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_11PyCudaTorch_10CudaTensor_5new = {"new", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_5new, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_5new(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("new (wrapper)", 0);
  if (unlikely(PyTuple_GET_SIZE(__pyx_args) > 0)) {
    __Pyx_RaiseArgtupleInvalid("new", 1, 0, 0, PyTuple_GET_SIZE(__pyx_args)); return NULL;}
  if (unlikely(__pyx_kwds) && unlikely(PyDict_Size(__pyx_kwds) > 0) && unlikely(!__Pyx_CheckKeywordStrings(__pyx_kwds, "new", 0))) return NULL;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_4new();

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_4new() {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("new", 0);

  /* "PyCudaTorch.pyx":99
 *     @staticmethod
 *     def new():
 *         return CudaTensor()             # <<<<<<<<<<<<<<
 * #        cdef THCudaTensor *newTensorC = THCudaTensor_new(cudaGlobalState.state)
 * #        return CudaTensor_fromNative(newTensorC, False)
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 99; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":98
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 *         return CudaTensor()
 * #        cdef THCudaTensor *newTensorC = THCudaTensor_new(cudaGlobalState.state)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.new", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":103
 * #        return CudaTensor_fromNative(newTensorC, False)
 * 
 *     def __getitem__(CudaTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_7__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_7__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index) {
  int __pyx_v_index;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 103; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_6__getitem__(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((int)__pyx_v_index));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_6__getitem__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_index) {
  struct THCudaTensor *__pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_11PyCudaTorch_CudaTensor_fromNative __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "PyCudaTorch.pyx":104
 * 
 *     def __getitem__(CudaTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyCudaTorch.pyx":105
 *     def __getitem__(CudaTensor self, int index):
 *         if self.dims() == 1:
 *             return self.get1d(index)             # <<<<<<<<<<<<<<
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)
 *         return CudaTensor_fromNative(res, False)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = PyFloat_FromDouble(((struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_index, 0)); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 105; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":106
 *         if self.dims() == 1:
 *             return self.get1d(index)
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)             # <<<<<<<<<<<<<<
 *         return CudaTensor_fromNative(res, False)
 * 
 */
  __pyx_v_res = THCudaTensor_newSelect(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, 0, __pyx_v_index);

  /* "PyCudaTorch.pyx":107
 *             return self.get1d(index)
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)
 *         return CudaTensor_fromNative(res, False)             # <<<<<<<<<<<<<<
 * 
 *     def __setitem__(CudaTensor self, int index, float value):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_11PyCudaTorch_CudaTensor_fromNative(__pyx_v_res, &__pyx_t_3); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 107; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":103
 * #        return CudaTensor_fromNative(newTensorC, False)
 * 
 *     def __getitem__(CudaTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":109
 *         return CudaTensor_fromNative(res, False)
 * 
 *     def __setitem__(CudaTensor self, int index, float value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

/* Python wrapper */
static int __pyx_pw_11PyCudaTorch_10CudaTensor_9__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value); /*proto*/
static int __pyx_pw_11PyCudaTorch_10CudaTensor_9__setitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index, PyObject *__pyx_arg_value) {
  int __pyx_v_index;
  float __pyx_v_value;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 109; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  assert(__pyx_arg_value); {
    __pyx_v_value = __pyx_PyFloat_AsFloat(__pyx_arg_value); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 109; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_8__setitem__(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((int)__pyx_v_index), ((float)__pyx_v_value));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_11PyCudaTorch_10CudaTensor_8__setitem__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_index, float __pyx_v_value) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__setitem__", 0);

  /* "PyCudaTorch.pyx":110
 * 
 *     def __setitem__(CudaTensor self, int index, float value):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             self.set1d(index, value)
 *         else:
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyCudaTorch.pyx":111
 *     def __setitem__(CudaTensor self, int index, float value):
 *         if self.dims() == 1:
 *             self.set1d(index, value)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception("not implemented")
 */
    __pyx_t_2 = ((struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *)__pyx_v_self->__pyx_vtab)->set1d(__pyx_v_self, __pyx_v_index, __pyx_v_value, 0); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 111; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    goto __pyx_L3;
  }
  /*else*/ {

    /* "PyCudaTorch.pyx":113
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(CudaTensor self):
 */
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_builtin_Exception, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 113; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    {__pyx_filename = __pyx_f[0]; __pyx_lineno = 113; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __pyx_L3:;

  /* "PyCudaTorch.pyx":109
 *         return CudaTensor_fromNative(res, False)
 * 
 *     def __setitem__(CudaTensor self, int index, float value):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             self.set1d(index, value)
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__setitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":115
 *             raise Exception("not implemented")
 * 
 *     def __repr__(CudaTensor self):             # <<<<<<<<<<<<<<
 *         cdef PyTorch._FloatTensor floatTensor = self.float()
 *         floatRepr = floatTensor.__repr__()
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_11__repr__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_11__repr__(PyObject *__pyx_v_self) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__repr__ (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_10__repr__(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_10__repr__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_floatTensor = 0;
  PyObject *__pyx_v_floatRepr = NULL;
  PyObject *__pyx_v_cudaRepr = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__repr__", 0);

  /* "PyCudaTorch.pyx":116
 * 
 *     def __repr__(CudaTensor self):
 *         cdef PyTorch._FloatTensor floatTensor = self.float()             # <<<<<<<<<<<<<<
 *         floatRepr = floatTensor.__repr__()
 *         cudaRepr = floatRepr.replace('FloatTensor', 'CudaTensor')
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_float); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 116; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 116; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 116; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 116; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_floatTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":117
 *     def __repr__(CudaTensor self):
 *         cdef PyTorch._FloatTensor floatTensor = self.float()
 *         floatRepr = floatTensor.__repr__()             # <<<<<<<<<<<<<<
 *         cudaRepr = floatRepr.replace('FloatTensor', 'CudaTensor')
 *         return cudaRepr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_floatTensor), __pyx_n_s_repr); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 117; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 117; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 117; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_floatRepr = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":118
 *         cdef PyTorch._FloatTensor floatTensor = self.float()
 *         floatRepr = floatTensor.__repr__()
 *         cudaRepr = floatRepr.replace('FloatTensor', 'CudaTensor')             # <<<<<<<<<<<<<<
 *         return cudaRepr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_floatRepr, __pyx_n_s_replace); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 118; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 118; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_cudaRepr = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "PyCudaTorch.pyx":119
 *         floatRepr = floatTensor.__repr__()
 *         cudaRepr = floatRepr.replace('FloatTensor', 'CudaTensor')
 *         return cudaRepr             # <<<<<<<<<<<<<<
 * 
 *     def float(CudaTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_cudaRepr);
  __pyx_r = __pyx_v_cudaRepr;
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":115
 *             raise Exception("not implemented")
 * 
 *     def __repr__(CudaTensor self):             # <<<<<<<<<<<<<<
 *         cdef PyTorch._FloatTensor floatTensor = self.float()
 *         floatRepr = floatTensor.__repr__()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__repr__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_floatTensor);
  __Pyx_XDECREF(__pyx_v_floatRepr);
  __Pyx_XDECREF(__pyx_v_cudaRepr);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":121
 *         return cudaRepr
 * 
 *     def float(CudaTensor self):             # <<<<<<<<<<<<<<
 *         cdef PyTorch._FloatTensor floatTensor = PyTorch._FloatTensor.new()
 *         cdef Storage._LongStorage size = self.size()
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_13float(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_13float(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("float (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_12float(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_12float(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_floatTensor = 0;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("float", 0);

  /* "PyCudaTorch.pyx":122
 * 
 *     def float(CudaTensor self):
 *         cdef PyTorch._FloatTensor floatTensor = PyTorch._FloatTensor.new()             # <<<<<<<<<<<<<<
 *         cdef Storage._LongStorage size = self.size()
 *         if size is None:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)((PyObject*)__pyx_ptype_7PyTorch__FloatTensor)), __pyx_n_s_new); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 122; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 122; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 122; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch__FloatTensor))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 122; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_floatTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":123
 *     def float(CudaTensor self):
 *         cdef PyTorch._FloatTensor floatTensor = PyTorch._FloatTensor.new()
 *         cdef Storage._LongStorage size = self.size()             # <<<<<<<<<<<<<<
 *         if size is None:
 *             return PyTorch._FloatTensor()
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 123; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 123; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 123; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7Storage__LongStorage))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 123; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":124
 *         cdef PyTorch._FloatTensor floatTensor = PyTorch._FloatTensor.new()
 *         cdef Storage._LongStorage size = self.size()
 *         if size is None:             # <<<<<<<<<<<<<<
 *             return PyTorch._FloatTensor()
 *         if len(size) == 0:
 */
  __pyx_t_4 = (((PyObject *)__pyx_v_size) == Py_None);
  __pyx_t_5 = (__pyx_t_4 != 0);
  if (__pyx_t_5) {

    /* "PyCudaTorch.pyx":125
 *         cdef Storage._LongStorage size = self.size()
 *         if size is None:
 *             return PyTorch._FloatTensor()             # <<<<<<<<<<<<<<
 *         if len(size) == 0:
 *             return PyTorch._FloatTensor()
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_7PyTorch__FloatTensor)), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 125; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":126
 *         if size is None:
 *             return PyTorch._FloatTensor()
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return PyTorch._FloatTensor()
 *         floatTensor.resize(size)
 */
  __pyx_t_6 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_6 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 126; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_t_5 = ((__pyx_t_6 == 0) != 0);
  if (__pyx_t_5) {

    /* "PyCudaTorch.pyx":127
 *             return PyTorch._FloatTensor()
 *         if len(size) == 0:
 *             return PyTorch._FloatTensor()             # <<<<<<<<<<<<<<
 *         floatTensor.resize(size)
 *         THFloatTensor_copyCuda(cudaGlobalState.state, floatTensor.native, self.native)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_7PyTorch__FloatTensor)), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 127; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_r = __pyx_t_1;
    __pyx_t_1 = 0;
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":128
 *         if len(size) == 0:
 *             return PyTorch._FloatTensor()
 *         floatTensor.resize(size)             # <<<<<<<<<<<<<<
 *         THFloatTensor_copyCuda(cudaGlobalState.state, floatTensor.native, self.native)
 *         return floatTensor
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_floatTensor), __pyx_n_s_resize); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 128; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (!__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, ((PyObject *)__pyx_v_size)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 128; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 128; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_7);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_3); __Pyx_GIVEREF(__pyx_t_3); __pyx_t_3 = NULL;
    __Pyx_INCREF(((PyObject *)__pyx_v_size));
    PyTuple_SET_ITEM(__pyx_t_7, 0+1, ((PyObject *)__pyx_v_size));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_size));
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 128; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":129
 *             return PyTorch._FloatTensor()
 *         floatTensor.resize(size)
 *         THFloatTensor_copyCuda(cudaGlobalState.state, floatTensor.native, self.native)             # <<<<<<<<<<<<<<
 *         return floatTensor
 * 
 */
  THFloatTensor_copyCuda(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_floatTensor->native, __pyx_v_self->native);

  /* "PyCudaTorch.pyx":130
 *         floatTensor.resize(size)
 *         THFloatTensor_copyCuda(cudaGlobalState.state, floatTensor.native, self.native)
 *         return floatTensor             # <<<<<<<<<<<<<<
 * 
 *     def copy(CudaTensor self, _src):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_floatTensor));
  __pyx_r = ((PyObject *)__pyx_v_floatTensor);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":121
 *         return cudaRepr
 * 
 *     def float(CudaTensor self):             # <<<<<<<<<<<<<<
 *         cdef PyTorch._FloatTensor floatTensor = PyTorch._FloatTensor.new()
 *         cdef Storage._LongStorage size = self.size()
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.float", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_floatTensor);
  __Pyx_XDECREF((PyObject *)__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":132
 *         return floatTensor
 * 
 *     def copy(CudaTensor self, _src):             # <<<<<<<<<<<<<<
 *         cdef PyTorch._FloatTensor fsrc
 *         cdef PyTorch._DoubleTensor dsrc
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_15copy(PyObject *__pyx_v_self, PyObject *__pyx_v__src); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_15copy(PyObject *__pyx_v_self, PyObject *__pyx_v__src) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("copy (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_14copy(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((PyObject *)__pyx_v__src));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_14copy(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, PyObject *__pyx_v__src) {
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_fsrc = 0;
  struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_dsrc = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("copy", 0);

  /* "PyCudaTorch.pyx":135
 *         cdef PyTorch._FloatTensor fsrc
 *         cdef PyTorch._DoubleTensor dsrc
 *         if isinstance(_src, PyTorch._FloatTensor):             # <<<<<<<<<<<<<<
 *             fsrc = _src
 *             THCudaTensor_copyFloat(cudaGlobalState.state, self.native, fsrc.native)
 */
  __pyx_t_1 = __Pyx_TypeCheck(__pyx_v__src, ((PyObject*)__pyx_ptype_7PyTorch__FloatTensor)); 
  __pyx_t_2 = (__pyx_t_1 != 0);
  if (__pyx_t_2) {

    /* "PyCudaTorch.pyx":136
 *         cdef PyTorch._DoubleTensor dsrc
 *         if isinstance(_src, PyTorch._FloatTensor):
 *             fsrc = _src             # <<<<<<<<<<<<<<
 *             THCudaTensor_copyFloat(cudaGlobalState.state, self.native, fsrc.native)
 *         elif isinstance(_src, PyTorch._DoubleTensor):
 */
    if (!(likely(((__pyx_v__src) == Py_None) || likely(__Pyx_TypeTest(__pyx_v__src, __pyx_ptype_7PyTorch__FloatTensor))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 136; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __pyx_t_3 = __pyx_v__src;
    __Pyx_INCREF(__pyx_t_3);
    __pyx_v_fsrc = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "PyCudaTorch.pyx":137
 *         if isinstance(_src, PyTorch._FloatTensor):
 *             fsrc = _src
 *             THCudaTensor_copyFloat(cudaGlobalState.state, self.native, fsrc.native)             # <<<<<<<<<<<<<<
 *         elif isinstance(_src, PyTorch._DoubleTensor):
 *             dsrc = _src
 */
    THCudaTensor_copyFloat(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_fsrc->native);
    goto __pyx_L3;
  }

  /* "PyCudaTorch.pyx":138
 *             fsrc = _src
 *             THCudaTensor_copyFloat(cudaGlobalState.state, self.native, fsrc.native)
 *         elif isinstance(_src, PyTorch._DoubleTensor):             # <<<<<<<<<<<<<<
 *             dsrc = _src
 *             THCudaTensor_copyDouble(cudaGlobalState.state, self.native, dsrc.native)
 */
  __pyx_t_2 = __Pyx_TypeCheck(__pyx_v__src, ((PyObject*)__pyx_ptype_7PyTorch__DoubleTensor)); 
  __pyx_t_1 = (__pyx_t_2 != 0);
  if (__pyx_t_1) {

    /* "PyCudaTorch.pyx":139
 *             THCudaTensor_copyFloat(cudaGlobalState.state, self.native, fsrc.native)
 *         elif isinstance(_src, PyTorch._DoubleTensor):
 *             dsrc = _src             # <<<<<<<<<<<<<<
 *             THCudaTensor_copyDouble(cudaGlobalState.state, self.native, dsrc.native)
 *         else:
 */
    if (!(likely(((__pyx_v__src) == Py_None) || likely(__Pyx_TypeTest(__pyx_v__src, __pyx_ptype_7PyTorch__DoubleTensor))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 139; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __pyx_t_3 = __pyx_v__src;
    __Pyx_INCREF(__pyx_t_3);
    __pyx_v_dsrc = ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_t_3);
    __pyx_t_3 = 0;

    /* "PyCudaTorch.pyx":140
 *         elif isinstance(_src, PyTorch._DoubleTensor):
 *             dsrc = _src
 *             THCudaTensor_copyDouble(cudaGlobalState.state, self.native, dsrc.native)             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('type not recognized ' + str(type(_src)))
 */
    THCudaTensor_copyDouble(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_dsrc->native);
    goto __pyx_L3;
  }
  /*else*/ {

    /* "PyCudaTorch.pyx":142
 *             THCudaTensor_copyDouble(cudaGlobalState.state, self.native, dsrc.native)
 *         else:
 *             raise Exception('type not recognized ' + str(type(_src)))             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 142; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v__src)));
    PyTuple_SET_ITEM(__pyx_t_3, 0, ((PyObject *)Py_TYPE(__pyx_v__src)));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v__src)));
    __pyx_t_4 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)(&PyString_Type))), __pyx_t_3, NULL); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 142; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyNumber_Add(__pyx_kp_s_type_not_recognized, __pyx_t_4); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 142; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 142; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_Exception, __pyx_t_4, NULL); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 142; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    {__pyx_filename = __pyx_f[0]; __pyx_lineno = 142; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __pyx_L3:;

  /* "PyCudaTorch.pyx":143
 *         else:
 *             raise Exception('type not recognized ' + str(type(_src)))
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     cpdef int dims(CudaTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":132
 *         return floatTensor
 * 
 *     def copy(CudaTensor self, _src):             # <<<<<<<<<<<<<<
 *         cdef PyTorch._FloatTensor fsrc
 *         cdef PyTorch._DoubleTensor dsrc
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_fsrc);
  __Pyx_XDECREF((PyObject *)__pyx_v_dsrc);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":145
 *         return self
 * 
 *     cpdef int dims(CudaTensor self):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_nDimension(cudaGlobalState.state, self.native)
 * 
 */

static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_17dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_11PyCudaTorch_10CudaTensor_dims(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_skip_dispatch) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("dims", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_dims); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 145; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_17dims)) {
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_3 = __pyx_t_1; __pyx_t_4 = NULL;
      if (CYTHON_COMPILING_IN_CPYTHON && unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        if (likely(__pyx_t_4)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
          __Pyx_INCREF(__pyx_t_4);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_3, function);
        }
      }
      if (__pyx_t_4) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_4); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 145; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      } else {
        __pyx_t_2 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 145; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      }
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 145; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_5;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyCudaTorch.pyx":146
 * 
 *     cpdef int dims(CudaTensor self):
 *         return THCudaTensor_nDimension(cudaGlobalState.state, self.native)             # <<<<<<<<<<<<<<
 * 
 *     def size(CudaTensor self):
 */
  __pyx_r = THCudaTensor_nDimension(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":145
 *         return self
 * 
 *     cpdef int dims(CudaTensor self):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_nDimension(cudaGlobalState.state, self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_WriteUnraisable("PyCudaTorch.CudaTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_17dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_17dims(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("dims (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_16dims(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_16dims(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("dims", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_11PyCudaTorch_10CudaTensor_dims(__pyx_v_self, 1)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 145; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.dims", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":148
 *         return THCudaTensor_nDimension(cudaGlobalState.state, self.native)
 * 
 *     def size(CudaTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 *         cdef Storage._LongStorage size
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_19size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_19size(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("size (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_18size(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_18size(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self) {
  int __pyx_v_dims;
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  int __pyx_v_d;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("size", 0);

  /* "PyCudaTorch.pyx":149
 * 
 *     def size(CudaTensor self):
 *         cdef int dims = self.dims()             # <<<<<<<<<<<<<<
 *         cdef Storage._LongStorage size
 * #        print('cltensor.size long versoin')
 */
  __pyx_v_dims = ((struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0);

  /* "PyCudaTorch.pyx":152
 *         cdef Storage._LongStorage size
 * #        print('cltensor.size long versoin')
 *         if dims >= 0:             # <<<<<<<<<<<<<<
 *             size = Storage._LongStorage(dims)
 *             for d in range(dims):
 */
  __pyx_t_1 = ((__pyx_v_dims >= 0) != 0);
  if (__pyx_t_1) {

    /* "PyCudaTorch.pyx":153
 * #        print('cltensor.size long versoin')
 *         if dims >= 0:
 *             size = Storage._LongStorage(dims)             # <<<<<<<<<<<<<<
 *             for d in range(dims):
 *                 size[d] = THCudaTensor_size(cudaGlobalState.state, self.native, d)
 */
    __pyx_t_2 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 153; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 153; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_2);
    __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_7Storage__LongStorage)), __pyx_t_3, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 153; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)__pyx_t_2);
    __pyx_t_2 = 0;

    /* "PyCudaTorch.pyx":154
 *         if dims >= 0:
 *             size = Storage._LongStorage(dims)
 *             for d in range(dims):             # <<<<<<<<<<<<<<
 *                 size[d] = THCudaTensor_size(cudaGlobalState.state, self.native, d)
 *             return size
 */
    __pyx_t_4 = __pyx_v_dims;
    for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
      __pyx_v_d = __pyx_t_5;

      /* "PyCudaTorch.pyx":155
 *             size = Storage._LongStorage(dims)
 *             for d in range(dims):
 *                 size[d] = THCudaTensor_size(cudaGlobalState.state, self.native, d)             # <<<<<<<<<<<<<<
 *             return size
 *         else:
 */
      __pyx_t_2 = __Pyx_PyInt_From_long(THCudaTensor_size(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_d)); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 155; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(__Pyx_SetItemInt(((PyObject *)__pyx_v_size), __pyx_v_d, __pyx_t_2, int, 1, __Pyx_PyInt_From_int, 0, 1, 1) < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 155; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    }

    /* "PyCudaTorch.pyx":156
 *             for d in range(dims):
 *                 size[d] = THCudaTensor_size(cudaGlobalState.state, self.native, d)
 *             return size             # <<<<<<<<<<<<<<
 *         else:
 *             return None  # not sure how to handle this yet
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_size));
    __pyx_r = ((PyObject *)__pyx_v_size);
    goto __pyx_L0;
  }
  /*else*/ {

    /* "PyCudaTorch.pyx":158
 *             return size
 *         else:
 *             return None  # not sure how to handle this yet             # <<<<<<<<<<<<<<
 * 
 *     def nElement(CudaTensor self):
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(Py_None);
    __pyx_r = Py_None;
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":148
 *         return THCudaTensor_nDimension(cudaGlobalState.state, self.native)
 * 
 *     def size(CudaTensor self):             # <<<<<<<<<<<<<<
 *         cdef int dims = self.dims()
 *         cdef Storage._LongStorage size
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.size", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":160
 *             return None  # not sure how to handle this yet
 * 
 *     def nElement(CudaTensor self):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_nElement(cudaGlobalState.state, self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_21nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_21nElement(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("nElement (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_20nElement(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_20nElement(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("nElement", 0);

  /* "PyCudaTorch.pyx":161
 * 
 *     def nElement(CudaTensor self):
 *         return THCudaTensor_nElement(cudaGlobalState.state, self.native)             # <<<<<<<<<<<<<<
 * 
 *     def sum(CudaTensor self):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_long(THCudaTensor_nElement(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 161; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":160
 *             return None  # not sure how to handle this yet
 * 
 *     def nElement(CudaTensor self):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_nElement(cudaGlobalState.state, self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.nElement", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":163
 *         return THCudaTensor_nElement(cudaGlobalState.state, self.native)
 * 
 *     def sum(CudaTensor self):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_sumall(cudaGlobalState.state, self.native)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_23sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_23sum(PyObject *__pyx_v_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("sum (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_22sum(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_22sum(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("sum", 0);

  /* "PyCudaTorch.pyx":164
 * 
 *     def sum(CudaTensor self):
 *         return THCudaTensor_sumall(cudaGlobalState.state, self.native)             # <<<<<<<<<<<<<<
 * 
 *     def narrow(CudaTensor self, int dimension, long firstIndex, long size):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(THCudaTensor_sumall(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 164; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":163
 *         return THCudaTensor_nElement(cudaGlobalState.state, self.native)
 * 
 *     def sum(CudaTensor self):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_sumall(cudaGlobalState.state, self.native)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.sum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":166
 *         return THCudaTensor_sumall(cudaGlobalState.state, self.native)
 * 
 *     def narrow(CudaTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THCudaTensor *narrowedC = THCudaTensor_newNarrow(cudaGlobalState.state, self.native, dimension, firstIndex, size)
 *         return CudaTensor_fromNative(narrowedC, retain=False)
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_25narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_25narrow(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_dimension;
  long __pyx_v_firstIndex;
  long __pyx_v_size;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("narrow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_dimension,&__pyx_n_s_firstIndex,&__pyx_n_s_size,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dimension)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_firstIndex)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 1); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 166; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, 2); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 166; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "narrow") < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 166; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_dimension = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_dimension == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 166; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    __pyx_v_firstIndex = __Pyx_PyInt_As_long(values[1]); if (unlikely((__pyx_v_firstIndex == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 166; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    __pyx_v_size = __Pyx_PyInt_As_long(values[2]); if (unlikely((__pyx_v_size == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 166; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("narrow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 166; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_24narrow(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_24narrow(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_dimension, long __pyx_v_firstIndex, long __pyx_v_size) {
  struct THCudaTensor *__pyx_v_narrowedC;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  struct __pyx_opt_args_11PyCudaTorch_CudaTensor_fromNative __pyx_t_2;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("narrow", 0);

  /* "PyCudaTorch.pyx":167
 * 
 *     def narrow(CudaTensor self, int dimension, long firstIndex, long size):
 *         cdef THCudaTensor *narrowedC = THCudaTensor_newNarrow(cudaGlobalState.state, self.native, dimension, firstIndex, size)             # <<<<<<<<<<<<<<
 *         return CudaTensor_fromNative(narrowedC, retain=False)
 * 
 */
  __pyx_v_narrowedC = THCudaTensor_newNarrow(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_dimension, __pyx_v_firstIndex, __pyx_v_size);

  /* "PyCudaTorch.pyx":168
 *     def narrow(CudaTensor self, int dimension, long firstIndex, long size):
 *         cdef THCudaTensor *narrowedC = THCudaTensor_newNarrow(cudaGlobalState.state, self.native, dimension, firstIndex, size)
 *         return CudaTensor_fromNative(narrowedC, retain=False)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set1d(self, int x0, float value):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.retain = Py_False;
  __pyx_t_1 = __pyx_f_11PyCudaTorch_CudaTensor_fromNative(__pyx_v_narrowedC, &__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 168; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":166
 *         return THCudaTensor_sumall(cudaGlobalState.state, self.native)
 * 
 *     def narrow(CudaTensor self, int dimension, long firstIndex, long size):             # <<<<<<<<<<<<<<
 *         cdef THCudaTensor *narrowedC = THCudaTensor_newNarrow(cudaGlobalState.state, self.native, dimension, firstIndex, size)
 *         return CudaTensor_fromNative(narrowedC, retain=False)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.narrow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":170
 *         return CudaTensor_fromNative(narrowedC, retain=False)
 * 
 *     cpdef set1d(self, int x0, float value):             # <<<<<<<<<<<<<<
 *         THCudaTensor_set1d(cudaGlobalState.state, self.native, x0, value)
 * 
 */

static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_27set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_11PyCudaTorch_10CudaTensor_set1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  Py_ssize_t __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("set1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set1d); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_27set1d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = PyFloat_FromDouble(__pyx_v_value); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_COMPILING_IN_CPYTHON && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_6) {
        PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __Pyx_GIVEREF(__pyx_t_6); __pyx_t_6 = NULL;
      }
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      __pyx_t_3 = 0;
      __pyx_t_4 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyCudaTorch.pyx":171
 * 
 *     cpdef set1d(self, int x0, float value):
 *         THCudaTensor_set1d(cudaGlobalState.state, self.native, x0, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef set2d(self, int x0, int x1, float value):
 */
  THCudaTensor_set1d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_x0, __pyx_v_value);

  /* "PyCudaTorch.pyx":170
 *         return CudaTensor_fromNative(narrowedC, retain=False)
 * 
 *     cpdef set1d(self, int x0, float value):             # <<<<<<<<<<<<<<
 *         THCudaTensor_set1d(cudaGlobalState.state, self.native, x0, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_27set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_27set1d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  float __pyx_v_value;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set1d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, 1); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set1d") < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    __pyx_v_value = __pyx_PyFloat_AsFloat(values[1]); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set1d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_26set1d(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_26set1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, float __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("set1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_11PyCudaTorch_10CudaTensor_set1d(__pyx_v_self, __pyx_v_x0, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 170; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.set1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":173
 *         THCudaTensor_set1d(cudaGlobalState.state, self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, float value):             # <<<<<<<<<<<<<<
 *         THCudaTensor_set2d(cudaGlobalState.state, self.native, x0, x1, value)
 * 
 */

static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_29set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_f_11PyCudaTorch_10CudaTensor_set2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value, int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  Py_ssize_t __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("set2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_set2d); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_29set2d)) {
      __Pyx_XDECREF(__pyx_r);
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_5 = PyFloat_FromDouble(__pyx_v_value); if (unlikely(!__pyx_t_5)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_6 = __pyx_t_1; __pyx_t_7 = NULL;
      __pyx_t_8 = 0;
      if (CYTHON_COMPILING_IN_CPYTHON && unlikely(PyMethod_Check(__pyx_t_6))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_6);
        if (likely(__pyx_t_7)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
          __Pyx_INCREF(__pyx_t_7);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_6, function);
          __pyx_t_8 = 1;
        }
      }
      __pyx_t_9 = PyTuple_New(3+__pyx_t_8); if (unlikely(!__pyx_t_9)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_9);
      if (__pyx_t_7) {
        PyTuple_SET_ITEM(__pyx_t_9, 0, __pyx_t_7); __Pyx_GIVEREF(__pyx_t_7); __pyx_t_7 = NULL;
      }
      PyTuple_SET_ITEM(__pyx_t_9, 0+__pyx_t_8, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_9, 1+__pyx_t_8, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_9, 2+__pyx_t_8, __pyx_t_5);
      __Pyx_GIVEREF(__pyx_t_5);
      __pyx_t_3 = 0;
      __pyx_t_4 = 0;
      __pyx_t_5 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_9, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_r = __pyx_t_2;
      __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyCudaTorch.pyx":174
 * 
 *     cpdef set2d(self, int x0, int x1, float value):
 *         THCudaTensor_set2d(cudaGlobalState.state, self.native, x0, x1, value)             # <<<<<<<<<<<<<<
 * 
 *     cpdef float get1d(self, int x0):
 */
  THCudaTensor_set2d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* "PyCudaTorch.pyx":173
 *         THCudaTensor_set1d(cudaGlobalState.state, self.native, x0, value)
 * 
 *     cpdef set2d(self, int x0, int x1, float value):             # <<<<<<<<<<<<<<
 *         THCudaTensor_set2d(cudaGlobalState.state, self.native, x0, x1, value)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_29set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_29set2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  float __pyx_v_value;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("set2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,&__pyx_n_s_value,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 1); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
        }
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, 2); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "set2d") < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    __pyx_v_value = __pyx_PyFloat_AsFloat(values[2]); if (unlikely((__pyx_v_value == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("set2d", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_28set2d(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1, __pyx_v_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_28set2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, float __pyx_v_value) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("set2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_11PyCudaTorch_10CudaTensor_set2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, __pyx_v_value, 1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 173; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.set2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":176
 *         THCudaTensor_set2d(cudaGlobalState.state, self.native, x0, x1, value)
 * 
 *     cpdef float get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_get1d(cudaGlobalState.state, self.native, x0)
 * 
 */

static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_31get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static float __pyx_f_11PyCudaTorch_10CudaTensor_get1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_skip_dispatch) {
  float __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  float __pyx_t_7;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get1d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get1d); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_31get1d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_4 = __pyx_t_1; __pyx_t_5 = NULL;
      if (CYTHON_COMPILING_IN_CPYTHON && unlikely(PyMethod_Check(__pyx_t_4))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
        if (likely(__pyx_t_5)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_4);
          __Pyx_INCREF(__pyx_t_5);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_4, function);
        }
      }
      if (!__pyx_t_5) {
        __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_4, __pyx_t_3); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_GOTREF(__pyx_t_2);
      } else {
        __pyx_t_6 = PyTuple_New(1+1); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
        __Pyx_GOTREF(__pyx_t_6);
        PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_5); __Pyx_GIVEREF(__pyx_t_5); __pyx_t_5 = NULL;
        PyTuple_SET_ITEM(__pyx_t_6, 0+1, __pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_3);
        __pyx_t_3 = 0;
        __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_4, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_7 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_7 == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_7;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyCudaTorch.pyx":177
 * 
 *     cpdef float get1d(self, int x0):
 *         return THCudaTensor_get1d(cudaGlobalState.state, self.native, x0)             # <<<<<<<<<<<<<<
 * 
 *     cpdef float get2d(self, int x0, int x1):
 */
  __pyx_r = THCudaTensor_get1d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_x0);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":176
 *         THCudaTensor_set2d(cudaGlobalState.state, self.native, x0, x1, value)
 * 
 *     cpdef float get1d(self, int x0):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_get1d(cudaGlobalState.state, self.native, x0)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_WriteUnraisable("PyCudaTorch.CudaTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_31get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_31get1d(PyObject *__pyx_v_self, PyObject *__pyx_arg_x0) {
  int __pyx_v_x0;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get1d (wrapper)", 0);
  assert(__pyx_arg_x0); {
    __pyx_v_x0 = __Pyx_PyInt_As_int(__pyx_arg_x0); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_30get1d(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((int)__pyx_v_x0));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_30get1d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get1d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_11PyCudaTorch_10CudaTensor_get1d(__pyx_v_self, __pyx_v_x0, 1)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 176; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.get1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":179
 *         return THCudaTensor_get1d(cudaGlobalState.state, self.native, x0)
 * 
 *     cpdef float get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_get2d(cudaGlobalState.state, self.native, x0, x1)
 * 
 */

static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_33get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static float __pyx_f_11PyCudaTorch_10CudaTensor_get2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1, int __pyx_skip_dispatch) {
  float __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  Py_ssize_t __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  float __pyx_t_9;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get2d", 0);
  /* Check if called by wrapper */
  if (unlikely(__pyx_skip_dispatch)) ;
  /* Check if overridden in Python */
  else if (unlikely(Py_TYPE(((PyObject *)__pyx_v_self))->tp_dictoffset != 0)) {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_get2d); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_1);
    if (!PyCFunction_Check(__pyx_t_1) || (PyCFunction_GET_FUNCTION(__pyx_t_1) != (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_33get2d)) {
      __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_x0); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_4 = __Pyx_PyInt_From_int(__pyx_v_x1); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_1);
      __pyx_t_5 = __pyx_t_1; __pyx_t_6 = NULL;
      __pyx_t_7 = 0;
      if (CYTHON_COMPILING_IN_CPYTHON && unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_5);
        if (likely(__pyx_t_6)) {
          PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_6);
          __Pyx_INCREF(function);
          __Pyx_DECREF_SET(__pyx_t_5, function);
          __pyx_t_7 = 1;
        }
      }
      __pyx_t_8 = PyTuple_New(2+__pyx_t_7); if (unlikely(!__pyx_t_8)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_8);
      if (__pyx_t_6) {
        PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_6); __Pyx_GIVEREF(__pyx_t_6); __pyx_t_6 = NULL;
      }
      PyTuple_SET_ITEM(__pyx_t_8, 0+__pyx_t_7, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_8, 1+__pyx_t_7, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_4);
      __pyx_t_3 = 0;
      __pyx_t_4 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_8, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_9 = __pyx_PyFloat_AsFloat(__pyx_t_2); if (unlikely((__pyx_t_9 == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_r = __pyx_t_9;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L0;
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "PyCudaTorch.pyx":180
 * 
 *     cpdef float get2d(self, int x0, int x1):
 *         return THCudaTensor_get2d(cudaGlobalState.state, self.native, x0, x1)             # <<<<<<<<<<<<<<
 * 
 *     def __add__(CudaTensor self, float scalar):
 */
  __pyx_r = THCudaTensor_get2d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_x0, __pyx_v_x1);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":179
 *         return THCudaTensor_get1d(cudaGlobalState.state, self.native, x0)
 * 
 *     cpdef float get2d(self, int x0, int x1):             # <<<<<<<<<<<<<<
 *         return THCudaTensor_get2d(cudaGlobalState.state, self.native, x0, x1)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_WriteUnraisable("PyCudaTorch.CudaTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_33get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_33get2d(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_x0;
  int __pyx_v_x1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get2d (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x0,&__pyx_n_s_x1,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x0)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, 1); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "get2d") < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_x0 = __Pyx_PyInt_As_int(values[0]); if (unlikely((__pyx_v_x0 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    __pyx_v_x1 = __Pyx_PyInt_As_int(values[1]); if (unlikely((__pyx_v_x1 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get2d", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_32get2d(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), __pyx_v_x0, __pyx_v_x1);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_32get2d(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_x0, int __pyx_v_x1) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get2d", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyFloat_FromDouble(__pyx_f_11PyCudaTorch_10CudaTensor_get2d(__pyx_v_self, __pyx_v_x0, __pyx_v_x1, 1)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 179; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.get2d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":182
 *         return THCudaTensor_get2d(cudaGlobalState.state, self.native, x0, x1)
 * 
 *     def __add__(CudaTensor self, float scalar):             # <<<<<<<<<<<<<<
 *         cdef CudaTensor res = CudaTensor()
 *         THCudaTensor_add(cudaGlobalState.state, res.native, self.native, scalar)
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_35__add__(PyObject *__pyx_v_self, PyObject *__pyx_arg_scalar); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_35__add__(PyObject *__pyx_v_self, PyObject *__pyx_arg_scalar) {
  float __pyx_v_scalar;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__add__ (wrapper)", 0);
  assert(__pyx_arg_scalar); {
    __pyx_v_scalar = __pyx_PyFloat_AsFloat(__pyx_arg_scalar); if (unlikely((__pyx_v_scalar == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 182; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_self), __pyx_ptype_11PyCudaTorch_CudaTensor, 1, "self", 0))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 182; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_34__add__(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((float)__pyx_v_scalar));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_34__add__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, float __pyx_v_scalar) {
  struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_res = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__add__", 0);

  /* "PyCudaTorch.pyx":183
 * 
 *     def __add__(CudaTensor self, float scalar):
 *         cdef CudaTensor res = CudaTensor()             # <<<<<<<<<<<<<<
 *         THCudaTensor_add(cudaGlobalState.state, res.native, self.native, scalar)
 *         return res
 */
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 183; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_res = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":184
 *     def __add__(CudaTensor self, float scalar):
 *         cdef CudaTensor res = CudaTensor()
 *         THCudaTensor_add(cudaGlobalState.state, res.native, self.native, scalar)             # <<<<<<<<<<<<<<
 *         return res
 * 
 */
  THCudaTensor_add(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_res->native, __pyx_v_self->native, __pyx_v_scalar);

  /* "PyCudaTorch.pyx":185
 *         cdef CudaTensor res = CudaTensor()
 *         THCudaTensor_add(cudaGlobalState.state, res.native, self.native, scalar)
 *         return res             # <<<<<<<<<<<<<<
 * 
 *     def __getitem__(CudaTensor self, int index):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_res));
  __pyx_r = ((PyObject *)__pyx_v_res);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":182
 *         return THCudaTensor_get2d(cudaGlobalState.state, self.native, x0, x1)
 * 
 *     def __add__(CudaTensor self, float scalar):             # <<<<<<<<<<<<<<
 *         cdef CudaTensor res = CudaTensor()
 *         THCudaTensor_add(cudaGlobalState.state, res.native, self.native, scalar)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__add__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_res);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":187
 *         return res
 * 
 *     def __getitem__(CudaTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_37__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_37__getitem__(PyObject *__pyx_v_self, PyObject *__pyx_arg_index) {
  int __pyx_v_index;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getitem__ (wrapper)", 0);
  assert(__pyx_arg_index); {
    __pyx_v_index = __Pyx_PyInt_As_int(__pyx_arg_index); if (unlikely((__pyx_v_index == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 187; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_36__getitem__(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((int)__pyx_v_index));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_36__getitem__(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, int __pyx_v_index) {
  struct THCudaTensor *__pyx_v_res;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  struct __pyx_opt_args_11PyCudaTorch_CudaTensor_fromNative __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__getitem__", 0);

  /* "PyCudaTorch.pyx":188
 * 
 *     def __getitem__(CudaTensor self, int index):
 *         if self.dims() == 1:             # <<<<<<<<<<<<<<
 *             return self.get1d(index)
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)
 */
  __pyx_t_1 = ((((struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *)__pyx_v_self->__pyx_vtab)->dims(__pyx_v_self, 0) == 1) != 0);
  if (__pyx_t_1) {

    /* "PyCudaTorch.pyx":189
 *     def __getitem__(CudaTensor self, int index):
 *         if self.dims() == 1:
 *             return self.get1d(index)             # <<<<<<<<<<<<<<
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)
 *         return CudaTensor_fromNative(res, False)
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_2 = PyFloat_FromDouble(((struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor *)__pyx_v_self->__pyx_vtab)->get1d(__pyx_v_self, __pyx_v_index, 0)); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 189; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":190
 *         if self.dims() == 1:
 *             return self.get1d(index)
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)             # <<<<<<<<<<<<<<
 *         return CudaTensor_fromNative(res, False)
 * 
 */
  __pyx_v_res = THCudaTensor_newSelect(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, 0, __pyx_v_index);

  /* "PyCudaTorch.pyx":191
 *             return self.get1d(index)
 *         cdef THCudaTensor *res = THCudaTensor_newSelect(cudaGlobalState.state, self.native, 0, index)
 *         return CudaTensor_fromNative(res, False)             # <<<<<<<<<<<<<<
 * 
 *     def resize(CudaTensor self, Storage._LongStorage size):
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_3.__pyx_n = 1;
  __pyx_t_3.retain = Py_False;
  __pyx_t_2 = __pyx_f_11PyCudaTorch_CudaTensor_fromNative(__pyx_v_res, &__pyx_t_3); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 191; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":187
 *         return res
 * 
 *     def __getitem__(CudaTensor self, int index):             # <<<<<<<<<<<<<<
 *         if self.dims() == 1:
 *             return self.get1d(index)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.__getitem__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":193
 *         return CudaTensor_fromNative(res, False)
 * 
 *     def resize(CudaTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_39resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_39resize(PyObject *__pyx_v_self, PyObject *__pyx_v_size) {
  CYTHON_UNUSED int __pyx_lineno = 0;
  CYTHON_UNUSED const char *__pyx_filename = NULL;
  CYTHON_UNUSED int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resize (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_size), __pyx_ptype_7Storage__LongStorage, 1, "size", 0))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 193; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_38resize(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((struct __pyx_obj_7Storage__LongStorage *)__pyx_v_size));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_38resize(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, struct __pyx_obj_7Storage__LongStorage *__pyx_v_size) {
  int __pyx_v_dims;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  long __pyx_t_4;
  long __pyx_t_5;
  long __pyx_t_6;
  long __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("resize", 0);

  /* "PyCudaTorch.pyx":195
 *     def resize(CudaTensor self, Storage._LongStorage size):
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:             # <<<<<<<<<<<<<<
 *             return self
 *         cdef int dims = len(size)
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 195; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_t_2 = ((__pyx_t_1 == 0) != 0);
  if (__pyx_t_2) {

    /* "PyCudaTorch.pyx":196
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 *             return self             # <<<<<<<<<<<<<<
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_self));
    __pyx_r = ((PyObject *)__pyx_v_self);
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":197
 *         if len(size) == 0:
 *             return self
 *         cdef int dims = len(size)             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 */
  __pyx_t_1 = PyObject_Length(((PyObject *)__pyx_v_size)); if (unlikely(__pyx_t_1 == -1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 197; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_dims = __pyx_t_1;

  /* "PyCudaTorch.pyx":205
 *         elif dims == 3:
 *             THCudaTensor_resize3d(cudaGlobalState.state, self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THCudaTensor_resize4d(cudaGlobalState.state, self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
  switch (__pyx_v_dims) {

    /* "PyCudaTorch.pyx":199
 *         cdef int dims = len(size)
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:             # <<<<<<<<<<<<<<
 *             THCudaTensor_resize1d(cudaGlobalState.state, self.native, size[0])
 *         elif dims == 2:
 */
    case 1:

    /* "PyCudaTorch.pyx":200
 * #        # print('_FloatTensor.resize dims:', dims)
 *         if dims == 1:
 *             THCudaTensor_resize1d(cudaGlobalState.state, self.native, size[0])             # <<<<<<<<<<<<<<
 *         elif dims == 2:
 *             THCudaTensor_resize2d(cudaGlobalState.state, self.native, size[0], size[1])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 200; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 200; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THCudaTensor_resize1d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_t_4);
    break;

    /* "PyCudaTorch.pyx":201
 *         if dims == 1:
 *             THCudaTensor_resize1d(cudaGlobalState.state, self.native, size[0])
 *         elif dims == 2:             # <<<<<<<<<<<<<<
 *             THCudaTensor_resize2d(cudaGlobalState.state, self.native, size[0], size[1])
 *         elif dims == 3:
 */
    case 2:

    /* "PyCudaTorch.pyx":202
 *             THCudaTensor_resize1d(cudaGlobalState.state, self.native, size[0])
 *         elif dims == 2:
 *             THCudaTensor_resize2d(cudaGlobalState.state, self.native, size[0], size[1])             # <<<<<<<<<<<<<<
 *         elif dims == 3:
 *             THCudaTensor_resize3d(cudaGlobalState.state, self.native, size[0], size[1], size[2])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 202; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 202; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 202; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 202; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THCudaTensor_resize2d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_t_4, __pyx_t_5);
    break;

    /* "PyCudaTorch.pyx":203
 *         elif dims == 2:
 *             THCudaTensor_resize2d(cudaGlobalState.state, self.native, size[0], size[1])
 *         elif dims == 3:             # <<<<<<<<<<<<<<
 *             THCudaTensor_resize3d(cudaGlobalState.state, self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 */
    case 3:

    /* "PyCudaTorch.pyx":204
 *             THCudaTensor_resize2d(cudaGlobalState.state, self.native, size[0], size[1])
 *         elif dims == 3:
 *             THCudaTensor_resize3d(cudaGlobalState.state, self.native, size[0], size[1], size[2])             # <<<<<<<<<<<<<<
 *         elif dims == 4:
 *             THCudaTensor_resize4d(cudaGlobalState.state, self.native, size[0], size[1], size[2], size[3])
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 204; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 204; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 204; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 204; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 204; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 204; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THCudaTensor_resize3d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_t_5, __pyx_t_4, __pyx_t_6);
    break;

    /* "PyCudaTorch.pyx":205
 *         elif dims == 3:
 *             THCudaTensor_resize3d(cudaGlobalState.state, self.native, size[0], size[1], size[2])
 *         elif dims == 4:             # <<<<<<<<<<<<<<
 *             THCudaTensor_resize4d(cudaGlobalState.state, self.native, size[0], size[1], size[2], size[3])
 *         else:
 */
    case 4:

    /* "PyCudaTorch.pyx":206
 *             THCudaTensor_resize3d(cudaGlobalState.state, self.native, size[0], size[1], size[2])
 *         elif dims == 4:
 *             THCudaTensor_resize4d(cudaGlobalState.state, self.native, size[0], size[1], size[2], size[3])             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 */
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_6 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_4 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_5 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_As_long(__pyx_t_3); if (unlikely((__pyx_t_7 == (long)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 206; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    THCudaTensor_resize4d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_t_6, __pyx_t_4, __pyx_t_5, __pyx_t_7);
    break;
    default:

    /* "PyCudaTorch.pyx":208
 *             THCudaTensor_resize4d(cudaGlobalState.state, self.native, size[0], size[1], size[2], size[3])
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
    __pyx_t_3 = __Pyx_PyInt_From_int(__pyx_v_dims); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 208; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_8 = PyTuple_New(1); if (unlikely(!__pyx_t_8)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 208; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_8);
    PyTuple_SET_ITEM(__pyx_t_8, 0, __pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_3);
    __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)(&PyString_Type))), __pyx_t_8, NULL); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 208; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    __pyx_t_8 = PyNumber_Add(__pyx_kp_s_Not_implemented_for_dims, __pyx_t_3); if (unlikely(!__pyx_t_8)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 208; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyTuple_New(1); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 208; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_3);
    PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_8);
    __Pyx_GIVEREF(__pyx_t_8);
    __pyx_t_8 = 0;
    __pyx_t_8 = __Pyx_PyObject_Call(__pyx_builtin_Exception, __pyx_t_3, NULL); if (unlikely(!__pyx_t_8)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 208; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_8);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_t_8, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
    {__pyx_filename = __pyx_f[0]; __pyx_lineno = 208; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    break;
  }

  /* "PyCudaTorch.pyx":209
 *         else:
 *             raise Exception('Not implemented for dims=' + str(dims))
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def resizeAs(CudaTensor self, CudaTensor model):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":193
 *         return CudaTensor_fromNative(res, False)
 * 
 *     def resize(CudaTensor self, Storage._LongStorage size):             # <<<<<<<<<<<<<<
 * #        # print('_FloatTensor.resize size:', size)
 *         if len(size) == 0:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.resize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":211
 *         return self
 * 
 *     def resizeAs(CudaTensor self, CudaTensor model):             # <<<<<<<<<<<<<<
 *         THCudaTensor_resizeAs(cudaGlobalState.state, self.native, model.native)
 *         return self
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_41resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_41resizeAs(PyObject *__pyx_v_self, PyObject *__pyx_v_model) {
  CYTHON_UNUSED int __pyx_lineno = 0;
  CYTHON_UNUSED const char *__pyx_filename = NULL;
  CYTHON_UNUSED int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_model), __pyx_ptype_11PyCudaTorch_CudaTensor, 1, "model", 0))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 211; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_40resizeAs(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_model));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_40resizeAs(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_model) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("resizeAs", 0);

  /* "PyCudaTorch.pyx":212
 * 
 *     def resizeAs(CudaTensor self, CudaTensor model):
 *         THCudaTensor_resizeAs(cudaGlobalState.state, self.native, model.native)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  THCudaTensor_resizeAs(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_self->native, __pyx_v_model->native);

  /* "PyCudaTorch.pyx":213
 *     def resizeAs(CudaTensor self, CudaTensor model):
 *         THCudaTensor_resizeAs(cudaGlobalState.state, self.native, model.native)
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def uniform(CudaTensor self, float a=0, float b=1):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":211
 *         return self
 * 
 *     def resizeAs(CudaTensor self, CudaTensor model):             # <<<<<<<<<<<<<<
 *         THCudaTensor_resizeAs(cudaGlobalState.state, self.native, model.native)
 *         return self
 */

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":215
 *         return self
 * 
 *     def uniform(CudaTensor self, float a=0, float b=1):             # <<<<<<<<<<<<<<
 *         cdef Storage._LongStorage size = self.size()
 *         cdef PyTorch._FloatTensor floatTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_43uniform(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_10CudaTensor_43uniform(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  float __pyx_v_a;
  float __pyx_v_b;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("uniform (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_a,&__pyx_n_s_b,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_a);
          if (value) { values[0] = value; kw_args--; }
        }
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_b);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "uniform") < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 215; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    if (values[0]) {
      __pyx_v_a = __pyx_PyFloat_AsFloat(values[0]); if (unlikely((__pyx_v_a == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 215; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    } else {
      __pyx_v_a = ((float)0.0);
    }
    if (values[1]) {
      __pyx_v_b = __pyx_PyFloat_AsFloat(values[1]); if (unlikely((__pyx_v_b == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 215; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
    } else {
      __pyx_v_b = ((float)1.0);
    }
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("uniform", 0, 0, 2, PyTuple_GET_SIZE(__pyx_args)); {__pyx_filename = __pyx_f[0]; __pyx_lineno = 215; __pyx_clineno = __LINE__; goto __pyx_L3_error;}
  __pyx_L3_error:;
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.uniform", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_11PyCudaTorch_10CudaTensor_42uniform(((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_self), __pyx_v_a, __pyx_v_b);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10CudaTensor_42uniform(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_self, float __pyx_v_a, float __pyx_v_b) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_floatTensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  Py_ssize_t __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("uniform", 0);

  /* "PyCudaTorch.pyx":216
 * 
 *     def uniform(CudaTensor self, float a=0, float b=1):
 *         cdef Storage._LongStorage size = self.size()             # <<<<<<<<<<<<<<
 *         cdef PyTorch._FloatTensor floatTensor
 * #        print('size', size)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 216; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 216; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 216; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7Storage__LongStorage))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 216; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":219
 *         cdef PyTorch._FloatTensor floatTensor
 * #        print('size', size)
 *         floatTensor = PyTorch._FloatTensor(size)             # <<<<<<<<<<<<<<
 * #        print('got floattensor')
 * #        print('uniform, floatTensor=', floatTensor)
 */
  __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 219; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)__pyx_v_size));
  PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)__pyx_v_size));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_size));
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_7PyTorch__FloatTensor)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 219; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_floatTensor = ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "PyCudaTorch.pyx":222
 * #        print('got floattensor')
 * #        print('uniform, floatTensor=', floatTensor)
 *         floatTensor.uniform(a, b)             # <<<<<<<<<<<<<<
 *         self.copy(floatTensor)
 *         return self
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_floatTensor), __pyx_n_s_uniform); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 222; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = PyFloat_FromDouble(__pyx_v_a); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 222; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyFloat_FromDouble(__pyx_v_b); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 222; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
      __pyx_t_6 = 1;
    }
  }
  __pyx_t_7 = PyTuple_New(2+__pyx_t_6); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 222; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_7);
  if (__pyx_t_5) {
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __Pyx_GIVEREF(__pyx_t_5); __pyx_t_5 = NULL;
  }
  PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_6, __pyx_t_3);
  __Pyx_GIVEREF(__pyx_t_3);
  PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_6, __pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __pyx_t_3 = 0;
  __pyx_t_4 = 0;
  __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_7, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 222; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "PyCudaTorch.pyx":223
 * #        print('uniform, floatTensor=', floatTensor)
 *         floatTensor.uniform(a, b)
 *         self.copy(floatTensor)             # <<<<<<<<<<<<<<
 *         return self
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_self), __pyx_n_s_copy); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 223; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_1))) {
    __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_1);
    if (likely(__pyx_t_7)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_7);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_1, function);
    }
  }
  if (!__pyx_t_7) {
    __pyx_t_2 = __Pyx_PyObject_CallOneArg(__pyx_t_1, ((PyObject *)__pyx_v_floatTensor)); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 223; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
  } else {
    __pyx_t_4 = PyTuple_New(1+1); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 223; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_7); __Pyx_GIVEREF(__pyx_t_7); __pyx_t_7 = NULL;
    __Pyx_INCREF(((PyObject *)__pyx_v_floatTensor));
    PyTuple_SET_ITEM(__pyx_t_4, 0+1, ((PyObject *)__pyx_v_floatTensor));
    __Pyx_GIVEREF(((PyObject *)__pyx_v_floatTensor));
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_4, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 223; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "PyCudaTorch.pyx":224
 *         floatTensor.uniform(a, b)
 *         self.copy(floatTensor)
 *         return self             # <<<<<<<<<<<<<<
 * 
 * cpdef int getPrediction(CudaTensor output):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":215
 *         return self
 * 
 *     def uniform(CudaTensor self, float a=0, float b=1):             # <<<<<<<<<<<<<<
 *         cdef Storage._LongStorage size = self.size()
 *         cdef PyTorch._FloatTensor floatTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor.uniform", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_size);
  __Pyx_XDECREF((PyObject *)__pyx_v_floatTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":226
 *         return self
 * 
 * cpdef int getPrediction(CudaTensor output):             # <<<<<<<<<<<<<<
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]
 */

static PyObject *__pyx_pw_11PyCudaTorch_5getPrediction(PyObject *__pyx_self, PyObject *__pyx_v_output); /*proto*/
static int __pyx_f_11PyCudaTorch_getPrediction(struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_output, CYTHON_UNUSED int __pyx_skip_dispatch) {
  int __pyx_v_prediction;
  float __pyx_v_maxSoFar;
  float __pyx_v_thisValue;
  int __pyx_v_i;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  float __pyx_t_2;
  long __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("getPrediction", 0);

  /* "PyCudaTorch.pyx":227
 * 
 * cpdef int getPrediction(CudaTensor output):
 *     cdef int prediction = 0             # <<<<<<<<<<<<<<
 *     cdef float maxSoFar = output[0]
 *     cdef float thisValue = 0
 */
  __pyx_v_prediction = 0;

  /* "PyCudaTorch.pyx":228
 * cpdef int getPrediction(CudaTensor output):
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]             # <<<<<<<<<<<<<<
 *     cdef float thisValue = 0
 *     cdef int i = 0
 */
  __pyx_t_1 = __Pyx_GetItemInt(((PyObject *)__pyx_v_output), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_1 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 228; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __pyx_PyFloat_AsFloat(__pyx_t_1); if (unlikely((__pyx_t_2 == (float)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 228; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_maxSoFar = __pyx_t_2;

  /* "PyCudaTorch.pyx":229
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]
 *     cdef float thisValue = 0             # <<<<<<<<<<<<<<
 *     cdef int i = 0
 *     for i in range(THCudaTensor_size(cudaGlobalState.state, output.native, 0)):
 */
  __pyx_v_thisValue = 0.0;

  /* "PyCudaTorch.pyx":230
 *     cdef float maxSoFar = output[0]
 *     cdef float thisValue = 0
 *     cdef int i = 0             # <<<<<<<<<<<<<<
 *     for i in range(THCudaTensor_size(cudaGlobalState.state, output.native, 0)):
 *         thisValue = THCudaTensor_get1d(cudaGlobalState.state, output.native, i)
 */
  __pyx_v_i = 0;

  /* "PyCudaTorch.pyx":231
 *     cdef float thisValue = 0
 *     cdef int i = 0
 *     for i in range(THCudaTensor_size(cudaGlobalState.state, output.native, 0)):             # <<<<<<<<<<<<<<
 *         thisValue = THCudaTensor_get1d(cudaGlobalState.state, output.native, i)
 *         if thisValue > maxSoFar:
 */
  __pyx_t_3 = THCudaTensor_size(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_output->native, 0);
  for (__pyx_t_4 = 0; __pyx_t_4 < __pyx_t_3; __pyx_t_4+=1) {
    __pyx_v_i = __pyx_t_4;

    /* "PyCudaTorch.pyx":232
 *     cdef int i = 0
 *     for i in range(THCudaTensor_size(cudaGlobalState.state, output.native, 0)):
 *         thisValue = THCudaTensor_get1d(cudaGlobalState.state, output.native, i)             # <<<<<<<<<<<<<<
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue
 */
    __pyx_v_thisValue = THCudaTensor_get1d(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_output->native, __pyx_v_i);

    /* "PyCudaTorch.pyx":233
 *     for i in range(THCudaTensor_size(cudaGlobalState.state, output.native, 0)):
 *         thisValue = THCudaTensor_get1d(cudaGlobalState.state, output.native, i)
 *         if thisValue > maxSoFar:             # <<<<<<<<<<<<<<
 *             maxSoFar = thisValue
 *             prediction = i
 */
    __pyx_t_5 = ((__pyx_v_thisValue > __pyx_v_maxSoFar) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":234
 *         thisValue = THCudaTensor_get1d(cudaGlobalState.state, output.native, i)
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue             # <<<<<<<<<<<<<<
 *             prediction = i
 *     return prediction + 1
 */
      __pyx_v_maxSoFar = __pyx_v_thisValue;

      /* "PyCudaTorch.pyx":235
 *         if thisValue > maxSoFar:
 *             maxSoFar = thisValue
 *             prediction = i             # <<<<<<<<<<<<<<
 *     return prediction + 1
 * 
 */
      __pyx_v_prediction = __pyx_v_i;
      goto __pyx_L5;
    }
    __pyx_L5:;
  }

  /* "PyCudaTorch.pyx":236
 *             maxSoFar = thisValue
 *             prediction = i
 *     return prediction + 1             # <<<<<<<<<<<<<<
 * 
 * cdef CudaTensor_fromNative(THCudaTensor *tensorC, retain=True):
 */
  __pyx_r = (__pyx_v_prediction + 1);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":226
 *         return self
 * 
 * cpdef int getPrediction(CudaTensor output):             # <<<<<<<<<<<<<<
 *     cdef int prediction = 0
 *     cdef float maxSoFar = output[0]
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_WriteUnraisable("PyCudaTorch.getPrediction", __pyx_clineno, __pyx_lineno, __pyx_filename, 0);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_5getPrediction(PyObject *__pyx_self, PyObject *__pyx_v_output); /*proto*/
static PyObject *__pyx_pw_11PyCudaTorch_5getPrediction(PyObject *__pyx_self, PyObject *__pyx_v_output) {
  CYTHON_UNUSED int __pyx_lineno = 0;
  CYTHON_UNUSED const char *__pyx_filename = NULL;
  CYTHON_UNUSED int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getPrediction (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_output), __pyx_ptype_11PyCudaTorch_CudaTensor, 1, "output", 0))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 226; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_pf_11PyCudaTorch_4getPrediction(__pyx_self, ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_v_output));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_4getPrediction(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_output) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("getPrediction", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyInt_From_int(__pyx_f_11PyCudaTorch_getPrediction(__pyx_v_output, 0)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 226; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.getPrediction", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":238
 *     return prediction + 1
 * 
 * cdef CudaTensor_fromNative(THCudaTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     cdef CudaTensor tensor = CudaTensor(_allocate=False )
 *     tensor.native = tensorC
 */

static PyObject *__pyx_f_11PyCudaTorch_CudaTensor_fromNative(struct THCudaTensor *__pyx_v_tensorC, struct __pyx_opt_args_11PyCudaTorch_CudaTensor_fromNative *__pyx_optional_args) {
  PyObject *__pyx_v_retain = ((PyObject *)Py_True);
  struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_tensor = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("CudaTensor_fromNative", 0);
  if (__pyx_optional_args) {
    if (__pyx_optional_args->__pyx_n > 0) {
      __pyx_v_retain = __pyx_optional_args->retain;
    }
  }

  /* "PyCudaTorch.pyx":239
 * 
 * cdef CudaTensor_fromNative(THCudaTensor *tensorC, retain=True):
 *     cdef CudaTensor tensor = CudaTensor(_allocate=False )             # <<<<<<<<<<<<<<
 *     tensor.native = tensorC
 *     if retain:
 */
  __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 239; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_t_1, __pyx_n_s_allocate, Py_False) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 239; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_empty_tuple, __pyx_t_1); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 239; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_tensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "PyCudaTorch.pyx":240
 * cdef CudaTensor_fromNative(THCudaTensor *tensorC, retain=True):
 *     cdef CudaTensor tensor = CudaTensor(_allocate=False )
 *     tensor.native = tensorC             # <<<<<<<<<<<<<<
 *     if retain:
 *         THCudaTensor_retain(cudaGlobalState.state, tensorC)
 */
  __pyx_v_tensor->native = __pyx_v_tensorC;

  /* "PyCudaTorch.pyx":241
 *     cdef CudaTensor tensor = CudaTensor(_allocate=False )
 *     tensor.native = tensorC
 *     if retain:             # <<<<<<<<<<<<<<
 *         THCudaTensor_retain(cudaGlobalState.state, tensorC)
 *     return tensor
 */
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_v_retain); if (unlikely(__pyx_t_3 < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 241; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  if (__pyx_t_3) {

    /* "PyCudaTorch.pyx":242
 *     tensor.native = tensorC
 *     if retain:
 *         THCudaTensor_retain(cudaGlobalState.state, tensorC)             # <<<<<<<<<<<<<<
 *     return tensor
 * 
 */
    THCudaTensor_retain(__pyx_v_11PyCudaTorch_cudaGlobalState->state, __pyx_v_tensorC);
    goto __pyx_L3;
  }
  __pyx_L3:;

  /* "PyCudaTorch.pyx":243
 *     if retain:
 *         THCudaTensor_retain(cudaGlobalState.state, tensorC)
 *     return tensor             # <<<<<<<<<<<<<<
 * 
 * def FloatTensorToCudaTensor(PyTorch._FloatTensor floatTensor):
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(((PyObject *)__pyx_v_tensor));
  __pyx_r = ((PyObject *)__pyx_v_tensor);
  goto __pyx_L0;

  /* "PyCudaTorch.pyx":238
 *     return prediction + 1
 * 
 * cdef CudaTensor_fromNative(THCudaTensor *tensorC, retain=True):             # <<<<<<<<<<<<<<
 *     cdef CudaTensor tensor = CudaTensor(_allocate=False )
 *     tensor.native = tensorC
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("PyCudaTorch.CudaTensor_fromNative", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_tensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":245
 *     return tensor
 * 
 * def FloatTensorToCudaTensor(PyTorch._FloatTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_7FloatTensorToCudaTensor(PyObject *__pyx_self, PyObject *__pyx_v_floatTensor); /*proto*/
static PyMethodDef __pyx_mdef_11PyCudaTorch_7FloatTensorToCudaTensor = {"FloatTensorToCudaTensor", (PyCFunction)__pyx_pw_11PyCudaTorch_7FloatTensorToCudaTensor, METH_O, 0};
static PyObject *__pyx_pw_11PyCudaTorch_7FloatTensorToCudaTensor(PyObject *__pyx_self, PyObject *__pyx_v_floatTensor) {
  CYTHON_UNUSED int __pyx_lineno = 0;
  CYTHON_UNUSED const char *__pyx_filename = NULL;
  CYTHON_UNUSED int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("FloatTensorToCudaTensor (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_floatTensor), __pyx_ptype_7PyTorch__FloatTensor, 1, "floatTensor", 0))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 245; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_pf_11PyCudaTorch_6FloatTensorToCudaTensor(__pyx_self, ((struct __pyx_obj_7PyTorch__FloatTensor *)__pyx_v_floatTensor));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_6FloatTensorToCudaTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__FloatTensor *__pyx_v_floatTensor) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_clTensor = 0;
  int __pyx_v_nElement;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("FloatTensorToCudaTensor", 0);

  /* "PyCudaTorch.pyx":246
 * 
 * def FloatTensorToCudaTensor(PyTorch._FloatTensor floatTensor):
 *     cdef Storage._LongStorage size = floatTensor.size()             # <<<<<<<<<<<<<<
 *     cdef CudaTensor clTensor
 *     cdef int nElement = floatTensor.nElement()
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_floatTensor), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 246; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 246; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 246; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7Storage__LongStorage))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 246; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":248
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 *     cdef int nElement = floatTensor.nElement()             # <<<<<<<<<<<<<<
 *     if nElement > 0:
 *         if floatTensor.dims() == 1:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_floatTensor), __pyx_n_s_nElement); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 248; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 248; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 248; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 248; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_nElement = __pyx_t_4;

  /* "PyCudaTorch.pyx":249
 *     cdef CudaTensor clTensor
 *     cdef int nElement = floatTensor.nElement()
 *     if nElement > 0:             # <<<<<<<<<<<<<<
 *         if floatTensor.dims() == 1:
 *             clTensor = CudaTensor(int(size[0]))
 */
  __pyx_t_5 = ((__pyx_v_nElement > 0) != 0);
  if (__pyx_t_5) {

    /* "PyCudaTorch.pyx":250
 *     cdef int nElement = floatTensor.nElement()
 *     if nElement > 0:
 *         if floatTensor.dims() == 1:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]))
 *         elif floatTensor.dims() == 2:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 1) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":251
 *     if nElement > 0:
 *         if floatTensor.dims() == 1:
 *             clTensor = CudaTensor(int(size[0]))             # <<<<<<<<<<<<<<
 *         elif floatTensor.dims() == 2:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 */
      __pyx_t_1 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_1 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 251; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = PyNumber_Int(__pyx_t_1); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 251; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 251; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 251; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_2);
      __pyx_t_2 = 0;
      goto __pyx_L4;
    }

    /* "PyCudaTorch.pyx":252
 *         if floatTensor.dims() == 1:
 *             clTensor = CudaTensor(int(size[0]))
 *         elif floatTensor.dims() == 2:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 *         elif floatTensor.dims() == 3:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 2) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":253
 *             clTensor = CudaTensor(int(size[0]))
 *         elif floatTensor.dims() == 2:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))             # <<<<<<<<<<<<<<
 *         elif floatTensor.dims() == 3:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 */
      __pyx_t_2 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 253; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyNumber_Int(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 253; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 253; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PyNumber_Int(__pyx_t_2); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 253; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 253; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      __pyx_t_1 = 0;
      __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 253; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_3);
      __pyx_t_3 = 0;
      goto __pyx_L4;
    }

    /* "PyCudaTorch.pyx":254
 *         elif floatTensor.dims() == 2:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 *         elif floatTensor.dims() == 3:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 *         elif floatTensor.dims() == 4:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 3) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":255
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 *         elif floatTensor.dims() == 3:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))             # <<<<<<<<<<<<<<
 *         elif floatTensor.dims() == 4:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 */
      __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = PyNumber_Int(__pyx_t_3); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_1 = PyNumber_Int(__pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_6 = PyNumber_Int(__pyx_t_3); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_6);
      __pyx_t_2 = 0;
      __pyx_t_1 = 0;
      __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_3, NULL); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 255; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_6);
      __pyx_t_6 = 0;
      goto __pyx_L4;
    }

    /* "PyCudaTorch.pyx":256
 *         elif floatTensor.dims() == 3:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 *         elif floatTensor.dims() == 4:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 *         else:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__FloatTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 4) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":257
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 *         elif floatTensor.dims() == 4:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('not implemented')
 */
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_3 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_1 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_2 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyTuple_New(4); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_6, 3, __pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      __pyx_t_3 = 0;
      __pyx_t_1 = 0;
      __pyx_t_2 = 0;
      __pyx_t_7 = 0;
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 257; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_7);
      __pyx_t_7 = 0;
      goto __pyx_L4;
    }
    /*else*/ {

      /* "PyCudaTorch.pyx":259
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 *         else:
 *             raise Exception('not implemented')             # <<<<<<<<<<<<<<
 *         clTensor.copy(floatTensor)
 *         return clTensor
 */
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_Exception, __pyx_tuple__4, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 259; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_Raise(__pyx_t_7, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      {__pyx_filename = __pyx_f[0]; __pyx_lineno = 259; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    }
    __pyx_L4:;

    /* "PyCudaTorch.pyx":260
 *         else:
 *             raise Exception('not implemented')
 *         clTensor.copy(floatTensor)             # <<<<<<<<<<<<<<
 *         return clTensor
 *     else:
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_clTensor), __pyx_n_s_copy); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 260; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_2 = NULL;
    if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    if (!__pyx_t_2) {
      __pyx_t_7 = __Pyx_PyObject_CallOneArg(__pyx_t_6, ((PyObject *)__pyx_v_floatTensor)); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 260; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
    } else {
      __pyx_t_1 = PyTuple_New(1+1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 260; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2); __Pyx_GIVEREF(__pyx_t_2); __pyx_t_2 = NULL;
      __Pyx_INCREF(((PyObject *)__pyx_v_floatTensor));
      PyTuple_SET_ITEM(__pyx_t_1, 0+1, ((PyObject *)__pyx_v_floatTensor));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_floatTensor));
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_1, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 260; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "PyCudaTorch.pyx":261
 *             raise Exception('not implemented')
 *         clTensor.copy(floatTensor)
 *         return clTensor             # <<<<<<<<<<<<<<
 *     else:
 *         return CudaTensor()
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_clTensor));
    __pyx_r = ((PyObject *)__pyx_v_clTensor);
    goto __pyx_L0;
  }
  /*else*/ {

    /* "PyCudaTorch.pyx":263
 *         return clTensor
 *     else:
 *         return CudaTensor()             # <<<<<<<<<<<<<<
 * 
 * def DoubleTensorToCudaTensor(PyTorch._DoubleTensor floatTensor):
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 263; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_r = __pyx_t_7;
    __pyx_t_7 = 0;
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":245
 *     return tensor
 * 
 * def FloatTensorToCudaTensor(PyTorch._FloatTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("PyCudaTorch.FloatTensorToCudaTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_size);
  __Pyx_XDECREF((PyObject *)__pyx_v_clTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":265
 *         return CudaTensor()
 * 
 * def DoubleTensorToCudaTensor(PyTorch._DoubleTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_9DoubleTensorToCudaTensor(PyObject *__pyx_self, PyObject *__pyx_v_floatTensor); /*proto*/
static PyMethodDef __pyx_mdef_11PyCudaTorch_9DoubleTensorToCudaTensor = {"DoubleTensorToCudaTensor", (PyCFunction)__pyx_pw_11PyCudaTorch_9DoubleTensorToCudaTensor, METH_O, 0};
static PyObject *__pyx_pw_11PyCudaTorch_9DoubleTensorToCudaTensor(PyObject *__pyx_self, PyObject *__pyx_v_floatTensor) {
  CYTHON_UNUSED int __pyx_lineno = 0;
  CYTHON_UNUSED const char *__pyx_filename = NULL;
  CYTHON_UNUSED int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("DoubleTensorToCudaTensor (wrapper)", 0);
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_floatTensor), __pyx_ptype_7PyTorch__DoubleTensor, 1, "floatTensor", 0))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 265; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_pf_11PyCudaTorch_8DoubleTensorToCudaTensor(__pyx_self, ((struct __pyx_obj_7PyTorch__DoubleTensor *)__pyx_v_floatTensor));

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_8DoubleTensorToCudaTensor(CYTHON_UNUSED PyObject *__pyx_self, struct __pyx_obj_7PyTorch__DoubleTensor *__pyx_v_floatTensor) {
  struct __pyx_obj_7Storage__LongStorage *__pyx_v_size = 0;
  struct __pyx_obj_11PyCudaTorch_CudaTensor *__pyx_v_clTensor = 0;
  int __pyx_v_nElement;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("DoubleTensorToCudaTensor", 0);

  /* "PyCudaTorch.pyx":266
 * 
 * def DoubleTensorToCudaTensor(PyTorch._DoubleTensor floatTensor):
 *     cdef Storage._LongStorage size = floatTensor.size()             # <<<<<<<<<<<<<<
 *     cdef CudaTensor clTensor
 *     cdef int nElement = floatTensor.nElement()
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_floatTensor), __pyx_n_s_size); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 266; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 266; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 266; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7Storage__LongStorage))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 266; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_v_size = ((struct __pyx_obj_7Storage__LongStorage *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":268
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 *     cdef int nElement = floatTensor.nElement()             # <<<<<<<<<<<<<<
 *     if nElement > 0:
 *         if floatTensor.dims() == 1:
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_floatTensor), __pyx_n_s_nElement); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 268; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_3)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
    }
  }
  if (__pyx_t_3) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 268; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 268; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 268; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_nElement = __pyx_t_4;

  /* "PyCudaTorch.pyx":269
 *     cdef CudaTensor clTensor
 *     cdef int nElement = floatTensor.nElement()
 *     if nElement > 0:             # <<<<<<<<<<<<<<
 *         if floatTensor.dims() == 1:
 *             clTensor = CudaTensor(int(size[0]))
 */
  __pyx_t_5 = ((__pyx_v_nElement > 0) != 0);
  if (__pyx_t_5) {

    /* "PyCudaTorch.pyx":270
 *     cdef int nElement = floatTensor.nElement()
 *     if nElement > 0:
 *         if floatTensor.dims() == 1:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]))
 *         elif floatTensor.dims() == 2:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 1) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":271
 *     if nElement > 0:
 *         if floatTensor.dims() == 1:
 *             clTensor = CudaTensor(int(size[0]))             # <<<<<<<<<<<<<<
 *         elif floatTensor.dims() == 2:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 */
      __pyx_t_1 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_1 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 271; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = PyNumber_Int(__pyx_t_1); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 271; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = PyTuple_New(1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 271; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_1, NULL); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 271; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_2);
      __pyx_t_2 = 0;
      goto __pyx_L4;
    }

    /* "PyCudaTorch.pyx":272
 *         if floatTensor.dims() == 1:
 *             clTensor = CudaTensor(int(size[0]))
 *         elif floatTensor.dims() == 2:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 *         elif floatTensor.dims() == 3:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 2) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":273
 *             clTensor = CudaTensor(int(size[0]))
 *         elif floatTensor.dims() == 2:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))             # <<<<<<<<<<<<<<
 *         elif floatTensor.dims() == 3:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 */
      __pyx_t_2 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 273; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_1 = PyNumber_Int(__pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 273; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_2 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 273; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = PyNumber_Int(__pyx_t_2); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 273; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 273; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      __pyx_t_1 = 0;
      __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_2, NULL); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 273; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_3);
      __pyx_t_3 = 0;
      goto __pyx_L4;
    }

    /* "PyCudaTorch.pyx":274
 *         elif floatTensor.dims() == 2:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 *         elif floatTensor.dims() == 3:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 *         elif floatTensor.dims() == 4:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 3) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":275
 *             clTensor = CudaTensor(int(size[0]), int(size[1]))
 *         elif floatTensor.dims() == 3:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))             # <<<<<<<<<<<<<<
 *         elif floatTensor.dims() == 4:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 */
      __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = PyNumber_Int(__pyx_t_3); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_1 = PyNumber_Int(__pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_3 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_6 = PyNumber_Int(__pyx_t_3); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_3 = PyTuple_New(3); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_3, 2, __pyx_t_6);
      __Pyx_GIVEREF(__pyx_t_6);
      __pyx_t_2 = 0;
      __pyx_t_1 = 0;
      __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_3, NULL); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 275; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_6);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_6);
      __pyx_t_6 = 0;
      goto __pyx_L4;
    }

    /* "PyCudaTorch.pyx":276
 *         elif floatTensor.dims() == 3:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 *         elif floatTensor.dims() == 4:             # <<<<<<<<<<<<<<
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 *         else:
 */
    __pyx_t_5 = ((((struct __pyx_vtabstruct_7PyTorch__DoubleTensor *)__pyx_v_floatTensor->__pyx_vtab)->dims(__pyx_v_floatTensor, 0) == 4) != 0);
    if (__pyx_t_5) {

      /* "PyCudaTorch.pyx":277
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]))
 *         elif floatTensor.dims() == 4:
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))             # <<<<<<<<<<<<<<
 *         else:
 *             raise Exception('not implemented')
 */
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_3 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_1 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_2 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = __Pyx_GetItemInt(((PyObject *)__pyx_v_size), 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(__pyx_t_6 == NULL)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
      __Pyx_GOTREF(__pyx_t_6);
      __pyx_t_7 = PyNumber_Int(__pyx_t_6); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_t_6 = PyTuple_New(4); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_6);
      PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_3);
      __Pyx_GIVEREF(__pyx_t_3);
      PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_t_1);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_6, 3, __pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_7);
      __pyx_t_3 = 0;
      __pyx_t_1 = 0;
      __pyx_t_2 = 0;
      __pyx_t_7 = 0;
      __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_t_6, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 277; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __pyx_v_clTensor = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)__pyx_t_7);
      __pyx_t_7 = 0;
      goto __pyx_L4;
    }
    /*else*/ {

      /* "PyCudaTorch.pyx":279
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 *         else:
 *             raise Exception('not implemented')             # <<<<<<<<<<<<<<
 *         clTensor.copy(floatTensor)
 *         return clTensor
 */
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_builtin_Exception, __pyx_tuple__5, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 279; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_Raise(__pyx_t_7, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      {__pyx_filename = __pyx_f[0]; __pyx_lineno = 279; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    }
    __pyx_L4:;

    /* "PyCudaTorch.pyx":280
 *         else:
 *             raise Exception('not implemented')
 *         clTensor.copy(floatTensor)             # <<<<<<<<<<<<<<
 *         return clTensor
 *     else:
 */
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v_clTensor), __pyx_n_s_copy); if (unlikely(!__pyx_t_6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 280; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_2 = NULL;
    if (CYTHON_COMPILING_IN_CPYTHON && likely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_6);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_6, function);
      }
    }
    if (!__pyx_t_2) {
      __pyx_t_7 = __Pyx_PyObject_CallOneArg(__pyx_t_6, ((PyObject *)__pyx_v_floatTensor)); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 280; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
    } else {
      __pyx_t_1 = PyTuple_New(1+1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 280; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2); __Pyx_GIVEREF(__pyx_t_2); __pyx_t_2 = NULL;
      __Pyx_INCREF(((PyObject *)__pyx_v_floatTensor));
      PyTuple_SET_ITEM(__pyx_t_1, 0+1, ((PyObject *)__pyx_v_floatTensor));
      __Pyx_GIVEREF(((PyObject *)__pyx_v_floatTensor));
      __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_1, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 280; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    }
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;

    /* "PyCudaTorch.pyx":281
 *             raise Exception('not implemented')
 *         clTensor.copy(floatTensor)
 *         return clTensor             # <<<<<<<<<<<<<<
 *     else:
 *         return CudaTensor()
 */
    __Pyx_XDECREF(__pyx_r);
    __Pyx_INCREF(((PyObject *)__pyx_v_clTensor));
    __pyx_r = ((PyObject *)__pyx_v_clTensor);
    goto __pyx_L0;
  }
  /*else*/ {

    /* "PyCudaTorch.pyx":283
 *         return clTensor
 *     else:
 *         return CudaTensor()             # <<<<<<<<<<<<<<
 * 
 * import floattensor_patch
 */
    __Pyx_XDECREF(__pyx_r);
    __pyx_t_7 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaTensor)), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 283; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_r = __pyx_t_7;
    __pyx_t_7 = 0;
    goto __pyx_L0;
  }

  /* "PyCudaTorch.pyx":265
 *         return CudaTensor()
 * 
 * def DoubleTensorToCudaTensor(PyTorch._DoubleTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("PyCudaTorch.DoubleTensorToCudaTensor", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_size);
  __Pyx_XDECREF((PyObject *)__pyx_v_clTensor);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "PyCudaTorch.pyx":300
 * cdef CudaGlobalState cudaGlobalState
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global cudaGlobalState
 *     cdef THCState *state2
 */

/* Python wrapper */
static PyObject *__pyx_pw_11PyCudaTorch_11init(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyMethodDef __pyx_mdef_11PyCudaTorch_11init = {"init", (PyCFunction)__pyx_pw_11PyCudaTorch_11init, METH_NOARGS, 0};
static PyObject *__pyx_pw_11PyCudaTorch_11init(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("init (wrapper)", 0);
  __pyx_r = __pyx_pf_11PyCudaTorch_10init(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_11PyCudaTorch_10init(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("init", 0);

  /* "PyCudaTorch.pyx":303
 *     global cudaGlobalState
 *     cdef THCState *state2
 *     print('initializing PyCudaTorch...')             # <<<<<<<<<<<<<<
 *     require(globalState.L, 'cutorch')
 *     print('loaded cutorch')
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_print, __pyx_tuple__6, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 303; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":304
 *     cdef THCState *state2
 *     print('initializing PyCudaTorch...')
 *     require(globalState.L, 'cutorch')             # <<<<<<<<<<<<<<
 *     print('loaded cutorch')
 *     require(globalState.L, 'cunn')
 */
  require(__pyx_v_11PyCudaTorch_globalState->L, __pyx_k_cutorch);

  /* "PyCudaTorch.pyx":305
 *     print('initializing PyCudaTorch...')
 *     require(globalState.L, 'cutorch')
 *     print('loaded cutorch')             # <<<<<<<<<<<<<<
 *     require(globalState.L, 'cunn')
 *     print('loaded cunn')
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_print, __pyx_tuple__7, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 305; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":306
 *     require(globalState.L, 'cutorch')
 *     print('loaded cutorch')
 *     require(globalState.L, 'cunn')             # <<<<<<<<<<<<<<
 *     print('loaded cunn')
 *     cudaGlobalState = CudaGlobalState()
 */
  require(__pyx_v_11PyCudaTorch_globalState->L, __pyx_k_cunn);

  /* "PyCudaTorch.pyx":307
 *     print('loaded cutorch')
 *     require(globalState.L, 'cunn')
 *     print('loaded cunn')             # <<<<<<<<<<<<<<
 *     cudaGlobalState = CudaGlobalState()
 *     cudaGlobalState.state = getState(globalState.L)
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_print, __pyx_tuple__8, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 307; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":308
 *     require(globalState.L, 'cunn')
 *     print('loaded cunn')
 *     cudaGlobalState = CudaGlobalState()             # <<<<<<<<<<<<<<
 *     cudaGlobalState.state = getState(globalState.L)
 *     print(' ... PyCudaTorch initialized')
 */
  __pyx_t_1 = __Pyx_PyObject_Call(((PyObject *)((PyObject*)__pyx_ptype_11PyCudaTorch_CudaGlobalState)), __pyx_empty_tuple, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 308; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_XGOTREF(((PyObject *)__pyx_v_11PyCudaTorch_cudaGlobalState));
  __Pyx_DECREF_SET(__pyx_v_11PyCudaTorch_cudaGlobalState, ((struct __pyx_obj_11PyCudaTorch_CudaGlobalState *)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":309
 *     print('loaded cunn')
 *     cudaGlobalState = CudaGlobalState()
 *     cudaGlobalState.state = getState(globalState.L)             # <<<<<<<<<<<<<<
 *     print(' ... PyCudaTorch initialized')
 * 
 */
  __pyx_v_11PyCudaTorch_cudaGlobalState->state = getState(__pyx_v_11PyCudaTorch_globalState->L);

  /* "PyCudaTorch.pyx":310
 *     cudaGlobalState = CudaGlobalState()
 *     cudaGlobalState.state = getState(globalState.L)
 *     print(' ... PyCudaTorch initialized')             # <<<<<<<<<<<<<<
 * 
 * init()
 */
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_print, __pyx_tuple__9, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 310; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":300
 * cdef CudaGlobalState cudaGlobalState
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global cudaGlobalState
 *     cdef THCState *state2
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("PyCudaTorch.init", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":91
 *             __data_union data
 * 
 *         def __getbuffer__(self, Py_buffer* info, int flags):             # <<<<<<<<<<<<<<
 *             # This implementation of getbuffer is geared towards Cython
 *             # requirements, and does not yet fullfill the PEP.
 */

/* Python wrapper */
static CYTHON_UNUSED int __pyx_pw_7cpython_5array_5array_1__getbuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags); /*proto*/
static CYTHON_UNUSED int __pyx_pw_7cpython_5array_5array_1__getbuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info, int __pyx_v_flags) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__getbuffer__ (wrapper)", 0);
  __pyx_r = __pyx_pf_7cpython_5array_5array___getbuffer__(((arrayobject *)__pyx_v_self), ((Py_buffer *)__pyx_v_info), ((int)__pyx_v_flags));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_7cpython_5array_5array___getbuffer__(arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info, CYTHON_UNUSED int __pyx_v_flags) {
  PyObject *__pyx_v_item_count = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  char *__pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__getbuffer__", 0);
  if (__pyx_v_info != NULL) {
    __pyx_v_info->obj = Py_None; __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(__pyx_v_info->obj);
  }

  /* "cpython/array.pxd":96
 *             # In particular strided access is always provided regardless
 *             # of flags
 *             item_count = Py_SIZE(self)             # <<<<<<<<<<<<<<
 * 
 *             info.suboffsets = NULL
 */
  __pyx_t_1 = PyInt_FromSsize_t(Py_SIZE(((PyObject *)__pyx_v_self))); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 96; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_item_count = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "cpython/array.pxd":98
 *             item_count = Py_SIZE(self)
 * 
 *             info.suboffsets = NULL             # <<<<<<<<<<<<<<
 *             info.buf = self.data.as_chars
 *             info.readonly = 0
 */
  __pyx_v_info->suboffsets = NULL;

  /* "cpython/array.pxd":99
 * 
 *             info.suboffsets = NULL
 *             info.buf = self.data.as_chars             # <<<<<<<<<<<<<<
 *             info.readonly = 0
 *             info.ndim = 1
 */
  __pyx_t_2 = __pyx_v_self->data.as_chars;
  __pyx_v_info->buf = __pyx_t_2;

  /* "cpython/array.pxd":100
 *             info.suboffsets = NULL
 *             info.buf = self.data.as_chars
 *             info.readonly = 0             # <<<<<<<<<<<<<<
 *             info.ndim = 1
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)
 */
  __pyx_v_info->readonly = 0;

  /* "cpython/array.pxd":101
 *             info.buf = self.data.as_chars
 *             info.readonly = 0
 *             info.ndim = 1             # <<<<<<<<<<<<<<
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)
 *             info.len = info.itemsize * item_count
 */
  __pyx_v_info->ndim = 1;

  /* "cpython/array.pxd":102
 *             info.readonly = 0
 *             info.ndim = 1
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)             # <<<<<<<<<<<<<<
 *             info.len = info.itemsize * item_count
 * 
 */
  __pyx_t_3 = __pyx_v_self->ob_descr->itemsize;
  __pyx_v_info->itemsize = __pyx_t_3;

  /* "cpython/array.pxd":103
 *             info.ndim = 1
 *             info.itemsize = self.ob_descr.itemsize   # e.g. sizeof(float)
 *             info.len = info.itemsize * item_count             # <<<<<<<<<<<<<<
 * 
 *             info.shape = <Py_ssize_t*> PyMem_Malloc(sizeof(Py_ssize_t) + 2)
 */
  __pyx_t_1 = PyInt_FromSsize_t(__pyx_v_info->itemsize); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 103; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyNumber_Multiply(__pyx_t_1, __pyx_v_item_count); if (unlikely(!__pyx_t_4)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 103; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_5 = __Pyx_PyIndex_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 103; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_info->len = __pyx_t_5;

  /* "cpython/array.pxd":105
 *             info.len = info.itemsize * item_count
 * 
 *             info.shape = <Py_ssize_t*> PyMem_Malloc(sizeof(Py_ssize_t) + 2)             # <<<<<<<<<<<<<<
 *             if not info.shape:
 *                 raise MemoryError()
 */
  __pyx_v_info->shape = ((Py_ssize_t *)PyMem_Malloc(((sizeof(Py_ssize_t)) + 2)));

  /* "cpython/array.pxd":106
 * 
 *             info.shape = <Py_ssize_t*> PyMem_Malloc(sizeof(Py_ssize_t) + 2)
 *             if not info.shape:             # <<<<<<<<<<<<<<
 *                 raise MemoryError()
 *             info.shape[0] = item_count      # constant regardless of resizing
 */
  __pyx_t_6 = ((!(__pyx_v_info->shape != 0)) != 0);
  if (__pyx_t_6) {

    /* "cpython/array.pxd":107
 *             info.shape = <Py_ssize_t*> PyMem_Malloc(sizeof(Py_ssize_t) + 2)
 *             if not info.shape:
 *                 raise MemoryError()             # <<<<<<<<<<<<<<
 *             info.shape[0] = item_count      # constant regardless of resizing
 *             info.strides = &info.itemsize
 */
    PyErr_NoMemory(); {__pyx_filename = __pyx_f[1]; __pyx_lineno = 107; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }

  /* "cpython/array.pxd":108
 *             if not info.shape:
 *                 raise MemoryError()
 *             info.shape[0] = item_count      # constant regardless of resizing             # <<<<<<<<<<<<<<
 *             info.strides = &info.itemsize
 * 
 */
  __pyx_t_5 = __Pyx_PyIndex_AsSsize_t(__pyx_v_item_count); if (unlikely((__pyx_t_5 == (Py_ssize_t)-1) && PyErr_Occurred())) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 108; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  (__pyx_v_info->shape[0]) = __pyx_t_5;

  /* "cpython/array.pxd":109
 *                 raise MemoryError()
 *             info.shape[0] = item_count      # constant regardless of resizing
 *             info.strides = &info.itemsize             # <<<<<<<<<<<<<<
 * 
 *             info.format = <char*> (info.shape + 1)
 */
  __pyx_v_info->strides = (&__pyx_v_info->itemsize);

  /* "cpython/array.pxd":111
 *             info.strides = &info.itemsize
 * 
 *             info.format = <char*> (info.shape + 1)             # <<<<<<<<<<<<<<
 *             info.format[0] = self.ob_descr.typecode
 *             info.format[1] = 0
 */
  __pyx_v_info->format = ((char *)(__pyx_v_info->shape + 1));

  /* "cpython/array.pxd":112
 * 
 *             info.format = <char*> (info.shape + 1)
 *             info.format[0] = self.ob_descr.typecode             # <<<<<<<<<<<<<<
 *             info.format[1] = 0
 *             info.obj = self
 */
  __pyx_t_3 = __pyx_v_self->ob_descr->typecode;
  (__pyx_v_info->format[0]) = __pyx_t_3;

  /* "cpython/array.pxd":113
 *             info.format = <char*> (info.shape + 1)
 *             info.format[0] = self.ob_descr.typecode
 *             info.format[1] = 0             # <<<<<<<<<<<<<<
 *             info.obj = self
 * 
 */
  (__pyx_v_info->format[1]) = 0;

  /* "cpython/array.pxd":114
 *             info.format[0] = self.ob_descr.typecode
 *             info.format[1] = 0
 *             info.obj = self             # <<<<<<<<<<<<<<
 * 
 *         def __releasebuffer__(self, Py_buffer* info):
 */
  __Pyx_INCREF(((PyObject *)__pyx_v_self));
  __Pyx_GIVEREF(((PyObject *)__pyx_v_self));
  __Pyx_GOTREF(__pyx_v_info->obj);
  __Pyx_DECREF(__pyx_v_info->obj);
  __pyx_v_info->obj = ((PyObject *)__pyx_v_self);

  /* "cpython/array.pxd":91
 *             __data_union data
 * 
 *         def __getbuffer__(self, Py_buffer* info, int flags):             # <<<<<<<<<<<<<<
 *             # This implementation of getbuffer is geared towards Cython
 *             # requirements, and does not yet fullfill the PEP.
 */

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("cpython.array.array.__getbuffer__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  if (__pyx_v_info != NULL && __pyx_v_info->obj != NULL) {
    __Pyx_GOTREF(__pyx_v_info->obj);
    __Pyx_DECREF(__pyx_v_info->obj); __pyx_v_info->obj = NULL;
  }
  goto __pyx_L2;
  __pyx_L0:;
  if (__pyx_v_info != NULL && __pyx_v_info->obj == Py_None) {
    __Pyx_GOTREF(Py_None);
    __Pyx_DECREF(Py_None); __pyx_v_info->obj = NULL;
  }
  __pyx_L2:;
  __Pyx_XDECREF(__pyx_v_item_count);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":116
 *             info.obj = self
 * 
 *         def __releasebuffer__(self, Py_buffer* info):             # <<<<<<<<<<<<<<
 *             PyMem_Free(info.shape)
 * 
 */

/* Python wrapper */
static CYTHON_UNUSED void __pyx_pw_7cpython_5array_5array_3__releasebuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info); /*proto*/
static CYTHON_UNUSED void __pyx_pw_7cpython_5array_5array_3__releasebuffer__(PyObject *__pyx_v_self, Py_buffer *__pyx_v_info) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__releasebuffer__ (wrapper)", 0);
  __pyx_pf_7cpython_5array_5array_2__releasebuffer__(((arrayobject *)__pyx_v_self), ((Py_buffer *)__pyx_v_info));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_7cpython_5array_5array_2__releasebuffer__(CYTHON_UNUSED arrayobject *__pyx_v_self, Py_buffer *__pyx_v_info) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__releasebuffer__", 0);

  /* "cpython/array.pxd":117
 * 
 *         def __releasebuffer__(self, Py_buffer* info):
 *             PyMem_Free(info.shape)             # <<<<<<<<<<<<<<
 * 
 *     array newarrayobject(PyTypeObject* type, Py_ssize_t size, arraydescr *descr)
 */
  PyMem_Free(__pyx_v_info->shape);

  /* "cpython/array.pxd":116
 *             info.obj = self
 * 
 *         def __releasebuffer__(self, Py_buffer* info):             # <<<<<<<<<<<<<<
 *             PyMem_Free(info.shape)
 * 
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

/* "cpython/array.pxd":128
 * 
 * 
 * cdef inline array clone(array template, Py_ssize_t length, bint zero):             # <<<<<<<<<<<<<<
 *     """ fast creation of a new array, given a template array.
 *     type will be same as template.
 */

static CYTHON_INLINE arrayobject *__pyx_f_7cpython_5array_clone(arrayobject *__pyx_v_template, Py_ssize_t __pyx_v_length, int __pyx_v_zero) {
  arrayobject *__pyx_v_op = NULL;
  arrayobject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("clone", 0);

  /* "cpython/array.pxd":132
 *     type will be same as template.
 *     if zero is true, new array will be initialized with zeroes."""
 *     op = newarrayobject(Py_TYPE(template), length, template.ob_descr)             # <<<<<<<<<<<<<<
 *     if zero and op is not None:
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)
 */
  __pyx_t_1 = ((PyObject *)newarrayobject(Py_TYPE(((PyObject *)__pyx_v_template)), __pyx_v_length, __pyx_v_template->ob_descr)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 132; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_op = ((arrayobject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cpython/array.pxd":133
 *     if zero is true, new array will be initialized with zeroes."""
 *     op = newarrayobject(Py_TYPE(template), length, template.ob_descr)
 *     if zero and op is not None:             # <<<<<<<<<<<<<<
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)
 *     return op
 */
  __pyx_t_3 = (__pyx_v_zero != 0);
  if (__pyx_t_3) {
  } else {
    __pyx_t_2 = __pyx_t_3;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = (((PyObject *)__pyx_v_op) != Py_None);
  __pyx_t_4 = (__pyx_t_3 != 0);
  __pyx_t_2 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_2) {

    /* "cpython/array.pxd":134
 *     op = newarrayobject(Py_TYPE(template), length, template.ob_descr)
 *     if zero and op is not None:
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)             # <<<<<<<<<<<<<<
 *     return op
 * 
 */
    memset(__pyx_v_op->data.as_chars, 0, (__pyx_v_length * __pyx_v_op->ob_descr->itemsize));
    goto __pyx_L3;
  }
  __pyx_L3:;

  /* "cpython/array.pxd":135
 *     if zero and op is not None:
 *         memset(op.data.as_chars, 0, length * op.ob_descr.itemsize)
 *     return op             # <<<<<<<<<<<<<<
 * 
 * cdef inline array copy(array self):
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_op));
  __pyx_r = __pyx_v_op;
  goto __pyx_L0;

  /* "cpython/array.pxd":128
 * 
 * 
 * cdef inline array clone(array template, Py_ssize_t length, bint zero):             # <<<<<<<<<<<<<<
 *     """ fast creation of a new array, given a template array.
 *     type will be same as template.
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cpython.array.clone", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_op);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":137
 *     return op
 * 
 * cdef inline array copy(array self):             # <<<<<<<<<<<<<<
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 */

static CYTHON_INLINE arrayobject *__pyx_f_7cpython_5array_copy(arrayobject *__pyx_v_self) {
  arrayobject *__pyx_v_op = NULL;
  arrayobject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("copy", 0);

  /* "cpython/array.pxd":139
 * cdef inline array copy(array self):
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)             # <<<<<<<<<<<<<<
 *     memcpy(op.data.as_chars, self.data.as_chars, Py_SIZE(op) * op.ob_descr.itemsize)
 *     return op
 */
  __pyx_t_1 = ((PyObject *)newarrayobject(Py_TYPE(((PyObject *)__pyx_v_self)), Py_SIZE(((PyObject *)__pyx_v_self)), __pyx_v_self->ob_descr)); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 139; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_op = ((arrayobject *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cpython/array.pxd":140
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 *     memcpy(op.data.as_chars, self.data.as_chars, Py_SIZE(op) * op.ob_descr.itemsize)             # <<<<<<<<<<<<<<
 *     return op
 * 
 */
  memcpy(__pyx_v_op->data.as_chars, __pyx_v_self->data.as_chars, (Py_SIZE(((PyObject *)__pyx_v_op)) * __pyx_v_op->ob_descr->itemsize));

  /* "cpython/array.pxd":141
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 *     memcpy(op.data.as_chars, self.data.as_chars, Py_SIZE(op) * op.ob_descr.itemsize)
 *     return op             # <<<<<<<<<<<<<<
 * 
 * cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1:
 */
  __Pyx_XDECREF(((PyObject *)__pyx_r));
  __Pyx_INCREF(((PyObject *)__pyx_v_op));
  __pyx_r = __pyx_v_op;
  goto __pyx_L0;

  /* "cpython/array.pxd":137
 *     return op
 * 
 * cdef inline array copy(array self):             # <<<<<<<<<<<<<<
 *     """ make a copy of an array. """
 *     op = newarrayobject(Py_TYPE(self), Py_SIZE(self), self.ob_descr)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cpython.array.copy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v_op);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":143
 *     return op
 * 
 * cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1:             # <<<<<<<<<<<<<<
 *     """ efficent appending of new stuff of same type
 *     (e.g. of same array type)
 */

static CYTHON_INLINE int __pyx_f_7cpython_5array_extend_buffer(arrayobject *__pyx_v_self, char *__pyx_v_stuff, Py_ssize_t __pyx_v_n) {
  Py_ssize_t __pyx_v_itemsize;
  Py_ssize_t __pyx_v_origsize;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("extend_buffer", 0);

  /* "cpython/array.pxd":147
 *     (e.g. of same array type)
 *     n: number of elements (not number of bytes!) """
 *     cdef Py_ssize_t itemsize = self.ob_descr.itemsize             # <<<<<<<<<<<<<<
 *     cdef Py_ssize_t origsize = Py_SIZE(self)
 *     resize_smart(self, origsize + n)
 */
  __pyx_t_1 = __pyx_v_self->ob_descr->itemsize;
  __pyx_v_itemsize = __pyx_t_1;

  /* "cpython/array.pxd":148
 *     n: number of elements (not number of bytes!) """
 *     cdef Py_ssize_t itemsize = self.ob_descr.itemsize
 *     cdef Py_ssize_t origsize = Py_SIZE(self)             # <<<<<<<<<<<<<<
 *     resize_smart(self, origsize + n)
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)
 */
  __pyx_v_origsize = Py_SIZE(((PyObject *)__pyx_v_self));

  /* "cpython/array.pxd":149
 *     cdef Py_ssize_t itemsize = self.ob_descr.itemsize
 *     cdef Py_ssize_t origsize = Py_SIZE(self)
 *     resize_smart(self, origsize + n)             # <<<<<<<<<<<<<<
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)
 *     return 0
 */
  __pyx_t_1 = resize_smart(__pyx_v_self, (__pyx_v_origsize + __pyx_v_n)); if (unlikely(__pyx_t_1 == -1)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 149; __pyx_clineno = __LINE__; goto __pyx_L1_error;}

  /* "cpython/array.pxd":150
 *     cdef Py_ssize_t origsize = Py_SIZE(self)
 *     resize_smart(self, origsize + n)
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)             # <<<<<<<<<<<<<<
 *     return 0
 * 
 */
  memcpy((__pyx_v_self->data.as_chars + (__pyx_v_origsize * __pyx_v_itemsize)), __pyx_v_stuff, (__pyx_v_n * __pyx_v_itemsize));

  /* "cpython/array.pxd":151
 *     resize_smart(self, origsize + n)
 *     memcpy(self.data.as_chars + origsize * itemsize, stuff, n * itemsize)
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * cdef inline int extend(array self, array other) except -1:
 */
  __pyx_r = 0;
  goto __pyx_L0;

  /* "cpython/array.pxd":143
 *     return op
 * 
 * cdef inline int extend_buffer(array self, char* stuff, Py_ssize_t n) except -1:             # <<<<<<<<<<<<<<
 *     """ efficent appending of new stuff of same type
 *     (e.g. of same array type)
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cpython.array.extend_buffer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":153
 *     return 0
 * 
 * cdef inline int extend(array self, array other) except -1:             # <<<<<<<<<<<<<<
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 */

static CYTHON_INLINE int __pyx_f_7cpython_5array_extend(arrayobject *__pyx_v_self, arrayobject *__pyx_v_other) {
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("extend", 0);

  /* "cpython/array.pxd":155
 * cdef inline int extend(array self, array other) except -1:
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:             # <<<<<<<<<<<<<<
 *         PyErr_BadArgument()
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 */
  __pyx_t_1 = ((__pyx_v_self->ob_descr->typecode != __pyx_v_other->ob_descr->typecode) != 0);
  if (__pyx_t_1) {

    /* "cpython/array.pxd":156
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 *         PyErr_BadArgument()             # <<<<<<<<<<<<<<
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 * 
 */
    __pyx_t_2 = PyErr_BadArgument(); if (unlikely(__pyx_t_2 == 0)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 156; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    goto __pyx_L3;
  }
  __pyx_L3:;

  /* "cpython/array.pxd":157
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 *         PyErr_BadArgument()
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))             # <<<<<<<<<<<<<<
 * 
 * cdef inline void zero(array self):
 */
  __pyx_t_2 = __pyx_f_7cpython_5array_extend_buffer(__pyx_v_self, __pyx_v_other->data.as_chars, Py_SIZE(((PyObject *)__pyx_v_other))); if (unlikely(__pyx_t_2 == -1)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 157; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_r = __pyx_t_2;
  goto __pyx_L0;

  /* "cpython/array.pxd":153
 *     return 0
 * 
 * cdef inline int extend(array self, array other) except -1:             # <<<<<<<<<<<<<<
 *     """ extend array with data from another array; types must match. """
 *     if self.ob_descr.typecode != other.ob_descr.typecode:
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cpython.array.extend", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cpython/array.pxd":159
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 * 
 * cdef inline void zero(array self):             # <<<<<<<<<<<<<<
 *     """ set all elements of array to zero. """
 *     memset(self.data.as_chars, 0, Py_SIZE(self) * self.ob_descr.itemsize)
 */

static CYTHON_INLINE void __pyx_f_7cpython_5array_zero(arrayobject *__pyx_v_self) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("zero", 0);

  /* "cpython/array.pxd":161
 * cdef inline void zero(array self):
 *     """ set all elements of array to zero. """
 *     memset(self.data.as_chars, 0, Py_SIZE(self) * self.ob_descr.itemsize)             # <<<<<<<<<<<<<<
 */
  memset(__pyx_v_self->data.as_chars, 0, (Py_SIZE(((PyObject *)__pyx_v_self)) * __pyx_v_self->ob_descr->itemsize));

  /* "cpython/array.pxd":159
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 * 
 * cdef inline void zero(array self):             # <<<<<<<<<<<<<<
 *     """ set all elements of array to zero. """
 *     memset(self.data.as_chars, 0, Py_SIZE(self) * self.ob_descr.itemsize)
 */

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}
static struct __pyx_vtabstruct_11PyCudaTorch_CudaTensor __pyx_vtable_11PyCudaTorch_CudaTensor;

static PyObject *__pyx_tp_new_11PyCudaTorch_CudaTensor(PyTypeObject *t, PyObject *a, PyObject *k) {
  struct __pyx_obj_11PyCudaTorch_CudaTensor *p;
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  p = ((struct __pyx_obj_11PyCudaTorch_CudaTensor *)o);
  p->__pyx_vtab = __pyx_vtabptr_11PyCudaTorch_CudaTensor;
  if (unlikely(__pyx_pw_11PyCudaTorch_10CudaTensor_1__cinit__(o, a, k) < 0)) {
    Py_DECREF(o); o = 0;
  }
  return o;
}

static void __pyx_tp_dealloc_11PyCudaTorch_CudaTensor(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    ++Py_REFCNT(o);
    __pyx_pw_11PyCudaTorch_10CudaTensor_3__dealloc__(o);
    --Py_REFCNT(o);
    PyErr_Restore(etype, eval, etb);
  }
  (*Py_TYPE(o)->tp_free)(o);
}
static PyObject *__pyx_sq_item_11PyCudaTorch_CudaTensor(PyObject *o, Py_ssize_t i) {
  PyObject *r;
  PyObject *x = PyInt_FromSsize_t(i); if(!x) return 0;
  r = Py_TYPE(o)->tp_as_mapping->mp_subscript(o, x);
  Py_DECREF(x);
  return r;
}

static int __pyx_mp_ass_subscript_11PyCudaTorch_CudaTensor(PyObject *o, PyObject *i, PyObject *v) {
  if (v) {
    return __pyx_pw_11PyCudaTorch_10CudaTensor_9__setitem__(o, i, v);
  }
  else {
    PyErr_Format(PyExc_NotImplementedError,
      "Subscript deletion not supported by %.200s", Py_TYPE(o)->tp_name);
    return -1;
  }
}

static PyMethodDef __pyx_methods_11PyCudaTorch_CudaTensor[] = {
  {"new", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_5new, METH_VARARGS|METH_KEYWORDS, 0},
  {"float", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_13float, METH_NOARGS, 0},
  {"copy", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_15copy, METH_O, 0},
  {"dims", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_17dims, METH_NOARGS, 0},
  {"size", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_19size, METH_NOARGS, 0},
  {"nElement", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_21nElement, METH_NOARGS, 0},
  {"sum", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_23sum, METH_NOARGS, 0},
  {"narrow", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_25narrow, METH_VARARGS|METH_KEYWORDS, 0},
  {"set1d", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_27set1d, METH_VARARGS|METH_KEYWORDS, 0},
  {"set2d", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_29set2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"get1d", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_31get1d, METH_O, 0},
  {"get2d", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_33get2d, METH_VARARGS|METH_KEYWORDS, 0},
  {"resize", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_39resize, METH_O, 0},
  {"resizeAs", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_41resizeAs, METH_O, 0},
  {"uniform", (PyCFunction)__pyx_pw_11PyCudaTorch_10CudaTensor_43uniform, METH_VARARGS|METH_KEYWORDS, 0},
  {0, 0, 0, 0}
};

static PyNumberMethods __pyx_tp_as_number_CudaTensor = {
  __pyx_pw_11PyCudaTorch_10CudaTensor_35__add__, /*nb_add*/
  0, /*nb_subtract*/
  0, /*nb_multiply*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_divide*/
  #endif
  0, /*nb_remainder*/
  0, /*nb_divmod*/
  0, /*nb_power*/
  0, /*nb_negative*/
  0, /*nb_positive*/
  0, /*nb_absolute*/
  0, /*nb_nonzero*/
  0, /*nb_invert*/
  0, /*nb_lshift*/
  0, /*nb_rshift*/
  0, /*nb_and*/
  0, /*nb_xor*/
  0, /*nb_or*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_coerce*/
  #endif
  0, /*nb_int*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_long*/
  #else
  0, /*reserved*/
  #endif
  0, /*nb_float*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_oct*/
  #endif
  #if PY_MAJOR_VERSION < 3
  0, /*nb_hex*/
  #endif
  0, /*nb_inplace_add*/
  0, /*nb_inplace_subtract*/
  0, /*nb_inplace_multiply*/
  #if PY_MAJOR_VERSION < 3
  0, /*nb_inplace_divide*/
  #endif
  0, /*nb_inplace_remainder*/
  0, /*nb_inplace_power*/
  0, /*nb_inplace_lshift*/
  0, /*nb_inplace_rshift*/
  0, /*nb_inplace_and*/
  0, /*nb_inplace_xor*/
  0, /*nb_inplace_or*/
  0, /*nb_floor_divide*/
  0, /*nb_true_divide*/
  0, /*nb_inplace_floor_divide*/
  0, /*nb_inplace_true_divide*/
  0, /*nb_index*/
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_matrix_multiply*/
  #endif
  #if PY_VERSION_HEX >= 0x03050000
  0, /*nb_inplace_matrix_multiply*/
  #endif
};

static PySequenceMethods __pyx_tp_as_sequence_CudaTensor = {
  0, /*sq_length*/
  0, /*sq_concat*/
  0, /*sq_repeat*/
  __pyx_sq_item_11PyCudaTorch_CudaTensor, /*sq_item*/
  0, /*sq_slice*/
  0, /*sq_ass_item*/
  0, /*sq_ass_slice*/
  0, /*sq_contains*/
  0, /*sq_inplace_concat*/
  0, /*sq_inplace_repeat*/
};

static PyMappingMethods __pyx_tp_as_mapping_CudaTensor = {
  0, /*mp_length*/
  __pyx_pw_11PyCudaTorch_10CudaTensor_37__getitem__, /*mp_subscript*/
  __pyx_mp_ass_subscript_11PyCudaTorch_CudaTensor, /*mp_ass_subscript*/
};

static PyTypeObject __pyx_type_11PyCudaTorch_CudaTensor = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyCudaTorch.CudaTensor", /*tp_name*/
  sizeof(struct __pyx_obj_11PyCudaTorch_CudaTensor), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_11PyCudaTorch_CudaTensor, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #else
  0, /*reserved*/
  #endif
  __pyx_pw_11PyCudaTorch_10CudaTensor_11__repr__, /*tp_repr*/
  &__pyx_tp_as_number_CudaTensor, /*tp_as_number*/
  &__pyx_tp_as_sequence_CudaTensor, /*tp_as_sequence*/
  &__pyx_tp_as_mapping_CudaTensor, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_11PyCudaTorch_CudaTensor, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_11PyCudaTorch_CudaTensor, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyObject *__pyx_tp_new_11PyCudaTorch_CudaGlobalState(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  PyObject *o;
  if (likely((t->tp_flags & Py_TPFLAGS_IS_ABSTRACT) == 0)) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  return o;
}

static void __pyx_tp_dealloc_11PyCudaTorch_CudaGlobalState(PyObject *o) {
  #if PY_VERSION_HEX >= 0x030400a1
  if (unlikely(Py_TYPE(o)->tp_finalize) && (!PyType_IS_GC(Py_TYPE(o)) || !_PyGC_FINALIZED(o))) {
    if (PyObject_CallFinalizerFromDealloc(o)) return;
  }
  #endif
  (*Py_TYPE(o)->tp_free)(o);
}

static PyTypeObject __pyx_type_11PyCudaTorch_CudaGlobalState = {
  PyVarObject_HEAD_INIT(0, 0)
  "PyCudaTorch.CudaGlobalState", /*tp_name*/
  sizeof(struct __pyx_obj_11PyCudaTorch_CudaGlobalState), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_11PyCudaTorch_CudaGlobalState, /*tp_dealloc*/
  0, /*tp_print*/
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  #if PY_MAJOR_VERSION < 3
  0, /*tp_compare*/
  #else
  0, /*reserved*/
  #endif
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE, /*tp_flags*/
  0, /*tp_doc*/
  0, /*tp_traverse*/
  0, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  0, /*tp_methods*/
  0, /*tp_members*/
  0, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  0, /*tp_dictoffset*/
  0, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_11PyCudaTorch_CudaGlobalState, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if PY_VERSION_HEX >= 0x030400a1
  0, /*tp_finalize*/
  #endif
};

static PyMethodDef __pyx_methods[] = {
  {"getPrediction", (PyCFunction)__pyx_pw_11PyCudaTorch_5getPrediction, METH_O, 0},
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
static struct PyModuleDef __pyx_moduledef = {
  #if PY_VERSION_HEX < 0x03020000
    { PyObject_HEAD_INIT(NULL) NULL, 0, NULL },
  #else
    PyModuleDef_HEAD_INIT,
  #endif
    "PyCudaTorch",
    0, /* m_doc */
    -1, /* m_size */
    __pyx_methods /* m_methods */,
    NULL, /* m_reload */
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_n_s_CudaTensor, __pyx_k_CudaTensor, sizeof(__pyx_k_CudaTensor), 0, 0, 1, 1},
  {&__pyx_n_s_DoubleTensorToCudaTensor, __pyx_k_DoubleTensorToCudaTensor, sizeof(__pyx_k_DoubleTensorToCudaTensor), 0, 0, 1, 1},
  {&__pyx_n_s_Exception, __pyx_k_Exception, sizeof(__pyx_k_Exception), 0, 0, 1, 1},
  {&__pyx_n_s_FloatTensor, __pyx_k_FloatTensor, sizeof(__pyx_k_FloatTensor), 0, 0, 1, 1},
  {&__pyx_n_s_FloatTensorToCudaTensor, __pyx_k_FloatTensorToCudaTensor, sizeof(__pyx_k_FloatTensorToCudaTensor), 0, 0, 1, 1},
  {&__pyx_n_s_MemoryError, __pyx_k_MemoryError, sizeof(__pyx_k_MemoryError), 0, 0, 1, 1},
  {&__pyx_kp_s_Not_implemented_for_dims, __pyx_k_Not_implemented_for_dims, sizeof(__pyx_k_Not_implemented_for_dims), 0, 0, 1, 0},
  {&__pyx_kp_s_Not_implemented_len_args, __pyx_k_Not_implemented_len_args, sizeof(__pyx_k_Not_implemented_len_args), 0, 0, 1, 0},
  {&__pyx_n_s_PyCudaTorch, __pyx_k_PyCudaTorch, sizeof(__pyx_k_PyCudaTorch), 0, 0, 1, 1},
  {&__pyx_kp_s_PyCudaTorch_initialized, __pyx_k_PyCudaTorch_initialized, sizeof(__pyx_k_PyCudaTorch_initialized), 0, 0, 1, 0},
  {&__pyx_n_s_PyTorch, __pyx_k_PyTorch, sizeof(__pyx_k_PyTorch), 0, 0, 1, 1},
  {&__pyx_n_s_a, __pyx_k_a, sizeof(__pyx_k_a), 0, 0, 1, 1},
  {&__pyx_n_s_allocate, __pyx_k_allocate, sizeof(__pyx_k_allocate), 0, 0, 1, 1},
  {&__pyx_n_s_array, __pyx_k_array, sizeof(__pyx_k_array), 0, 0, 1, 1},
  {&__pyx_n_s_b, __pyx_k_b, sizeof(__pyx_k_b), 0, 0, 1, 1},
  {&__pyx_kp_s_cannot_provide_arguments_to_init, __pyx_k_cannot_provide_arguments_to_init, sizeof(__pyx_k_cannot_provide_arguments_to_init), 0, 0, 1, 0},
  {&__pyx_n_s_clTensor, __pyx_k_clTensor, sizeof(__pyx_k_clTensor), 0, 0, 1, 1},
  {&__pyx_n_s_copy, __pyx_k_copy, sizeof(__pyx_k_copy), 0, 0, 1, 1},
  {&__pyx_n_s_cyPopCudaTensor, __pyx_k_cyPopCudaTensor, sizeof(__pyx_k_cyPopCudaTensor), 0, 0, 1, 1},
  {&__pyx_n_s_cyPushCudaTensor, __pyx_k_cyPushCudaTensor, sizeof(__pyx_k_cyPushCudaTensor), 0, 0, 1, 1},
  {&__pyx_kp_s_data_norep_git_pycudatorch_PyCu, __pyx_k_data_norep_git_pycudatorch_PyCu, sizeof(__pyx_k_data_norep_git_pycudatorch_PyCu), 0, 0, 1, 0},
  {&__pyx_n_s_dimension, __pyx_k_dimension, sizeof(__pyx_k_dimension), 0, 0, 1, 1},
  {&__pyx_n_s_dims, __pyx_k_dims, sizeof(__pyx_k_dims), 0, 0, 1, 1},
  {&__pyx_n_s_firstIndex, __pyx_k_firstIndex, sizeof(__pyx_k_firstIndex), 0, 0, 1, 1},
  {&__pyx_n_s_float, __pyx_k_float, sizeof(__pyx_k_float), 0, 0, 1, 1},
  {&__pyx_n_s_floatTensor, __pyx_k_floatTensor, sizeof(__pyx_k_floatTensor), 0, 0, 1, 1},
  {&__pyx_n_s_floattensor_patch, __pyx_k_floattensor_patch, sizeof(__pyx_k_floattensor_patch), 0, 0, 1, 1},
  {&__pyx_n_s_get1d, __pyx_k_get1d, sizeof(__pyx_k_get1d), 0, 0, 1, 1},
  {&__pyx_n_s_get2d, __pyx_k_get2d, sizeof(__pyx_k_get2d), 0, 0, 1, 1},
  {&__pyx_n_s_getGlobalState, __pyx_k_getGlobalState, sizeof(__pyx_k_getGlobalState), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_init, __pyx_k_init, sizeof(__pyx_k_init), 0, 0, 1, 1},
  {&__pyx_kp_s_initializing_PyCudaTorch, __pyx_k_initializing_PyCudaTorch, sizeof(__pyx_k_initializing_PyCudaTorch), 0, 0, 1, 0},
  {&__pyx_kp_s_loaded_cunn, __pyx_k_loaded_cunn, sizeof(__pyx_k_loaded_cunn), 0, 0, 1, 0},
  {&__pyx_kp_s_loaded_cutorch, __pyx_k_loaded_cutorch, sizeof(__pyx_k_loaded_cutorch), 0, 0, 1, 0},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_nElement, __pyx_k_nElement, sizeof(__pyx_k_nElement), 0, 0, 1, 1},
  {&__pyx_n_s_new, __pyx_k_new, sizeof(__pyx_k_new), 0, 0, 1, 1},
  {&__pyx_kp_s_not_implemented, __pyx_k_not_implemented, sizeof(__pyx_k_not_implemented), 0, 0, 1, 0},
  {&__pyx_n_s_print, __pyx_k_print, sizeof(__pyx_k_print), 0, 0, 1, 1},
  {&__pyx_n_s_pyx_vtable, __pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 0, 1, 1},
  {&__pyx_n_s_range, __pyx_k_range, sizeof(__pyx_k_range), 0, 0, 1, 1},
  {&__pyx_n_s_replace, __pyx_k_replace, sizeof(__pyx_k_replace), 0, 0, 1, 1},
  {&__pyx_n_s_repr, __pyx_k_repr, sizeof(__pyx_k_repr), 0, 0, 1, 1},
  {&__pyx_n_s_resize, __pyx_k_resize, sizeof(__pyx_k_resize), 0, 0, 1, 1},
  {&__pyx_n_s_set1d, __pyx_k_set1d, sizeof(__pyx_k_set1d), 0, 0, 1, 1},
  {&__pyx_n_s_set2d, __pyx_k_set2d, sizeof(__pyx_k_set2d), 0, 0, 1, 1},
  {&__pyx_n_s_size, __pyx_k_size, sizeof(__pyx_k_size), 0, 0, 1, 1},
  {&__pyx_n_s_state2, __pyx_k_state2, sizeof(__pyx_k_state2), 0, 0, 1, 1},
  {&__pyx_n_s_staticmethod, __pyx_k_staticmethod, sizeof(__pyx_k_staticmethod), 0, 0, 1, 1},
  {&__pyx_n_s_tensor, __pyx_k_tensor, sizeof(__pyx_k_tensor), 0, 0, 1, 1},
  {&__pyx_n_s_tensorC, __pyx_k_tensorC, sizeof(__pyx_k_tensorC), 0, 0, 1, 1},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_kp_s_type_not_recognized, __pyx_k_type_not_recognized, sizeof(__pyx_k_type_not_recognized), 0, 0, 1, 0},
  {&__pyx_n_s_uniform, __pyx_k_uniform, sizeof(__pyx_k_uniform), 0, 0, 1, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_x0, __pyx_k_x0, sizeof(__pyx_k_x0), 0, 0, 1, 1},
  {&__pyx_n_s_x1, __pyx_k_x1, sizeof(__pyx_k_x1), 0, 0, 1, 1},
  {0, 0, 0, 0, 0, 0, 0}
};
static int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_staticmethod = __Pyx_GetBuiltinName(__pyx_n_s_staticmethod); if (!__pyx_builtin_staticmethod) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 97; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_builtin_Exception = __Pyx_GetBuiltinName(__pyx_n_s_Exception); if (!__pyx_builtin_Exception) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 79; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_n_s_range); if (!__pyx_builtin_range) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 154; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_builtin_print = __Pyx_GetBuiltinName(__pyx_n_s_print); if (!__pyx_builtin_print) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 303; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_n_s_MemoryError); if (!__pyx_builtin_MemoryError) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 107; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  return 0;
  __pyx_L1_error:;
  return -1;
}

static int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "PyCudaTorch.pyx":79
 *             for arg in args:
 *                 if not isinstance(arg, int):
 *                     raise Exception('cannot provide arguments to initializer')             # <<<<<<<<<<<<<<
 *             if len(args) == 0:
 *                 self.native = THCudaTensor_new(cudaGlobalState.state)
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_cannot_provide_arguments_to_init); if (unlikely(!__pyx_tuple_)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 79; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "PyCudaTorch.pyx":113
 *             self.set1d(index, value)
 *         else:
 *             raise Exception("not implemented")             # <<<<<<<<<<<<<<
 * 
 *     def __repr__(CudaTensor self):
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 113; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "PyCudaTorch.pyx":118
 *         cdef PyTorch._FloatTensor floatTensor = self.float()
 *         floatRepr = floatTensor.__repr__()
 *         cudaRepr = floatRepr.replace('FloatTensor', 'CudaTensor')             # <<<<<<<<<<<<<<
 *         return cudaRepr
 * 
 */
  __pyx_tuple__3 = PyTuple_Pack(2, __pyx_n_s_FloatTensor, __pyx_n_s_CudaTensor); if (unlikely(!__pyx_tuple__3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 118; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__3);
  __Pyx_GIVEREF(__pyx_tuple__3);

  /* "PyCudaTorch.pyx":259
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 *         else:
 *             raise Exception('not implemented')             # <<<<<<<<<<<<<<
 *         clTensor.copy(floatTensor)
 *         return clTensor
 */
  __pyx_tuple__4 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__4)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 259; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);

  /* "PyCudaTorch.pyx":279
 *             clTensor = CudaTensor(int(size[0]), int(size[1]), int(size[2]), int(size[3]))
 *         else:
 *             raise Exception('not implemented')             # <<<<<<<<<<<<<<
 *         clTensor.copy(floatTensor)
 *         return clTensor
 */
  __pyx_tuple__5 = PyTuple_Pack(1, __pyx_kp_s_not_implemented); if (unlikely(!__pyx_tuple__5)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 279; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__5);
  __Pyx_GIVEREF(__pyx_tuple__5);

  /* "PyCudaTorch.pyx":303
 *     global cudaGlobalState
 *     cdef THCState *state2
 *     print('initializing PyCudaTorch...')             # <<<<<<<<<<<<<<
 *     require(globalState.L, 'cutorch')
 *     print('loaded cutorch')
 */
  __pyx_tuple__6 = PyTuple_Pack(1, __pyx_kp_s_initializing_PyCudaTorch); if (unlikely(!__pyx_tuple__6)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 303; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);

  /* "PyCudaTorch.pyx":305
 *     print('initializing PyCudaTorch...')
 *     require(globalState.L, 'cutorch')
 *     print('loaded cutorch')             # <<<<<<<<<<<<<<
 *     require(globalState.L, 'cunn')
 *     print('loaded cunn')
 */
  __pyx_tuple__7 = PyTuple_Pack(1, __pyx_kp_s_loaded_cutorch); if (unlikely(!__pyx_tuple__7)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 305; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__7);
  __Pyx_GIVEREF(__pyx_tuple__7);

  /* "PyCudaTorch.pyx":307
 *     print('loaded cutorch')
 *     require(globalState.L, 'cunn')
 *     print('loaded cunn')             # <<<<<<<<<<<<<<
 *     cudaGlobalState = CudaGlobalState()
 *     cudaGlobalState.state = getState(globalState.L)
 */
  __pyx_tuple__8 = PyTuple_Pack(1, __pyx_kp_s_loaded_cunn); if (unlikely(!__pyx_tuple__8)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 307; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__8);
  __Pyx_GIVEREF(__pyx_tuple__8);

  /* "PyCudaTorch.pyx":310
 *     cudaGlobalState = CudaGlobalState()
 *     cudaGlobalState.state = getState(globalState.L)
 *     print(' ... PyCudaTorch initialized')             # <<<<<<<<<<<<<<
 * 
 * init()
 */
  __pyx_tuple__9 = PyTuple_Pack(1, __pyx_kp_s_PyCudaTorch_initialized); if (unlikely(!__pyx_tuple__9)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 310; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__9);
  __Pyx_GIVEREF(__pyx_tuple__9);

  /* "PyCudaTorch.pyx":63
 *     void pushCudaTensor(THCState *state, lua_State *L, THCudaTensor *tensor)
 * 
 * def cyPopCudaTensor():             # <<<<<<<<<<<<<<
 *     cdef THCudaTensor *tensorC = popCudaTensor(globalState.L)
 *     cdef CudaTensor tensor = CudaTensor_fromNative(tensorC)
 */
  __pyx_tuple__10 = PyTuple_Pack(2, __pyx_n_s_tensorC, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__10)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 63; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__10);
  __Pyx_GIVEREF(__pyx_tuple__10);
  __pyx_codeobj__11 = (PyObject*)__Pyx_PyCode_New(0, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__10, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_data_norep_git_pycudatorch_PyCu, __pyx_n_s_cyPopCudaTensor, 63, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__11)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 63; __pyx_clineno = __LINE__; goto __pyx_L1_error;}

  /* "PyCudaTorch.pyx":68
 *     return tensor
 * 
 * def cyPushCudaTensor(CudaTensor tensor):             # <<<<<<<<<<<<<<
 *     pushCudaTensor(cudaGlobalState.state, globalState.L, tensor.native)
 * 
 */
  __pyx_tuple__12 = PyTuple_Pack(1, __pyx_n_s_tensor); if (unlikely(!__pyx_tuple__12)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 68; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__12);
  __Pyx_GIVEREF(__pyx_tuple__12);
  __pyx_codeobj__13 = (PyObject*)__Pyx_PyCode_New(1, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__12, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_data_norep_git_pycudatorch_PyCu, __pyx_n_s_cyPushCudaTensor, 68, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__13)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 68; __pyx_clineno = __LINE__; goto __pyx_L1_error;}

  /* "PyCudaTorch.pyx":98
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 *         return CudaTensor()
 * #        cdef THCudaTensor *newTensorC = THCudaTensor_new(cudaGlobalState.state)
 */
  __pyx_codeobj__14 = (PyObject*)__Pyx_PyCode_New(0, 0, 0, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_data_norep_git_pycudatorch_PyCu, __pyx_n_s_new, 98, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__14)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 98; __pyx_clineno = __LINE__; goto __pyx_L1_error;}

  /* "PyCudaTorch.pyx":245
 *     return tensor
 * 
 * def FloatTensorToCudaTensor(PyTorch._FloatTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */
  __pyx_tuple__15 = PyTuple_Pack(4, __pyx_n_s_floatTensor, __pyx_n_s_size, __pyx_n_s_clTensor, __pyx_n_s_nElement); if (unlikely(!__pyx_tuple__15)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 245; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__15);
  __Pyx_GIVEREF(__pyx_tuple__15);
  __pyx_codeobj__16 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__15, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_data_norep_git_pycudatorch_PyCu, __pyx_n_s_FloatTensorToCudaTensor, 245, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__16)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 245; __pyx_clineno = __LINE__; goto __pyx_L1_error;}

  /* "PyCudaTorch.pyx":265
 *         return CudaTensor()
 * 
 * def DoubleTensorToCudaTensor(PyTorch._DoubleTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */
  __pyx_tuple__17 = PyTuple_Pack(4, __pyx_n_s_floatTensor, __pyx_n_s_size, __pyx_n_s_clTensor, __pyx_n_s_nElement); if (unlikely(!__pyx_tuple__17)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 265; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__17);
  __Pyx_GIVEREF(__pyx_tuple__17);
  __pyx_codeobj__18 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__17, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_data_norep_git_pycudatorch_PyCu, __pyx_n_s_DoubleTensorToCudaTensor, 265, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__18)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 265; __pyx_clineno = __LINE__; goto __pyx_L1_error;}

  /* "PyCudaTorch.pyx":300
 * cdef CudaGlobalState cudaGlobalState
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global cudaGlobalState
 *     cdef THCState *state2
 */
  __pyx_tuple__19 = PyTuple_Pack(1, __pyx_n_s_state2); if (unlikely(!__pyx_tuple__19)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 300; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_tuple__19);
  __Pyx_GIVEREF(__pyx_tuple__19);
  __pyx_codeobj__20 = (PyObject*)__Pyx_PyCode_New(0, 0, 1, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__19, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_data_norep_git_pycudatorch_PyCu, __pyx_n_s_init, 300, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__20)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 300; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
  return 0;
  __pyx_L1_error:;
  return -1;
}

#if PY_MAJOR_VERSION < 3
PyMODINIT_FUNC initPyCudaTorch(void); /*proto*/
PyMODINIT_FUNC initPyCudaTorch(void)
#else
PyMODINIT_FUNC PyInit_PyCudaTorch(void); /*proto*/
PyMODINIT_FUNC PyInit_PyCudaTorch(void)
#endif
{
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  #if CYTHON_REFNANNY
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
  if (!__Pyx_RefNanny) {
      PyErr_Clear();
      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
      if (!__Pyx_RefNanny)
          Py_FatalError("failed to import 'refnanny' module");
  }
  #endif
  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_PyCudaTorch(void)", 0);
  if ( __Pyx_check_binary_version() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  #ifdef __Pyx_CyFunction_USED
  if (__Pyx_CyFunction_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("PyCudaTorch", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  #if CYTHON_COMPILING_IN_PYPY
  Py_INCREF(__pyx_b);
  #endif
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
  /*--- Initialize various global constants etc. ---*/
  if (unlikely(__Pyx_InitGlobals() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  #endif
  if (__pyx_module_is_main_PyCudaTorch) {
    if (PyObject_SetAttrString(__pyx_m, "__name__", __pyx_n_s_main) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;};
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    if (!PyDict_GetItemString(modules, "PyCudaTorch")) {
      if (unlikely(PyDict_SetItemString(modules, "PyCudaTorch", __pyx_m) < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (unlikely(__Pyx_InitCachedBuiltins() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  /*--- Constants init code ---*/
  if (unlikely(__Pyx_InitCachedConstants() < 0)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  /*--- Global init code ---*/
  __pyx_v_11PyCudaTorch_globalState = ((struct __pyx_obj_7PyTorch_GlobalState *)Py_None); Py_INCREF(Py_None);
  __pyx_v_11PyCudaTorch_cudaGlobalState = ((struct __pyx_obj_11PyCudaTorch_CudaGlobalState *)Py_None); Py_INCREF(Py_None);
  /*--- Variable export code ---*/
  /*--- Function export code ---*/
  /*--- Type init code ---*/
  __pyx_vtabptr_11PyCudaTorch_CudaTensor = &__pyx_vtable_11PyCudaTorch_CudaTensor;
  __pyx_vtable_11PyCudaTorch_CudaTensor.dims = (int (*)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int __pyx_skip_dispatch))__pyx_f_11PyCudaTorch_10CudaTensor_dims;
  __pyx_vtable_11PyCudaTorch_CudaTensor.set1d = (PyObject *(*)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, float, int __pyx_skip_dispatch))__pyx_f_11PyCudaTorch_10CudaTensor_set1d;
  __pyx_vtable_11PyCudaTorch_CudaTensor.set2d = (PyObject *(*)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, int, float, int __pyx_skip_dispatch))__pyx_f_11PyCudaTorch_10CudaTensor_set2d;
  __pyx_vtable_11PyCudaTorch_CudaTensor.get1d = (float (*)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, int __pyx_skip_dispatch))__pyx_f_11PyCudaTorch_10CudaTensor_get1d;
  __pyx_vtable_11PyCudaTorch_CudaTensor.get2d = (float (*)(struct __pyx_obj_11PyCudaTorch_CudaTensor *, int, int, int __pyx_skip_dispatch))__pyx_f_11PyCudaTorch_10CudaTensor_get2d;
  if (PyType_Ready(&__pyx_type_11PyCudaTorch_CudaTensor) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 71; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_type_11PyCudaTorch_CudaTensor.tp_print = 0;
  if (__Pyx_SetVtable(__pyx_type_11PyCudaTorch_CudaTensor.tp_dict, __pyx_vtabptr_11PyCudaTorch_CudaTensor) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 71; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  if (PyObject_SetAttrString(__pyx_m, "CudaTensor", (PyObject *)&__pyx_type_11PyCudaTorch_CudaTensor) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 71; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_11PyCudaTorch_CudaTensor = &__pyx_type_11PyCudaTorch_CudaTensor;
  if (PyType_Ready(&__pyx_type_11PyCudaTorch_CudaGlobalState) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 289; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_type_11PyCudaTorch_CudaGlobalState.tp_print = 0;
  if (PyObject_SetAttrString(__pyx_m, "CudaGlobalState", (PyObject *)&__pyx_type_11PyCudaTorch_CudaGlobalState) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 289; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_11PyCudaTorch_CudaGlobalState = &__pyx_type_11PyCudaTorch_CudaGlobalState;
  /*--- Type import code ---*/
  __pyx_ptype_7cpython_5array_array = __Pyx_ImportType("array", "array", sizeof(arrayobject), 0); if (unlikely(!__pyx_ptype_7cpython_5array_array)) {__pyx_filename = __pyx_f[1]; __pyx_lineno = 58; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7PyTorch__DoubleTensor = __Pyx_ImportType("PyTorch", "_DoubleTensor", sizeof(struct __pyx_obj_7PyTorch__DoubleTensor), 1); if (unlikely(!__pyx_ptype_7PyTorch__DoubleTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 21; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7PyTorch__DoubleTensor = (struct __pyx_vtabstruct_7PyTorch__DoubleTensor*)__Pyx_GetVtable(__pyx_ptype_7PyTorch__DoubleTensor->tp_dict); if (unlikely(!__pyx_vtabptr_7PyTorch__DoubleTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 21; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7PyTorch__ByteTensor = __Pyx_ImportType("PyTorch", "_ByteTensor", sizeof(struct __pyx_obj_7PyTorch__ByteTensor), 1); if (unlikely(!__pyx_ptype_7PyTorch__ByteTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 36; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7PyTorch__ByteTensor = (struct __pyx_vtabstruct_7PyTorch__ByteTensor*)__Pyx_GetVtable(__pyx_ptype_7PyTorch__ByteTensor->tp_dict); if (unlikely(!__pyx_vtabptr_7PyTorch__ByteTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 36; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7PyTorch__FloatTensor = __Pyx_ImportType("PyTorch", "_FloatTensor", sizeof(struct __pyx_obj_7PyTorch__FloatTensor), 1); if (unlikely(!__pyx_ptype_7PyTorch__FloatTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 51; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7PyTorch__FloatTensor = (struct __pyx_vtabstruct_7PyTorch__FloatTensor*)__Pyx_GetVtable(__pyx_ptype_7PyTorch__FloatTensor->tp_dict); if (unlikely(!__pyx_vtabptr_7PyTorch__FloatTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 51; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7PyTorch__LongTensor = __Pyx_ImportType("PyTorch", "_LongTensor", sizeof(struct __pyx_obj_7PyTorch__LongTensor), 1); if (unlikely(!__pyx_ptype_7PyTorch__LongTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 66; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7PyTorch__LongTensor = (struct __pyx_vtabstruct_7PyTorch__LongTensor*)__Pyx_GetVtable(__pyx_ptype_7PyTorch__LongTensor->tp_dict); if (unlikely(!__pyx_vtabptr_7PyTorch__LongTensor)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 66; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7PyTorch_GlobalState = __Pyx_ImportType("PyTorch", "GlobalState", sizeof(struct __pyx_obj_7PyTorch_GlobalState), 1); if (unlikely(!__pyx_ptype_7PyTorch_GlobalState)) {__pyx_filename = __pyx_f[2]; __pyx_lineno = 77; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7Storage__DoubleStorage = __Pyx_ImportType("Storage", "_DoubleStorage", sizeof(struct __pyx_obj_7Storage__DoubleStorage), 1); if (unlikely(!__pyx_ptype_7Storage__DoubleStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 80; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7Storage__DoubleStorage = (struct __pyx_vtabstruct_7Storage__DoubleStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__DoubleStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__DoubleStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 80; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7Storage__ByteStorage = __Pyx_ImportType("Storage", "_ByteStorage", sizeof(struct __pyx_obj_7Storage__ByteStorage), 1); if (unlikely(!__pyx_ptype_7Storage__ByteStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7Storage__ByteStorage = (struct __pyx_vtabstruct_7Storage__ByteStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__ByteStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__ByteStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 87; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7Storage__FloatStorage = __Pyx_ImportType("Storage", "_FloatStorage", sizeof(struct __pyx_obj_7Storage__FloatStorage), 1); if (unlikely(!__pyx_ptype_7Storage__FloatStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 94; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7Storage__FloatStorage = (struct __pyx_vtabstruct_7Storage__FloatStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__FloatStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__FloatStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 94; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_ptype_7Storage__LongStorage = __Pyx_ImportType("Storage", "_LongStorage", sizeof(struct __pyx_obj_7Storage__LongStorage), 1); if (unlikely(!__pyx_ptype_7Storage__LongStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 101; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __pyx_vtabptr_7Storage__LongStorage = (struct __pyx_vtabstruct_7Storage__LongStorage*)__Pyx_GetVtable(__pyx_ptype_7Storage__LongStorage->tp_dict); if (unlikely(!__pyx_vtabptr_7Storage__LongStorage)) {__pyx_filename = __pyx_f[3]; __pyx_lineno = 101; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  /*--- Variable import code ---*/
  /*--- Function import code ---*/
  /*--- Execution code ---*/

  /* "PyCudaTorch.pyx":7
 * 
 * cimport cpython.array
 * import array             # <<<<<<<<<<<<<<
 * 
 * import PyTorch
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_array, 0, -1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 7; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_array, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 7; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":9
 * import array
 * 
 * import PyTorch             # <<<<<<<<<<<<<<
 * cimport PyTorch
 * cimport Storage
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_PyTorch, 0, -1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 9; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_PyTorch, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 9; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":63
 *     void pushCudaTensor(THCState *state, lua_State *L, THCudaTensor *tensor)
 * 
 * def cyPopCudaTensor():             # <<<<<<<<<<<<<<
 *     cdef THCudaTensor *tensorC = popCudaTensor(globalState.L)
 *     cdef CudaTensor tensor = CudaTensor_fromNative(tensorC)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_11PyCudaTorch_1cyPopCudaTensor, NULL, __pyx_n_s_PyCudaTorch); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 63; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cyPopCudaTensor, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 63; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":68
 *     return tensor
 * 
 * def cyPushCudaTensor(CudaTensor tensor):             # <<<<<<<<<<<<<<
 *     pushCudaTensor(cudaGlobalState.state, globalState.L, tensor.native)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_11PyCudaTorch_3cyPushCudaTensor, NULL, __pyx_n_s_PyCudaTorch); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 68; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cyPushCudaTensor, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 68; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":98
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 *         return CudaTensor()
 * #        cdef THCudaTensor *newTensorC = THCudaTensor_new(cudaGlobalState.state)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_11PyCudaTorch_10CudaTensor_5new, NULL, __pyx_n_s_PyCudaTorch); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 98; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);

  /* "PyCudaTorch.pyx":97
 *         THCudaTensor_free(cudaGlobalState.state, self.native)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 *         return CudaTensor()
 */
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 97; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 97; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_11PyCudaTorch_CudaTensor->tp_dict, __pyx_n_s_new, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 98; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_11PyCudaTorch_CudaTensor);

  /* "PyCudaTorch.pyx":98
 * 
 *     @staticmethod
 *     def new():             # <<<<<<<<<<<<<<
 *         return CudaTensor()
 * #        cdef THCudaTensor *newTensorC = THCudaTensor_new(cudaGlobalState.state)
 */
  __pyx_t_1 = __Pyx_GetNameInClass((PyObject *)__pyx_ptype_11PyCudaTorch_CudaTensor, __pyx_n_s_new); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 98; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);

  /* "PyCudaTorch.pyx":97
 *         THCudaTensor_free(cudaGlobalState.state, self.native)
 * 
 *     @staticmethod             # <<<<<<<<<<<<<<
 *     def new():
 *         return CudaTensor()
 */
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 97; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_staticmethod, __pyx_t_2, NULL); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 97; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (PyDict_SetItem((PyObject *)__pyx_ptype_11PyCudaTorch_CudaTensor->tp_dict, __pyx_n_s_new, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 98; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  PyType_Modified(__pyx_ptype_11PyCudaTorch_CudaTensor);

  /* "PyCudaTorch.pyx":245
 *     return tensor
 * 
 * def FloatTensorToCudaTensor(PyTorch._FloatTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_11PyCudaTorch_7FloatTensorToCudaTensor, NULL, __pyx_n_s_PyCudaTorch); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 245; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_FloatTensorToCudaTensor, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 245; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":265
 *         return CudaTensor()
 * 
 * def DoubleTensorToCudaTensor(PyTorch._DoubleTensor floatTensor):             # <<<<<<<<<<<<<<
 *     cdef Storage._LongStorage size = floatTensor.size()
 *     cdef CudaTensor clTensor
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_11PyCudaTorch_9DoubleTensorToCudaTensor, NULL, __pyx_n_s_PyCudaTorch); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 265; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_DoubleTensorToCudaTensor, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 265; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":285
 *         return CudaTensor()
 * 
 * import floattensor_patch             # <<<<<<<<<<<<<<
 * 
 * cdef PyTorch.GlobalState globalState = PyTorch.getGlobalState()
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_floattensor_patch, 0, -1); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 285; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_floattensor_patch, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 285; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":287
 * import floattensor_patch
 * 
 * cdef PyTorch.GlobalState globalState = PyTorch.getGlobalState()             # <<<<<<<<<<<<<<
 * 
 * cdef class CudaGlobalState(object):
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_PyTorch); if (unlikely(!__pyx_t_2)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 287; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_getGlobalState); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 287; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (__pyx_t_2) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 287; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 287; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!(likely(((__pyx_t_1) == Py_None) || likely(__Pyx_TypeTest(__pyx_t_1, __pyx_ptype_7PyTorch_GlobalState))))) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 287; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_XGOTREF(((PyObject *)__pyx_v_11PyCudaTorch_globalState));
  __Pyx_DECREF_SET(__pyx_v_11PyCudaTorch_globalState, ((struct __pyx_obj_7PyTorch_GlobalState *)__pyx_t_1));
  __Pyx_GIVEREF(__pyx_t_1);
  __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":300
 * cdef CudaGlobalState cudaGlobalState
 * 
 * def init():             # <<<<<<<<<<<<<<
 *     global cudaGlobalState
 *     cdef THCState *state2
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_11PyCudaTorch_11init, NULL, __pyx_n_s_PyCudaTorch); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 300; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_init, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 300; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":312
 *     print(' ... PyCudaTorch initialized')
 * 
 * init()             # <<<<<<<<<<<<<<
 * 
 */
  __pyx_t_3 = __Pyx_GetModuleGlobalName(__pyx_n_s_init); if (unlikely(!__pyx_t_3)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 312; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = NULL;
  if (CYTHON_COMPILING_IN_CPYTHON && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
    }
  }
  if (__pyx_t_2) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 312; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else {
    __pyx_t_1 = __Pyx_PyObject_CallNoArg(__pyx_t_3); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 312; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  }
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "PyCudaTorch.pyx":1
 * from __future__ import print_function             # <<<<<<<<<<<<<<
 * 
 * import cython
 */
  __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_1) < 0) {__pyx_filename = __pyx_f[0]; __pyx_lineno = 1; __pyx_clineno = __LINE__; goto __pyx_L1_error;}
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cpython/array.pxd":159
 *     return extend_buffer(self, other.data.as_chars, Py_SIZE(other))
 * 
 * cdef inline void zero(array self):             # <<<<<<<<<<<<<<
 *     """ set all elements of array to zero. """
 *     memset(self.data.as_chars, 0, Py_SIZE(self) * self.ob_descr.itemsize)
 */

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init PyCudaTorch", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    Py_DECREF(__pyx_m); __pyx_m = 0;
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init PyCudaTorch");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if PY_MAJOR_VERSION < 3
  return;
  #else
  return __pyx_m;
  #endif
}

/* --- Runtime support code --- */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule((char *)modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

static CYTHON_INLINE int __Pyx_TypeTest(PyObject *obj, PyTypeObject *type) {
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    if (likely(PyObject_TypeCheck(obj, type)))
        return 1;
    PyErr_Format(PyExc_TypeError, "Cannot convert %.200s to %.200s",
                 Py_TYPE(obj)->tp_name, type->tp_name);
    return 0;
}

static void __Pyx_RaiseArgumentTypeInvalid(const char* name, PyObject *obj, PyTypeObject *type) {
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected %.200s, got %.200s)",
        name, type->tp_name, Py_TYPE(obj)->tp_name);
}
static CYTHON_INLINE int __Pyx_ArgTypeTest(PyObject *obj, PyTypeObject *type, int none_allowed,
    const char *name, int exact)
{
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    if (none_allowed && obj == Py_None) return 1;
    else if (exact) {
        if (likely(Py_TYPE(obj) == type)) return 1;
        #if PY_MAJOR_VERSION == 2
        else if ((type == &PyBaseString_Type) && likely(__Pyx_PyBaseString_CheckExact(obj))) return 1;
        #endif
    }
    else {
        if (likely(PyObject_TypeCheck(obj, type))) return 1;
    }
    __Pyx_RaiseArgumentTypeInvalid(name, obj, type);
    return 0;
}

static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_CheckExact(key)) || likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

static CYTHON_INLINE void __Pyx_ErrRestore(PyObject *type, PyObject *value, PyObject *tb) {
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyThreadState *tstate = PyThreadState_GET();
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#else
    PyErr_Restore(type, value, tb);
#endif
}
static CYTHON_INLINE void __Pyx_ErrFetch(PyObject **type, PyObject **value, PyObject **tb) {
#if CYTHON_COMPILING_IN_CPYTHON
    PyThreadState *tstate = PyThreadState_GET();
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#else
    PyErr_Fetch(type, value, tb);
#endif
}

#if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                if (PyObject_IsSubclass(instance_class, type)) {
                    type = instance_class;
                } else {
                    instance_class = NULL;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
#if PY_VERSION_HEX >= 0x03030000
    if (cause) {
#else
    if (cause && cause != Py_None) {
#endif
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(tmp_type, tmp_value, tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = PyThreadState_GET();
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck) {
#if CYTHON_COMPILING_IN_CPYTHON
    if (wraparound & unlikely(i < 0)) i += PyList_GET_SIZE(o);
    if ((!boundscheck) || likely((0 <= i) & (i < PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck) {
#if CYTHON_COMPILING_IN_CPYTHON
    if (wraparound & unlikely(i < 0)) i += PyTuple_GET_SIZE(o);
    if ((!boundscheck) || likely((0 <= i) & (i < PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck) {
#if CYTHON_COMPILING_IN_CPYTHON
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely((n >= 0) & (n < PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely((n >= 0) & (n < PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (PyErr_ExceptionMatches(PyExc_OverflowError))
                        PyErr_Clear();
                    else
                        return NULL;
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

static CYTHON_INLINE int __Pyx_CheckKeywordStrings(
    PyObject *kwdict,
    const char* function_name,
    int kw_allowed)
{
    PyObject* key = 0;
    Py_ssize_t pos = 0;
#if CYTHON_COMPILING_IN_PYPY
    if (!kw_allowed && PyDict_Next(kwdict, &pos, &key, 0))
        goto invalid_keyword;
    return 1;
#else
    while (PyDict_Next(kwdict, &pos, &key, 0)) {
        #if PY_MAJOR_VERSION < 3
        if (unlikely(!PyString_CheckExact(key)) && unlikely(!PyString_Check(key)))
        #endif
            if (unlikely(!PyUnicode_Check(key)))
                goto invalid_keyword_type;
    }
    if ((!kw_allowed) && unlikely(key))
        goto invalid_keyword;
    return 1;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    return 0;
#endif
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
    return 0;
}

#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

#if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || PyObject_TypeCheck(func, __pyx_CyFunctionType))) {
#else
    if (likely(PyCFunction_Check(func))) {
#endif
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject* args = PyTuple_Pack(1, arg);
    return (likely(args)) ? __Pyx_PyObject_Call(func, args, NULL) : NULL;
}
#endif

#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
#ifdef __Pyx_CyFunction_USED
    if (likely(PyCFunction_Check(func) || PyObject_TypeCheck(func, __pyx_CyFunctionType))) {
#else
    if (likely(PyCFunction_Check(func))) {
#endif
        if (likely(PyCFunction_GET_FLAGS(func) & METH_NOARGS)) {
            return __Pyx_PyObject_CallMethO(func, NULL);
        }
    }
    return __Pyx_PyObject_Call(func, __pyx_empty_tuple, NULL);
}
#endif

static void __Pyx_WriteUnraisable(const char *name, CYTHON_UNUSED int clineno,
                                  CYTHON_UNUSED int lineno, CYTHON_UNUSED const char *filename,
                                  int full_traceback) {
    PyObject *old_exc, *old_val, *old_tb;
    PyObject *ctx;
    __Pyx_ErrFetch(&old_exc, &old_val, &old_tb);
    if (full_traceback) {
        Py_XINCREF(old_exc);
        Py_XINCREF(old_val);
        Py_XINCREF(old_tb);
        __Pyx_ErrRestore(old_exc, old_val, old_tb);
        PyErr_PrintEx(1);
    }
    #if PY_MAJOR_VERSION < 3
    ctx = PyString_FromString(name);
    #else
    ctx = PyUnicode_FromString(name);
    #endif
    __Pyx_ErrRestore(old_exc, old_val, old_tb);
    if (!ctx) {
        PyErr_WriteUnraisable(Py_None);
    } else {
        PyErr_WriteUnraisable(ctx);
        Py_DECREF(ctx);
    }
}

static CYTHON_INLINE int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v) {
    int r;
    if (!j) return -1;
    r = PyObject_SetItem(o, j, v);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v,
                                               int is_list, int wraparound, int boundscheck) {
#if CYTHON_COMPILING_IN_CPYTHON
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = (!wraparound) ? i : ((likely(i >= 0)) ? i : i + PyList_GET_SIZE(o));
        if ((!boundscheck) || likely((n >= 0) & (n < PyList_GET_SIZE(o)))) {
            PyObject* old = PyList_GET_ITEM(o, n);
            Py_INCREF(v);
            PyList_SET_ITEM(o, n, v);
            Py_DECREF(old);
            return 1;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_ass_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (PyErr_ExceptionMatches(PyExc_OverflowError))
                        PyErr_Clear();
                    else
                        return -1;
                }
            }
            return m->sq_ass_item(o, i, v);
        }
    }
#else
#if CYTHON_COMPILING_IN_PYPY
    if (is_list || (PySequence_Check(o) && !PyDict_Check(o))) {
#else
    if (is_list || PySequence_Check(o)) {
#endif
        return PySequence_SetItem(o, i, v);
    }
#endif
    return __Pyx_SetItemInt_Generic(o, PyInt_FromSsize_t(i), v);
}

static int __Pyx_SetVtable(PyObject *dict, void *vtable) {
#if PY_VERSION_HEX >= 0x02070000
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
#else
    PyObject *ob = PyCObject_FromVoidPtr(vtable, 0);
#endif
    if (!ob)
        goto bad;
    if (PyDict_SetItem(dict, __pyx_n_s_pyx_vtable, ob) < 0)
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

static void* __Pyx_GetVtable(PyObject *dict) {
    void* ptr;
    PyObject *ob = PyObject_GetItem(dict, __pyx_n_s_pyx_vtable);
    if (!ob)
        goto bad;
#if PY_VERSION_HEX >= 0x02070000
    ptr = PyCapsule_GetPointer(ob, 0);
#else
    ptr = PyCObject_AsVoidPtr(ob);
#endif
    if (!ptr && !PyErr_Occurred())
        PyErr_SetString(PyExc_RuntimeError, "invalid vtable found for imported type");
    Py_DECREF(ob);
    return ptr;
bad:
    Py_XDECREF(ob);
    return NULL;
}

static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name) {
    PyObject *result;
#if CYTHON_COMPILING_IN_CPYTHON
    result = PyDict_GetItem(__pyx_d, name);
    if (likely(result)) {
        Py_INCREF(result);
    } else {
#else
    result = PyObject_GetItem(__pyx_d, name);
    if (!result) {
        PyErr_Clear();
#endif
        result = __Pyx_GetBuiltinName(name);
    }
    return result;
}

static PyObject *__Pyx_GetNameInClass(PyObject *nmspace, PyObject *name) {
    PyObject *result;
    result = __Pyx_PyObject_GetAttrStr(nmspace, name);
    if (!result)
        result = __Pyx_GetModuleGlobalName(name);
    return result;
}

static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = (start + end) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, (size_t)new_max*sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

#include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    py_code = __pyx_find_code_object(c_line ? c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        PyThreadState_GET(), /*PyThreadState *tstate,*/
        py_code,             /*PyCodeObject *code,*/
        __pyx_d,      /*PyObject *globals,*/
        0                    /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    py_frame->f_lineno = py_line;
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_VERSION_HEX < 0x03030000
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.')) {
                #if PY_VERSION_HEX < 0x03030000
                PyObject *py_level = PyInt_FromLong(1);
                if (!py_level)
                    goto bad;
                module = PyObject_CallFunctionObjArgs(py_import,
                    name, global_dict, empty_dict, list, py_level, NULL);
                Py_DECREF(py_level);
                #else
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                #endif
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_VERSION_HEX < 0x03030000
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_VERSION_HEX < 0x03030000
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

#define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)       \
    {                                                                     \
        func_type value = func_value;                                     \
        if (sizeof(target_type) < sizeof(func_type)) {                    \
            if (unlikely(value != (func_type) (target_type) value)) {     \
                func_type zero = 0;                                       \
                if (is_unsigned && unlikely(value < zero))                \
                    goto raise_neg_overflow;                              \
                else                                                      \
                    goto raise_overflow;                                  \
            }                                                             \
        }                                                                 \
        return (target_type) value;                                       \
    }

#if CYTHON_COMPILING_IN_CPYTHON && PY_MAJOR_VERSION >= 3
 #if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
 #endif
#endif

static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) -1, const_zero = 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_MAJOR_VERSION >= 3
 #if CYTHON_USE_PYLONG_INTERNALS
            switch (Py_SIZE(x)) {
                case  0: return 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, ((PyLongObject*)x)->ob_digit[0]);
            }
 #endif
#endif
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT(int, unsigned long, PyLong_AsUnsignedLong(x))
            } else if (sizeof(int) <= sizeof(unsigned long long)) {
                __PYX_VERIFY_RETURN_INT(int, unsigned long long, PyLong_AsUnsignedLongLong(x))
            }
        } else {
#if CYTHON_COMPILING_IN_CPYTHON && PY_MAJOR_VERSION >= 3
 #if CYTHON_USE_PYLONG_INTERNALS
            switch (Py_SIZE(x)) {
                case  0: return 0;
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +(((PyLongObject*)x)->ob_digit[0]));
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, -(sdigit) ((PyLongObject*)x)->ob_digit[0]);
            }
 #endif
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT(int, long, PyLong_AsLong(x))
            } else if (sizeof(int) <= sizeof(long long)) {
                __PYX_VERIFY_RETURN_INT(int, long long, PyLong_AsLongLong(x))
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_Int(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_Int(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) -1, const_zero = 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_MAJOR_VERSION >= 3
 #if CYTHON_USE_PYLONG_INTERNALS
            switch (Py_SIZE(x)) {
                case  0: return 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, ((PyLongObject*)x)->ob_digit[0]);
            }
 #endif
#endif
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT(long, unsigned long, PyLong_AsUnsignedLong(x))
            } else if (sizeof(long) <= sizeof(unsigned long long)) {
                __PYX_VERIFY_RETURN_INT(long, unsigned long long, PyLong_AsUnsignedLongLong(x))
            }
        } else {
#if CYTHON_COMPILING_IN_CPYTHON && PY_MAJOR_VERSION >= 3
 #if CYTHON_USE_PYLONG_INTERNALS
            switch (Py_SIZE(x)) {
                case  0: return 0;
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +(((PyLongObject*)x)->ob_digit[0]));
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, -(sdigit) ((PyLongObject*)x)->ob_digit[0]);
            }
 #endif
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT(long, long, PyLong_AsLong(x))
            } else if (sizeof(long) <= sizeof(long long)) {
                __PYX_VERIFY_RETURN_INT(long, long long, PyLong_AsLongLong(x))
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_Int(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_Int(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) -1, const_zero = 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
        } else if (sizeof(long) <= sizeof(unsigned long long)) {
            return PyLong_FromUnsignedLongLong((unsigned long long) value);
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(long long)) {
            return PyLong_FromLongLong((long long) value);
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

static CYTHON_INLINE PyObject* __Pyx_PyInt_From_int(int value) {
    const int neg_one = (int) -1, const_zero = 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
        } else if (sizeof(int) <= sizeof(unsigned long long)) {
            return PyLong_FromUnsignedLongLong((unsigned long long) value);
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(long long)) {
            return PyLong_FromLongLong((long long) value);
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
    }
}

static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

#ifndef __PYX_HAVE_RT_ImportModule
#define __PYX_HAVE_RT_ImportModule
static PyObject *__Pyx_ImportModule(const char *name) {
    PyObject *py_name = 0;
    PyObject *py_module = 0;
    py_name = __Pyx_PyIdentifier_FromString(name);
    if (!py_name)
        goto bad;
    py_module = PyImport_Import(py_name);
    Py_DECREF(py_name);
    return py_module;
bad:
    Py_XDECREF(py_name);
    return 0;
}
#endif

#ifndef __PYX_HAVE_RT_ImportType
#define __PYX_HAVE_RT_ImportType
static PyTypeObject *__Pyx_ImportType(const char *module_name, const char *class_name,
    size_t size, int strict)
{
    PyObject *py_module = 0;
    PyObject *result = 0;
    PyObject *py_name = 0;
    char warning[200];
    Py_ssize_t basicsize;
#ifdef Py_LIMITED_API
    PyObject *py_basicsize;
#endif
    py_module = __Pyx_ImportModule(module_name);
    if (!py_module)
        goto bad;
    py_name = __Pyx_PyIdentifier_FromString(class_name);
    if (!py_name)
        goto bad;
    result = PyObject_GetAttr(py_module, py_name);
    Py_DECREF(py_name);
    py_name = 0;
    Py_DECREF(py_module);
    py_module = 0;
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#ifndef Py_LIMITED_API
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
#else
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if (!strict && (size_t)basicsize > size) {
        PyOS_snprintf(warning, sizeof(warning),
            "%s.%s size changed, may indicate binary incompatibility",
            module_name, class_name);
        if (PyErr_WarnEx(NULL, warning, 0) < 0) goto bad;
    }
    else if ((size_t)basicsize != size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s has the wrong size, try recompiling",
            module_name, class_name);
        goto bad;
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(py_module);
    Py_XDECREF(result);
    return NULL;
}
#endif

static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
static CYTHON_INLINE char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
#if PY_VERSION_HEX < 0x03030000
        char* defenc_c;
        PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
        if (!defenc) return NULL;
        defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        {
            char* end = defenc_c + PyBytes_GET_SIZE(defenc);
            char* c;
            for (c = defenc_c; c < end; c++) {
                if ((unsigned char) (*c) >= 128) {
                    PyUnicode_AsASCIIString(o);
                    return NULL;
                }
            }
        }
#endif
        *length = PyBytes_GET_SIZE(defenc);
        return defenc_c;
#else
        if (__Pyx_PyUnicode_READY(o) == -1) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        if (PyUnicode_IS_ASCII(o)) {
            *length = PyUnicode_GET_LENGTH(o);
            return PyUnicode_AsUTF8(o);
        } else {
            PyUnicode_AsASCIIString(o);
            return NULL;
        }
#else
        return PyUnicode_AsUTF8AndSize(o, length);
#endif
#endif
    } else
#endif
#if !CYTHON_COMPILING_IN_PYPY
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_Int(PyObject* x) {
  PyNumberMethods *m;
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (PyInt_Check(x) || PyLong_Check(x))
#else
  if (PyLong_Check(x))
#endif
    return Py_INCREF(x), x;
  m = Py_TYPE(x)->tp_as_number;
#if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = PyNumber_Int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = PyNumber_Long(x);
  }
#else
  if (m && m->nb_int) {
    name = "int";
    res = PyNumber_Long(x);
  }
#endif
  if (res) {
#if PY_MAJOR_VERSION < 3
    if (!PyInt_Check(res) && !PyLong_Check(res)) {
#else
    if (!PyLong_Check(res)) {
#endif
      PyErr_Format(PyExc_TypeError,
                   "__%.4s__ returned non-%.4s (type %.200s)",
                   name, name, Py_TYPE(res)->tp_name);
      Py_DECREF(res);
      return NULL;
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b)))
      return PyInt_AS_LONG(b);
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_COMPILING_IN_CPYTHON && PY_MAJOR_VERSION >= 3
     #if CYTHON_USE_PYLONG_INTERNALS
       switch (Py_SIZE(b)) {
       case -1: return -(sdigit)((PyLongObject*)b)->ob_digit[0];
       case  0: return 0;
       case  1: return ((PyLongObject*)b)->ob_digit[0];
       }
     #endif
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
